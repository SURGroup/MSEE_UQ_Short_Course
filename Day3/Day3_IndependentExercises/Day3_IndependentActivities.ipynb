{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c0e7067",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MSEE UQ short course:  The $\\texttt{UQpy}$ library\n",
    "\n",
    "Application of Inference using the $\\texttt{UQpy}$ module $\\texttt{inference}$. \n",
    "\n",
    "Detailed instructions on how to use this module can be found in the $\\texttt{UQpy}$ documentation.\n",
    "\n",
    "https://uqpyproject.readthedocs.io/en/latest/inference_doc.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5af25f",
   "metadata": {},
   "source": [
    "# Activity 1 \n",
    "\n",
    "The goal of this activity is to become familiar with various $\\texttt{MCMC}$ algorithms\n",
    "\n",
    "Use the Rosenbrock distribution provided below, and generate samples using the following $\\texttt{MCMC}$ algorithms:\n",
    "- $\\texttt{ModifiedMetropolisHastings}$\n",
    "- $\\texttt{DRAM}$\n",
    "- $\\texttt{Stretch}$\n",
    "\n",
    "Explore the various options provided by each one of the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UQpy.distributions import DistributionND\n",
    "\n",
    "\n",
    "class Rosenbrock(DistributionND):\n",
    "    def __init__(self, p=20.):\n",
    "        super().__init__(p=p)\n",
    "\n",
    "    def pdf(self, x):\n",
    "        return np.exp(-(100 * (x[:, 1] - x[:, 0] ** 2) ** 2 + (1 - x[:, 0]) ** 2) / self.parameters['p'])\n",
    "\n",
    "    def log_pdf(self, x):\n",
    "        return -(100 * (x[:, 1] - x[:, 0] ** 2) ** 2 + (1 - x[:, 0]) ** 2) / self.parameters['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a37255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "027b8dda",
   "metadata": {},
   "source": [
    "# Activity 2\n",
    "\n",
    "Use **information-theoretic** inference to select between probability models. \n",
    "\n",
    "You are provided with file $\\texttt{'data_ex1b.txt'}$ that contains synthetic measurements for the parameter.  Use model selection with $BIC$ criterion to identify the probability model that best describes the data. \n",
    "\n",
    "The set of candidate models consists of the following probability models: \n",
    "\n",
    "- $\\texttt{Normal}$\n",
    "- $\\texttt{Lognormal}$\n",
    "- $\\texttt{Uniform}$\n",
    "- $\\texttt{ChiSquare}$\n",
    "- $\\texttt{Beta}$\n",
    "- $\\texttt{Levy}$\n",
    "- $\\texttt{InverseGauss}$\n",
    "- $\\texttt{Exponential}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ad414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UQpy.inference import DistributionModel, InformationModelSelection, MLE, BIC\n",
    "from UQpy.distributions import *\n",
    "import numpy as np\n",
    "\n",
    "data_ex1b = np.loadtxt('data_ex1b.txt')\n",
    "\n",
    "m0 = DistributionModel(distributions=Normal(loc=None, scale=None), n_parameters=2, name='normal')\n",
    "m1 = DistributionModel(distributions=Lognormal(s=None, loc=None, scale=None), n_parameters=3, name='lognormal')\n",
    "m2 = DistributionModel(distributions=Uniform(loc=None, scale=None), n_parameters=2, name='uniform')\n",
    "m3 = DistributionModel(distributions=ChiSquare(df=None, loc=None, scale=None), n_parameters=3, name='chi-square')\n",
    "m4 = DistributionModel(distributions=Beta(a=None, b=None, loc=None, scale=None), n_parameters=4, name='beta')\n",
    "m5 = DistributionModel(distributions=Levy(loc=None, scale=None), n_parameters=2, name='levy')\n",
    "m6 = DistributionModel(distributions=InverseGauss(mu=None, loc=None, scale=None), n_parameters=3, name='inv-gauss')\n",
    "m7 = DistributionModel(distributions=Exponential(loc=None, scale=None), n_parameters=2, name='exponential')\n",
    "\n",
    "candidate_models = [m0, m1, m2, m3, m4, m5, m6, m7]\n",
    "\n",
    "mle_list= [MLE(inference_model=model, random_state=0, data=data_ex1b) for model in candidate_models]\n",
    "\n",
    "selector = InformationModelSelection(parameter_estimators=mle_list, criterion=BIC(), n_optimizations=[5]*8)\n",
    "selector.sort_models()\n",
    "print('Sorted model using BIC criterion: ' + ', '.join(m.name for m in selector.candidate_models))\n",
    "print(\"Values of model probabilities: \", selector.probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3d8ea",
   "metadata": {},
   "source": [
    "# Activity 3\n",
    "\n",
    "Using the **Bayesian model** selection to choose between regression models. Consider the problem of Exercise 1. In this case, each candidate model $m_i$ is given a prior probability $P(m_i) = 1/3$. For each model, our prior belief about its parameters $\\theta_i$ is that they are normally distributed as: \n",
    "- $m_0(\\theta)$: $\\theta_0\\sim\\mathcal{N}(0,10)$.\n",
    "- $m_1(\\boldsymbol{\\theta})$: $\\theta_0\\sim\\mathcal{N}(0,1)$, $\\theta_1\\sim\\mathcal{N}(0,1)$\n",
    "- $m_2(\\boldsymbol{\\theta})$:  $\\theta_0\\sim\\mathcal{N}(0,1)$, $\\theta_1\\sim\\mathcal{N}(0,2)$, $\\theta_2\\sim\\mathcal{N}(0,0.25)$\n",
    "\n",
    "Using the same $\\texttt{BayesModelSelection}$ of **Exercise 4** of the In-Class exercises\n",
    "\n",
    "- Change the parameters of the $\\texttt{MetropolisHastings}$ sampling, to see how the results change.\n",
    "- Use $\\texttt{ModifiedMetropolisHastings}$, $\\texttt{DRAM}$ and $\\texttt{MetropolisHastings}$ sampling algorithms for each one of the probability models respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb6abf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior probabilities of sorted models:\n",
      "[4.64507579525117e-115, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "# Solution\n",
    "import pickle\n",
    "from UQpy.inference import BayesModelSelection\n",
    "from UQpy.distributions import Normal, JointIndependent\n",
    "# Solution\n",
    "objectRep = open(\"data_ex3.pkl\", \"rb\")\n",
    "data3 = pickle.load(objectRep)\n",
    "objectRep.close()\n",
    "\n",
    "# Solution\n",
    "from UQpy.run_model import RunModel, PythonModel\n",
    "\n",
    "runmodel4 = RunModel(model=PythonModel(model_script='pfn.py', model_object_name='model_linear', var_names=['theta_0']))\n",
    "runmodel5 = RunModel(model=PythonModel(model_script='pfn1.py', model_object_name='model_quadratic', var_names=['theta_0','theta_1']))\n",
    "runmodel6 = RunModel(model=PythonModel(model_script='pfn2.py', model_object_name='model_cubic', var_names=['theta_0','theta_1','theta_2']))\n",
    "\n",
    "# Solution\n",
    "from UQpy.distributions import JointIndependent, Normal\n",
    "prior1=Normal(0, 10)\n",
    "prior2=JointIndependent(marginals=[Normal(0, 1), Normal(0, 1)])\n",
    "prior3=JointIndependent(marginals=[Normal(0, 1), Normal(0, 2), Normal(0, 0.25)])\n",
    "\n",
    "# Solution\n",
    "import numpy as np\n",
    "from UQpy.inference import ComputationalModel\n",
    "model_n_params = [1, 2, 3]\n",
    "model1 = ComputationalModel(n_parameters=1, runmodel_object=runmodel4, prior=prior1,\n",
    "                            error_covariance=np.ones(50), name='model_linear')\n",
    "model2 = ComputationalModel(n_parameters=2, runmodel_object=runmodel5, prior=prior2,\n",
    "                            error_covariance=np.ones(50), name='model_quadratic')\n",
    "model3 = ComputationalModel(n_parameters=3, runmodel_object=runmodel6, prior=prior3,\n",
    "                            error_covariance=np.ones(50), name='model_cubic')\n",
    "\n",
    "candidate_models= [model1, model2, model3]\n",
    "\n",
    "# Solution\n",
    "from UQpy.inference import BayesParameterEstimation\n",
    "from UQpy.inference import BayesModelSelection\n",
    "from UQpy.sampling import MetropolisHastings\n",
    "proposals = [Normal(0.1),\n",
    "            JointIndependent([Normal(0.1), Normal(0.1)]),\n",
    "            JointIndependent([Normal(0.15), Normal(0.1), Normal(0.05)])]\n",
    "\n",
    "model_prior_means = [[0.], [0., 0.], [0., 0., 0.]]\n",
    "\n",
    "mh1 = ModifiedMetropolisHastings(jump=10, burn_length=1000, proposal=proposals[0], seed=[0])\n",
    "mh2 = DRAM(jump=10, burn_length=1000, seed=[0., 1.1])\n",
    "mh3 = MetropolisHastings(jump=10, burn_length=1000,proposal=proposals[2], seed=[0.9, 2.2, 0.])\n",
    "\n",
    "samplers=[mh1, mh2, mh3]\n",
    "estimators = []\n",
    "for i in range(3):\n",
    "    estimators.append(BayesParameterEstimation(inference_model=candidate_models[i], data=data3, \n",
    "                                               sampling_class=samplers[i]))\n",
    "\n",
    "selection = BayesModelSelection(parameter_estimators=estimators,\n",
    "                                prior_probabilities=[1. / 3., 1. / 3., 1. / 3.],\n",
    "                                nsamples=[2000, 2000, 2000])\n",
    "\n",
    "sorted_indices = np.argsort(selection.probabilities)[::-1]\n",
    "print('Sorted models:')\n",
    "print([selection.candidate_models[i].name for i in sorted_indices])\n",
    "print('Posterior probabilities of sorted models:')\n",
    "print([selection.probabilities[i] for i in sorted_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27ef906",
   "metadata": {},
   "source": [
    "# Activity 4\n",
    "\n",
    "\n",
    "## Perform ${BayesParameterEstimation}$ for the Hugoniot relationships.\n",
    "\n",
    "The model consists of the Rankine-Hugoniot equations. These equations describe the relationship between the states on both sides of a shock wave and express the conservation of mass, momentum and energy:\n",
    "\n",
    "   \\begin{align*}\n",
    "    & \\rho_0 U_s = \\rho_1(U_s -u_p)\\\\\n",
    "    & P_1=\\rho_0 U_s u_p \\\\\n",
    "    & E_1 -E_0=\\frac{1}{2}(P_1+P_0)(\\frac{1}{\\rho_0}-\\frac{1}{\\rho_1})\n",
    "   \\end{align*}\n",
    "\n",
    "given the relationship between $U_s, u_p$ can be computed and subsequently the quantities $\\rho_1, P_1$ and $E_1$ can be computed. We know that the relationship between the shock velocity $U_s$ and particle velocity $u_p$ is given by a cubic polynomial expression as follows:\n",
    "\n",
    "   \\begin{align*}\n",
    "    U_s = a_0 + a_1 \\cdot u_p + a_2 \\cdot u_p^2+ a_3 \\cdot u_p^3\n",
    "   \\end{align*}\n",
    "\n",
    "\n",
    "Given the file $\\texttt{experimental}\\_\\texttt{hugoniot}\\_\\texttt{data.pkl}$ that contains experimental results, perform $\\texttt{BayesParameterEstimation}$ to determine the actual distribution of the polynomial parameters that dictate the relationship between the shock $U_s$ and particle velocities $u_p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815509a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "output = open('activity_data.pkl', 'rb')\n",
    "activity_data = pickle.load(output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024aad4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from UQpy.run_model.model_execution.PythonModel import PythonModel\n",
    "from UQpy.run_model.RunModel import RunModel\n",
    "model = PythonModel(model_script='activity_model.py',\n",
    "                    model_object_name='model_quadratic',\n",
    "                    var_names=['a_0', 'a_1', 'a_2', 'a_3'])\n",
    "h_func = RunModel(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7839011",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from UQpy.distributions import Normal, JointIndependent\n",
    "p0 = Normal()\n",
    "p1 = Normal()\n",
    "p2 = Normal()\n",
    "p3 = Normal()\n",
    "prior = JointIndependent(marginals=[p0, p1, p2, p3])\n",
    "\n",
    "error_covariance = 1.0\n",
    "\n",
    "from UQpy.inference import ComputationalModel\n",
    "inference_model = ComputationalModel(n_parameters=4, runmodel_object=h_func, error_covariance=error_covariance, prior=prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174524e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from UQpy.sampling import MetropolisHastings\n",
    "\n",
    "proposal = JointIndependent([Normal(), Normal(), \n",
    "                             Normal(), Normal()])\n",
    "\n",
    "mh1 = MetropolisHastings(jump=10, burn_length=0, proposal=proposal, seed=[0.0, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c57562",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from UQpy.inference import BayesParameterEstimation\n",
    "bayes_estimator = BayesParameterEstimation(inference_model=inference_model,\n",
    "                                           data=activity_data, sampling_class=mh1,\n",
    "                                           nsamples=500)\n",
    "s = bayes_estimator.sampler.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563df4eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity  # for the plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pdf_from_kde(domain, samples1d):\n",
    "    bandwidth = 1.06 * np.std(samples1d) * samples1d.size ** (-1 / 5)\n",
    "    kde = KernelDensity(bandwidth=bandwidth).fit(samples1d.reshape((-1, 1)))\n",
    "    log_dens = kde.score_samples(domain)\n",
    "    return np.exp(log_dens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7dece",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 4))\n",
    "\n",
    "domain = np.linspace(-4, 10, 200)[:, np.newaxis]\n",
    "pdf_ = pdf_from_kde(domain, s[:, 0])\n",
    "ax[0].plot(domain, pdf_, label='posterior')\n",
    "ax[0].plot(domain, p0.pdf(domain), label='prior')\n",
    "ax[0].set_title('posterior pdf of a_{0}')\n",
    "\n",
    "domain = np.linspace(-4, 4, 200)[:, np.newaxis]\n",
    "pdf_ = pdf_from_kde(domain, s[:, 1])\n",
    "ax[1].plot(domain, pdf_, label='posterior')\n",
    "ax[1].plot(domain, p1.pdf(domain), label='prior')\n",
    "ax[1].set_title('posterior pdf of a_{1}')\n",
    "\n",
    "domain = np.linspace(-4, 4, 200)[:, np.newaxis]\n",
    "pdf_ = pdf_from_kde(domain, s[:, 2])\n",
    "ax[2].plot(domain, pdf_, label='posterior')\n",
    "ax[2].plot(domain, p2.pdf(domain), label='prior')\n",
    "ax[2].set_title('posterior pdf of a_{2}')\n",
    "\n",
    "domain = np.linspace(-4, 4, 200)[:, np.newaxis]\n",
    "pdf_ = pdf_from_kde(domain, s[:, 3])\n",
    "ax[3].plot(domain, pdf_, label='posterior')\n",
    "ax[3].plot(domain, p2.pdf(domain), label='prior')\n",
    "ax[3].set_title('posterior pdf of a_{3}')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
