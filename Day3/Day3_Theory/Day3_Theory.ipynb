{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>MSEE Short course on UQ</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Introduction</b></span>\n",
    "<ul style=\"margin-top:0px\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Inverse UQ framework</span></li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Inference</b></span>\n",
    "<ul style=\"margin-top:0px\">\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">Conditional probabilities</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Model selection</span></li>\n",
    "    <ul>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">Bayesian selection</span></li>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">Information-theoretic model selection</span></li>\n",
    "    </ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Bayesian parameter estimation</span></li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Markov Chain Monte Carlo</b></span>\n",
    "<ul style=\"margin-top:0px\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Ingredients</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Metropolis-Hastings</span></li>\n",
    "</ul>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Example from MSEE</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Inverse UQ framework</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"./photos/Day1_7.png\" width=\"2000\"> \n",
    "</div>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Inverse UQ framework</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"./photos/Day1_8.png\" width=\"2000\"> \n",
    "</div>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Inference</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\">A set of data $\\mathcal{D}=\\{ \\text{Y}_1,...,\\text{Y}_N \\}$ with added noise is generated from some (probability) model $M$.</span> \n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">We need to find model $M$, i.e., find its <span style=\"color:blue;\">form</span> and/or its <span style=\"color:blue;\">parameters</span>:</span> \n",
    "\n",
    "<br></br>\n",
    "<ul style=\"margin-top:0px\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Model selection</b> identifies the form $M$ out of a set of candidate models. (e.g., <i>linear, quadratic, Gaussian, lognormal, Beta</i>).</span> </li>\n",
    "    <br></br>\n",
    "    <ul>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">Establish well-justified criteria for determining the best model.</span> </li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Bayesian methods and Informatic model selection will be presented</span> </li>\n",
    "    </ul>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Parameter Estimation:</b> Bayesian inference estimates the distribution of parameters $\\boldsymbol{\\theta}$ of model $M$, given the data $\\mathcal{D}$, i.e. $M(\\boldsymbol{\\theta|\\mathcal{D}})$</span> </li>\n",
    "    <br></br>\n",
    "    <ul>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">Combine <span style=\"color:blue;\">prior</span> knowledge on the parameters $\\boldsymbol{\\theta}$ with the available data $\\mathcal{D}$.</span> </li>\n",
    "    </ul>\n",
    "    <br></br>\n",
    "</ul>\n",
    "\n",
    " <br></br>\n",
    " <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Probability Theory</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Conditional probabilities</b></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Consider the probability space $\\{\\Omega, \\mathcal{B}, {P} \\}$</span> \n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">If $A,B \\in \\mathcal{B}$ and $P(B)>0$, then the conditional probability of $A$ given $B$ is:</span> \n",
    "\n",
    " \\begin{align*}\n",
    "    P(A|B)=\\frac{P(A\\cap B)}{P(B)} \\qquad P(B|A)=\\frac{P(B\\cap A)}{P(A)}\n",
    " \\end{align*}\n",
    "\n",
    " \n",
    " Given that $P(A \\cap B)=P(B \\cap A)$, and solving for it in the latest equation we obtain\n",
    " \n",
    " \n",
    " \\begin{align*}\n",
    "    P(B \\cap A)=P(B|A)P(A)\n",
    " \\end{align*}\n",
    " \n",
    " Replacing in $P(B \\cap A)$ in the first equation we obtain <span style=\"color:blue; font-size:1em; font-family:Arial\"><b>Bayes' rule</b></span>\n",
    " \n",
    " \n",
    " \\begin{align*}\n",
    "    P(A|B)=\\frac{P(B|A)P(A)}{P(B)}\n",
    " \\end{align*}\n",
    " \n",
    " <br></br>\n",
    " <br></br>\n",
    " <br></br>\n",
    " <br></br>\n",
    " <br></br>\n",
    " <br></br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"./photos/Day3_VennDiagram.png\" width=\"800\"> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Bayes' rule</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\\begin{align*}\n",
    "    P(A|B)=\\frac{P(B|A)P(A)}{P(B)}\n",
    " \\end{align*}\n",
    " \n",
    " <ol>\n",
    "    <li>The <b>prior probability</b> of event $A$, $P(A)$, represents the strength of our belief that event $A$ occurs before we observe event $B$.</li>\n",
    "    <li>The <b>likelihood</b> is the probability of observing $B$ given that $A$ has occured.</li>\n",
    "    <ul>\n",
    "        <li>The likelihood expresses the impact of event $B$ on the strength of our belief in observing event $A$.</li>\n",
    "        <li><i>Poor prior:</i> One that gives low probability of observing $B$</li>\n",
    "        <ul>\n",
    "            <li>Poor priors are <b>weakend</b> by the data</li>\n",
    "        </ul>\n",
    "        <li><i>Strong prior:</i> One that gives high probability of observing $B$</li>\n",
    "        <ul>\n",
    "            <li>Strong priors are <b>strengthened</b> by the data</li>\n",
    "        </ul>\n",
    "    </ul>\n",
    "    <li>The <b>posterior probability</b> is the strength of our belief in $A$ after having observed $B$.</li>\n",
    "    <li>The <b>evidence</b> $P(B)=\\sum_A P(B|A)P(A)$ is the probability of observing $B$ given any $A$</li>\n",
    " </ol>\n",
    " \n",
    "  <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Model selection</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Bayes model selection</b></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Selection between two models $M_i, M_j$ is often conducted by comparing the ratio of posterior probabilities as:</span> \n",
    "\n",
    "\\begin{align*}\n",
    "    & \\frac{\\hat{\\pi}_i}{\\hat{\\pi}_j}=\\frac{\\pi_i}{\\pi_j}\\times\\color{blue}{\\frac{p(\\mathcal{D}|M_j)}{p(\\mathcal{D}|M_j)}\\rightarrow (\\text{Bayes' factor})}\n",
    " \\end{align*}\n",
    " \n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where</span> \n",
    " \n",
    " \\begin{align*}\n",
    "    & p(\\mathcal{D}|M_j)=\\int p(\\mathcal{D}|M_j,\\boldsymbol{\\theta}_j)p(\\boldsymbol{\\theta}_j|M_j)d\\boldsymbol{\\theta}_j\\rightarrow\\color{blue}{\\text{evidence}}\n",
    " \\end{align*}\n",
    " \n",
    "<span style=\"font-size:1.1em; font-family:Arial\">This can be generalized for comparison of multiple models:</span> \n",
    "\n",
    "\\begin{align*}\n",
    "    & \\hat{\\pi}_j \\equiv p(M_j|\\mathcal{D})=\\frac{p(\\mathcal{D}|M_j)\\cdot \\pi_j}{\\sum_{k=1}^m p(\\mathcal{D}|M_k)\\cdot \\pi_k}\n",
    " \\end{align*}\n",
    " \n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where $\\hat{\\pi}_j$ is the posterior distribution, computed with the aid of Bayes rule</span> \n",
    " \n",
    "  <br></br>\n",
    "   <br></br>\n",
    "     <br></br>\n",
    "   <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Model selection</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\">Consider two model, $M_i$ and $M_j$, we can express the posterior odds as</span> \n",
    "\n",
    "\\begin{align*}\n",
    "    & \\frac{\\hat{\\pi}_i}{\\hat{\\pi}_j}= \\frac{\\pi_i}{\\pi_j} \\times \\frac{P(\\mathcal{D}|M_i)}{P(\\mathcal{D}|M_j)}\n",
    " \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">posterior odds = likelihood odds $\\times$ prior odds</span> \n",
    " \n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">What if $M_i$ is more likely that $M_j$?</span> \n",
    "\n",
    "\\begin{align*}\n",
    "    & \\frac{\\hat{\\pi}_i}{\\hat{\\pi}_j} \\ge 1\n",
    " \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">What if $M_j$ is more likely that $M_i$?</span> \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\frac{\\hat{\\pi}_i}{\\hat{\\pi}_j} \\le 1\n",
    " \\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Model selection</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Bayes' rule for model selection</b></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Let $M$ represent our model and $\\mathcal{D}$ represent an observation of our experiment (data).</span> \n",
    "\n",
    "\\begin{align*}\n",
    "    & P(M|\\mathcal{D}) \\propto P(\\mathcal{D}|M)\\times P(M)=\\mathcal{L}(M|D)P(M)\n",
    " \\end{align*}\n",
    " \n",
    " <ol>\n",
    "    <li>The <b>prior probability</b> of our model $M$, $P(M)$, represents the strength of our belief in that model $M$ is the best model before we observe $\\mathcal{D}$.</li>\n",
    "    <li>The <b>likelihood</b> is the probability of observing $\\mathcal{D}$ given that model $M$ is the best model.</li>\n",
    "    <ul>\n",
    "        <li>The likelihood expresses the impact of the data $\\mathcal{D}$ on the strength of our belief in the model.</li>\n",
    "        <li><i>Poor model:</i> One that gives low probability of observing $\\mathcal{D}$</li>\n",
    "        <ul>\n",
    "            <li>Poor models are <b>weakend</b> by the data</li>\n",
    "        </ul>\n",
    "        <li><i>Strong model:</i> One that gives high probability of observing $\\mathcal{D}$</li>\n",
    "        <ul>\n",
    "            <li>Strong models are <b>strengthened</b> by the data</li>\n",
    "        </ul>\n",
    "    </ul>\n",
    "    <li>The <b>posterior probability</b> is the strength of our belief in $M$ after having observed $\\mathcal{D}$.</li>\n",
    " </ol>\n",
    " \n",
    "  <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Model selection</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Consider a set of $m$ candidate (probability) models $\\{ M_1,...,M_m\\}$, from which the data may have been generated</span> \n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">We want to estimate the probability that model $M_j$ is the \"best\" model.</span> \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\hat{\\pi}_j=P(M_j|\\mathcal{D})=\\frac{P(\\mathcal{D}|M_j)\\times P(M_j)}{\\sum_i P(\\mathcal{D}|M_i)\\times P(M_i)}\n",
    " \\end{align*}\n",
    " \n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Assign a prior</span> </li>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\"><u>Assumption</u>: All prior models $\\{ M_1,...,M_m\\}$ have <span style=\"color:blue;\">equal</span> probability:</span>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "     \\begin{align*}\n",
    "    & \\pi_j=P(M_j)=\\frac{1}{m}, \\qquad \\text{where} \\qquad  \\sum_{k=1}^m\\pi_k=1\n",
    " \\end{align*}\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Models are ranked according to their probabilities $\\hat{\\pi}_j$.</span> </li>\n",
    "    <ul>\n",
    "    <li><b>Model Selection:</b> The model with the highest probability is selected.</li>\n",
    "    <li><b>Multi-model selection:</b> All models with non-negligible probability are retained.</li>\n",
    "    </ul>\n",
    "    <br></br>\n",
    "</ul>\n",
    "\n",
    " <br></br>\n",
    " <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Bayes' factor</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\">Consider two model, $M_i$ and $M_j$, we can express the posterior odds as</span> \n",
    "\n",
    "\\begin{align*}\n",
    "    & \\frac{\\hat{\\pi}_i}{\\hat{\\pi}_j}= \\frac{\\pi_i}{\\pi_j} \\times \\frac{P(\\mathcal{D}|M_i)}{P(\\mathcal{D}|M_j)}\n",
    " \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">posterior odds = likelihood odds $\\times$ prior odds</span> \n",
    " \n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">What if $M_i$ is more likely that $M_j$?</span> \n",
    "\n",
    "\\begin{align*}\n",
    "    & \\frac{\\hat{\\pi}_i}{\\hat{\\pi}_j} \\ge 1\n",
    " \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">What if $M_j$ is more likely that $M_i$?</span> \n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\frac{\\hat{\\pi}_i}{\\hat{\\pi}_j} \\le 1\n",
    " \\end{align*}\n",
    "\n",
    "  <br></br>\n",
    "    <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Information theoretic model selection</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\">Framework to compare relative information loss of different models</span> \n",
    "\n",
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Loss functions are used to estimate model information loss, called criteria:</span> \n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">The output of information loss functions is a scalar estimate of information loss</span> </li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Comparing models is translated to comparing the values of loss functions</span> </li>\n",
    "</ul>    \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Each criterion is comprised of two competing terms:</span> \n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Model fitting term</span> </li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Penalty term for overparameterization</span> </li>    \n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Information theoretic model selection</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br></br>\n",
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Information theoretic criteria</b></span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Bayesian information criterion</b> (BIC)</span></li>\n",
    "        \\begin{align*}\n",
    "    & \\alpha=-2\\log\\mathcal{L}(\\hat{\\boldsymbol{\\theta}}_j|\\mathcal{D},M_j)+K\\log n,\n",
    " \\end{align*}\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Akaike information criterion</b> (AIC)</span></li>\n",
    "        \\begin{align*}\n",
    "    & \\alpha=-2 \\log \\mathcal{L}(\\hat{\\boldsymbol{\\theta}}_j|\\mathcal{D},M_j)+2K,\n",
    " \\end{align*}\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Extened</b> AIC</span></li>\n",
    "        \\begin{align*}\n",
    "    & \\alpha_c=-2 \\log\\mathcal{L}(\\hat{\\boldsymbol{\\theta}}_j|\\mathcal{D},M_j)+2K+\\frac{2K(K+1)}{n-K-1}\n",
    " \\end{align*}\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">$\\hat{\\boldsymbol{\\theta}}_j\\rightarrow$ maximum likelihood estimate of parameters</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\hat{\\boldsymbol{\\theta}}_j=\\arg \\max p(\\mathcal{D}|{\\hat{\\boldsymbol{\\theta}}}_j,M_j)\n",
    " \\end{align*}\n",
    " \n",
    " <span style=\"font-size:1.1em; font-family:Arial\">$\\mathcal{L}(\\hat{\\boldsymbol{\\theta}}_j|\\mathcal{D})=p(\\mathcal{D}|\\hat{\\boldsymbol{\\theta}}_j,M_j)\\rightarrow$ maximized log-likelihood</span>\n",
    " \n",
    " <span style=\"font-size:1.1em; font-family:Arial\">$\\boldsymbol{K}\\rightarrow$ dimension of random vector $\\boldsymbol{\\theta}$\n",
    "</span>\n",
    "\n",
    "  <span style=\"font-size:1.1em; font-family:Arial\">$n\\rightarrow$ size of data $\\mathcal{D}$</span>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:0.9em; font-family:Arial\">Burnham K., Anderson D., 2004,  Multimodel Inference Understaning AIC and BIC in Model Selection, Sociological methods and Research </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Information theoretic model selection</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br></br>\n",
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Information theoretic criteria</b></span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Bayesian information criterion</b> (BIC)</span></li>\n",
    "        \\begin{align*}\n",
    "    & \\alpha=-2\\log\\mathcal{L}(\\hat{\\boldsymbol{\\theta}}_j|\\mathcal{D},M_j)+K\\log n,\n",
    " \\end{align*}\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Akaike information criterion</b> (AIC)</span></li>\n",
    "        \\begin{align*}\n",
    "    & \\alpha=-2 \\log \\mathcal{L}(\\hat{\\boldsymbol{\\theta}}_j|\\mathcal{D},M_j)+2K,\n",
    " \\end{align*}\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Extened</b> AIC</span></li>\n",
    "        \\begin{align*}\n",
    "    & \\alpha_c=-2 \\log\\mathcal{L}(\\hat{\\boldsymbol{\\theta}}_j|\\mathcal{D},M_j)+2K+\\frac{2K(K+1)}{n-K-1}\n",
    " \\end{align*}\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "  \n",
    "\\begin{align*}\n",
    "    & \\Delta_{\\alpha}^{(j)}=\\alpha^{(j)}-\\min(\\alpha)\\rightarrow \\color{blue}{\\text{best} \\ \\text{model}:}\\Delta_{\\alpha}^{(j)}=0\n",
    "\\end{align*}\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\\begin{align*}\n",
    "    & \\hat{\\pi}_j=p(M_j|\\mathcal{D})=\\frac{\\exp\\big( -\\frac{1}{2}\\Delta_{\\alpha}^{(j)} \\big)}{\\sum_{k=1}^m \\exp\\big( -\\frac{1}{2}\\Delta_{\\alpha}^{(k)} \\big)} \\\\\n",
    " \\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:0.9em; font-family:Arial\">Burnham K., Anderson D., 2004,  Multimodel Inference Understaning AIC and BIC in Model Selection, Sociological methods and Research </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Model selection in $\\texttt{UQpy}$</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The $\\texttt{Inference}$ module in $\\texttt{UQpy}$\n",
    "\n",
    "\n",
    "This module contains classes and functions for statistical inference from data.\n",
    "\n",
    "The module currently contains the following classes:\n",
    "\n",
    "- $\\texttt{DistributionModel, ComputationalModel}$: Define a probabilistic model for Inference.\n",
    "- $\\texttt{MLE}$: Compute maximum likelihood parameter estimate.\n",
    "- $\\texttt{InformationModelSelection}$: Perform model selection using information theoretic criteria.\n",
    "- $\\texttt{BayesParameterEstimation}$: Perform Bayesian parameter estimation (estimate posterior density) via MCMC or ImportanceSampling.\n",
    "- $\\texttt{BayesModelSelection}$: Estimate model posterior probabilities\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Model selection in $\\texttt{UQpy}$</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<div align=\"center\">\n",
    "  <img src=\"./photos/inference.png\" width=\"1200\"> \n",
    "</div>\n",
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Model selection in $\\texttt{UQpy}$</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\texttt{InferenceModel}$ - In $\\texttt{UQpy}$ an inference model is the model(s) that we we are trying to learn to best fit the data.\n",
    "\n",
    "<ul>\n",
    "    <li>Gaussian error model powered by $\\texttt{RunModel}$:</li>\n",
    "    <ul>\n",
    "        <li>Data come from a model: $\\sim h(\\theta) + eps$, where $eps$ is i.i.d Gaussian and $h$ consists of a computational model executed using $\\texttt{RunModel}$. \n",
    "</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "    <li>non-Gaussian error model powered by $\\texttt{RunModel}$:</li>\n",
    "    <ul>\n",
    "        <li>Provide the likelihood function in addition to a $\\texttt{RunModel}$ object. \n",
    "</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "    <li>User-defined likelihood without $\\texttt{RunModel}$:</li>\n",
    "    <ul>\n",
    "        <li>The likelihood function is user-defined and does not leverage $\\texttt{RunModel}$.\n",
    "</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "    <li>Learn parameters of a probability distribution:</li>\n",
    "    <ul>\n",
    "        <li> Here, the user must define an object of the $\\texttt{Distribution}$ class.\n",
    "</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UQpy.inference.inference_models.DistributionModel import DistributionModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Model selection in $\\texttt{UQpy}$</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection between different univariate distributions from i.i.d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 500 data from Gamma distribution\n",
    "from UQpy.distributions import Gamma\n",
    "data = Gamma(a=2, loc=0, scale=2).rvs(nsamples=500, random_state=17)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to be compared:\n",
    "from UQpy.distributions import Gamma, Exponential, Uniform\n",
    "m0 = DistributionModel(distributions=Gamma(a=None, loc=None, scale=None), n_parameters=3, name='gamma')\n",
    "m1 = DistributionModel(distributions=Exponential(loc=None, scale=None), n_parameters=2, name='exponential')\n",
    "m2 = DistributionModel(distributions=Uniform(loc=None, scale=None), n_parameters=2, name='uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Model selection in $\\texttt{UQpy}$</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\texttt{InfoModelSelection}$ class for performing model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UQpy.inference.InformationModelSelection import InformationModelSelection\n",
    "from UQpy.inference.MLE import MLE\n",
    "from UQpy.inference.information_criteria.BIC import BIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform model selection using the BIC criterion\n",
    "mle1 = MLE(inference_model=m0, data=data)\n",
    "mle2 = MLE(inference_model=m1, data=data)\n",
    "mle3 = MLE(inference_model=m2, data=data)\n",
    "\n",
    "# Perform model selection using the BIC criterion\n",
    "selector = InformationModelSelection(parameter_estimators=[mle1, mle2, mle3], \n",
    "                                     criterion=BIC(), n_optimizations=[5]*3)\n",
    "\n",
    "selector.sort_models()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sorted model using BIC criterion: '+', '.join(\n",
    "    m.name for m in selector.candidate_models))\n",
    "print('Model probabilities: ' + str(selector.probabilities))\n",
    "\n",
    "param = [m.mle for m in selector.parameter_estimators]\n",
    "print('Estimated parameters using MLE:', param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Inference/Bayesian parameter estimation</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">The multi-model selection process identifies a set of candidate model forms $M_j, j=1,...,m$ and their associated probabilities $\\hat{\\pi}_j$.</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">For each one of these models, there are additional uncertainties associated with their parameters $\\boldsymbol{\\theta}_j$</span></li>\n",
    "    <br></br>\n",
    "    Quantify these uncertainties by using Bayes' law:\n",
    "    \\begin{align*}\n",
    "        & P(\\boldsymbol{\\theta}_j|\\mathcal{D}, M_j)=\\frac{P(\\mathcal{D}|\\boldsymbol{\\theta}_j, M_j)P(\\boldsymbol{\\theta}_j|M_j)}{P(\\mathcal{D}|M_j)}\\propto \\mathcal{L}(\\boldsymbol{\\theta}_j|\\mathcal{D})P(\\boldsymbol{\\theta}_j|M_j)\n",
    "     \\end{align*}\n",
    "     <p>where\n",
    "     \\begin{align*}\n",
    "        & P(\\mathcal{D}|M_j)=\\int \\mathcal{L}(\\boldsymbol{\\theta}_j|\\mathcal{D})\\cdot P(\\boldsymbol{\\theta}_j, M_j)d\\boldsymbol{\\theta}\n",
    "     \\end{align*}\n",
    "     <br></br>\n",
    "     <li><span style=\"font-size:1.1em; font-family:Arial\">Use <b>Markov Chain Monte Carlo (MCMC)</b> to sample from $P(\\boldsymbol{\\theta}_j|\\mathcal{D}, M_j)$</span></li>\n",
    "    <br></br>\n",
    "</ul>\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Inference/Bayesian parameter estimation</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">The multi-model selection process identifies a set of candidate model forms $M_j, j=1,...,m$ and their associated probabilities $\\hat{\\pi}_j$.</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">For each one of these models, there are additional uncertainties associated with their parameters $\\boldsymbol{\\theta}_j$</span></li>\n",
    "    <br></br>\n",
    "    Quantify these uncertainties by using Bayes' law:\n",
    "    \\begin{align*}\n",
    "        & P(\\boldsymbol{\\theta}_j|\\mathcal{D}, M_j)=\\frac{P(\\mathcal{D}|\\boldsymbol{\\theta}_j, M_j)P(\\boldsymbol{\\theta}_j|M_j)}{P(\\mathcal{D}|M_j)}\\propto \\mathcal{L}(\\boldsymbol{\\theta}_j|\\mathcal{D})P(\\boldsymbol{\\theta}_j|M_j)\n",
    "     \\end{align*}\n",
    "     <p>where\n",
    "     \\begin{align*}\n",
    "        & P(\\mathcal{D}|M_j)=\\int \\mathcal{L}(\\boldsymbol{\\theta}_j|\\mathcal{D})\\cdot P(\\boldsymbol{\\theta}_j, M_j)d\\boldsymbol{\\theta}\n",
    "     \\end{align*}\n",
    "     <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Maximum Likelihood Estimate (MLE):</b> Select the parameters $\\hat{\\theta}_j$ that maximize the likelihood function $P(\\mathcal{D}|\\boldsymbol{\\theta}_j, M_j)$</span></li>\n",
    "     <ul>\n",
    "    <li>$\\texttt{UQpy}$ $\\texttt{MLEstimation}$ class</li>\n",
    "    </ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Maximum Aposteriori Estimate (MAE):</b> Select the parameters $\\hat{\\theta}_j$ that maximize the posterior probability $P(\\boldsymbol{\\theta}_j|\\mathcal{D}, M_j)$</span></li>\n",
    "    <br></br>\n",
    "</ul>\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">We want to draw samples from some distribution $p(\\boldsymbol{x})=\\frac{\\tilde{p}(\\boldsymbol{x})}{Z}$, where $\\tilde{p}(\\boldsymbol{x})$ is known but $Z$ is hard to compute.\n",
    "        \n",
    " <li><span style=\"font-size:1.1em; font-family:Arial\">In Bayes' rule, the evidence $P(\\mathcal{D}|M_j)$ is difficult to compute</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">MCMC: Simulate a Markov chain with stationary probability equal to the target distribution $p(\\boldsymbol{x})$.</span></li>\n",
    "    <br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\"><b>Markov chain:</b> A stochastic process where the system moves between a sequence of states $(\\boldsymbol{x}^{(1)},...,\\boldsymbol{x}^{(t)},\\boldsymbol{x}^{(t+1)})$ with a specified transition probability.\n",
    "    \n",
    "<ul>    \n",
    "<li>$\\mathbb{p}(\\boldsymbol{x}^{(t+1)}|\\boldsymbol{x}^{(t)})$: Probability of transitioning from the state $\\boldsymbol{x}^{(t)}$ at iteration $t$ to the state $\\boldsymbol{x}^{(t+1)}$ at the next iteration $t+1$.</li>\n",
    "<li>$\\mathbb{p}(\\boldsymbol{x}^{(t+1)}|\\boldsymbol{x}^{(t)})$: depends only on state $\\boldsymbol{x}^{(t)}$.</li>\n",
    "</ul>\n",
    "<br></br>    \n",
    "    <span style=\"font-size:1.1em; font-family:Arial\"><b>Stationary probability:</b> The long-run probability $p(\\boldsymbol{x})$ that the chain is in state $\\boldsymbol{x}$. \n",
    "     <br></br>\n",
    "     <br></br>\n",
    "     \n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\"><b>Markov chain:</b> A stochastic process where the system moves between a sequence of states $(\\boldsymbol{x}^{(1)},...,\\boldsymbol{x}^{(t)},\\boldsymbol{x}^{(t+1)})$ with a specified transition probability.\n",
    "    \n",
    "<ul>    \n",
    "<li>$\\mathbb{p}(\\boldsymbol{x}^{(t+1)}|\\boldsymbol{x}^{(t)})$: Probability of transitioning from the state $\\boldsymbol{x}^{(t)}$ at iteration $t$ to the state $\\boldsymbol{x}^{(t+1)}$ at the next iteration $t+1$ .</li>\n",
    "<li>$\\mathbb{p}(\\boldsymbol{x}^{(t+1)}|\\boldsymbol{x}^{(t)})$: depends only on state $\\boldsymbol{x}^{(t)}$.</li>\n",
    "</ul>\n",
    "<br></br>    \n",
    "    <span style=\"font-size:1.1em; font-family:Arial\"><b>Stationary probability:</b> The long-run probability $p(\\boldsymbol{x})$ that the chain is in state $\\boldsymbol{x}$. \n",
    "     <br></br>\n",
    "     <br></br>\n",
    "     <span style=\"font-size:1.0em; font-family:Arial\"><b>Ingredients</b></span>\n",
    "     <ol style=\"margin-top:0px\">\n",
    "    <li>Start from an initial state $\\boldsymbol{x}^{(0)}$.</li>\n",
    "    <li>Specify a transition probability to sample $\\boldsymbol{x}^{(t+1)}$ from $\\boldsymbol{x}^{(t)}$.</li>\n",
    "    <li>Transition probability must satisfy the condition that as  $t\\rightarrow \\infty$, the stationary probability of $\\boldsymbol{x}\\rightarrow p(\\boldsymbol{x})$.</li>\n",
    "    </ol>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo/Sampling</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Metropolis-Hastings (MH)</b></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">MH generates a chain of states $\\boldsymbol{x}$ from $p(\\boldsymbol{x})$ based on the following idea:</span> \n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Draw a candidate state $\\boldsymbol{x}^{(*)}$ from some arbitrary proposal distribution $q(\\boldsymbol{x}^{(*)}|\\boldsymbol{x}^{(t)})$</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Accept the candidate $(\\boldsymbol{x}^{(t+1)}=\\boldsymbol{x}^{(*)})$ with probability:</span></li>\n",
    "    \\begin{align*}\n",
    "        & \\alpha(\\boldsymbol{x}^{(*)}, \\boldsymbol{x}^{(t)})=\\min\\bigg(1, \\frac{p(\\boldsymbol{x}^{(*)})q(\\boldsymbol{x}^{(t)}|\\boldsymbol{x}^{(*)})}{p(\\boldsymbol{x}^{(t)})q(\\boldsymbol{x}^{(*)}|\\boldsymbol{x}^{(t)})} \\bigg),\\text{ otherwise reject, i.e.,} \\ (\\boldsymbol{x}^{(t+1)}=\\boldsymbol{x}^{(t)})\n",
    "    \\end{align*}\n",
    "    <br></br>\n",
    "</ul>\n",
    "\n",
    " \n",
    "<span style=\"font-size:1.1em; font-family:Arial\">In practice, in order to accept and reject the proposed candidates with the probability $\\alpha$ we:</span> \n",
    "\n",
    "<ol style=\"margin-top:0px\">\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\"><li>Draw a random number $u \\in [0,1]$.</li></span>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\"><li>Compare $u$ to the ratio $\\alpha$</li></span>    \n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">if $u \\le \\alpha$, then the proposed candidate $\\boldsymbol{x}^{(*)}$ is accepted. Otherwise $\\boldsymbol{x}^{(*)}$ is rejected</span>\n",
    "</ol>\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo/Sampling</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Random walk Metropolis</b></span> \n",
    "\n",
    "<ul>\n",
    "   <li><span style=\"font-size:1.3em; font-family:Arial\">The proposal distribution $q(\\cdot)$ is symmetric $q(\\boldsymbol{x}^{(t)}|\\boldsymbol{x}^{(*)})=q(\\boldsymbol{x}^{(*)}|\\boldsymbol{x}^{(t)})$. <span></li>  \n",
    "       <li><span style=\"font-size:1.3em; font-family:Arial\">$\\alpha(\\boldsymbol{x}^{(*)},\\boldsymbol{x}^{(t)})=\\min\\bigg(1, \\frac{p(\\boldsymbol{x}^{(*)})}{p(\\boldsymbol{x}^{(t)})} \\bigg)$<span></li>    \n",
    "    </ul>\n",
    "    <br></br>  \n",
    "\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\">A common choice is $q \\sim \\mathcal{N}(\\boldsymbol{x}^{(t)},\\Sigma)$</span>\n",
    "    <br></br>\n",
    " <ul>\n",
    "        <li><span style=\"font-size:1.3em; font-family:Arial\"> $\\boldsymbol{x}^{(*)}=\\boldsymbol{x}^{(t)}+\\epsilon, \\ \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$</span></li>\n",
    "    </ul>\n",
    "    <br></br>\n",
    "</ul>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo/Sampling</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Proposal density selection</b></span> \n",
    "\n",
    "\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\">A common choice is $q \\sim \\mathcal{N}(\\boldsymbol{x}^{(t)},\\Sigma)$</span>\n",
    "    <br></br>\n",
    "<ul>\n",
    "<li><span style=\"font-size:1.3em; font-family:Arial\"> $\\boldsymbol{x}^{(*)}=\\boldsymbol{x}^{(t)}+\\epsilon, \\ \\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$</span></li>\n",
    "    </ul>\n",
    "    <br></br>\n",
    "</ul>\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\">Large $\\sigma^2$</span>\n",
    "<ul style=\"margin-top:0px\">\n",
    "    <li>Low correlation between samples.</li>\n",
    "    <li>High rejection</li>\n",
    "</ul>\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\">Small $\\sigma^2$</span>\n",
    "<ul style=\"margin-top:0px\">\n",
    "    <li>High correlation between samples </li>\n",
    "    <li>Low rejection</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\">A <span style=\"color:blue;\">badly</span> chosen proposal distribution significantly affects the MCMC performance </span>\n",
    "    <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo/Sampling</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Affine Invariant Ensemble Sampler (Stretch)</b></span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Stretch is invariant to affine transformation of the target distribution. The algorithm simultaneously runs an ensemble of Markov chains, where each chain is called a walker.</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">The affine invariance property stems from the so-called strech move: Randomly select a walker $\\boldsymbol{x}_t^{(t)}$ from the set of walkers, excluding the current walker $\\boldsymbol{x}_i^{(t)}, (i \\ne j)$</span>></li>\n",
    "    \\begin{align*}\n",
    "        & \\boldsymbol{x}_i^{(*)}=\\boldsymbol{x}_i^{(t)}+Q(\\boldsymbol{x}_j^{(t)}-\\boldsymbol{x}_i^{(t)}), \\ \\text{where} \\ Q \\sim p(z)=\\bigg\\{\n",
    "        \\begin{matrix}\n",
    "        \\frac{1}{\\sqrt{z}(2\\sqrt{\\alpha}-\\frac{2}{\\sqrt{a}})}, z \\in [\\frac{1}{a},a]\\\\\n",
    "        0, \\quad \\text{otherwise}\n",
    "        \\end{matrix}\n",
    "        \\\\\n",
    "        & \\alpha(\\boldsymbol{x}^{(*)},\\boldsymbol{x}^{(t)},z)=\\min\\bigg(1, z^{M-1}\\frac{p(\\boldsymbol{x}^{(*)})}{p(\\boldsymbol{x}^{(t)})} \\bigg)\n",
    "    \\end{align*}\n",
    "    <br></br>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">The algorithm requires the tuning of parameter $\\alpha$ (usually taken $\\alpha=2$)</span>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo/Sampling</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Delayed Rejection Adaptive Metropolis (DRAM)</b></span>\n",
    "\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">DRAM combines <span style=\"color:blue;\">adaptive Metropolis</span> samplers and <span style=\"color:blue;\">delaying rejection</span> (DR).</span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">A candidate sample $\\boldsymbol{x}^{(*)}$ is generated from $q_1(\\cdot)$</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">The basic idea of DR is that, upon rejection with probability $\\alpha_1(\\boldsymbol{x}^{(*)},\\boldsymbol{x}^{(t)})$ in a MH, instead of advancing time and retaining the current position (i.e., $\\boldsymbol{x}^{(t+1)}=\\boldsymbol{x}^{(t)}$), a second candidate $\\boldsymbol{x}^{(**)}$ is generated from $q_2(\\cdot)$.</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">$\\boldsymbol{x}^{(**)}$ is allowed to depend not only on the current position of the chain but also on what we just proposed and rejected</span></li>\n",
    "    <br></br>\n",
    "</ul>\n",
    "\n",
    "\\begin{align*}\n",
    "        & \\alpha(\\boldsymbol{x}^{(t)}, \\boldsymbol{x}^{(*)},\\boldsymbol{x}^{(**)})=        \n",
    "        min\\bigg(1, \\frac{p(\\boldsymbol{x}^{(**)})}{p(\\boldsymbol{x}^{(t)})}\n",
    "        \\frac{q_1(\\boldsymbol{x}^{(**)},\\boldsymbol{x}^{(*)})}{q_1(\\boldsymbol{x}^{(t)},\\boldsymbol{x}^{(*)})}\n",
    "        \\frac{q_2(\\boldsymbol{x}^{(**)},\\boldsymbol{x}^{(*)},\\boldsymbol{x}^{(t)})}{q_1(\\boldsymbol{x}^{(t)},\\boldsymbol{x}^{(*)},\\boldsymbol{x}^{(**)})}\n",
    "        \\frac{[1-a_1(\\boldsymbol{x}^{(**)},\\boldsymbol{x}^{(*)})]}{[1-a_1(\\boldsymbol{x}^{(t)},\\boldsymbol{x}^{(*)})]}\n",
    "        \\bigg)\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo/Convergence</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\">In practice, we need metrics to help us decide whether convergence to the posterior distribution is achieved.</span>\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Acceptance rate</span></li>\n",
    "    <ul>\n",
    "        <li>High acceptance rate usually associated with highly correlated distributions</li>\n",
    "    </ul>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Burn-in period</span></li>       \n",
    "    <ul>\n",
    "        <li>Initial samples may not follow the posterior stationary distribution and may need to be discarded</li>\n",
    "    </ul>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Diagnostics</span></li>           \n",
    "    <ul>\n",
    "        <li>Other diagnostics exist, for example the effective sample size</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\texttt{MCMC}$ class of $\\texttt{SampleMethods}$ module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Import the MCMC sampling algorithm\n",
    "from UQpy.sampling.mcmc.ModifiedMetropolisHastings import ModifiedMetropolisHastings\n",
    "import numpy as np\n",
    "\n",
    "# Define the target distribution\n",
    "def log_Rosenbrock(x):\n",
    "     return (-(100*(x[:, 1]-x[:, 0]**2)**2+(1-x[:, 0])**2)/20)\n",
    "\n",
    "x0 = ModifiedMetropolisHastings(dimension=2, burn_length=0, jump=1, nsamples=5000, n_chains=10, log_pdf_target=log_Rosenbrock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 6)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x0.samples[:, 0], x0.samples[:, 1], linestyle='none', marker='.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the proposal distributions\n",
    "\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "from UQpy.distributions import Normal\n",
    "proposal = [Normal(), Normal()]\n",
    "proposal_is_symmetric = [False, False]\n",
    "\n",
    "x1 = ModifiedMetropolisHastings(dimension=2, burn_length=500, jump=10, nsamples=500, log_pdf_target=log_Rosenbrock, \n",
    "                                proposal=proposal, proposal_is_symmetric=proposal_is_symmetric, n_chains=1)\n",
    "print(x1.acceptance_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "ax.plot(x1.samples[:, 0], x1.samples[:, 1], linestyle='none', marker='.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Markov Chain Monte Carlo</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\texttt{UQpy}$ includes several MCMC algorithms such as \n",
    "<ul>\n",
    "    <li>Metropolis-Hastings ($\\texttt{MetropolisHastings}$)</li>\n",
    "    <li>Component-wise modified Metropolis-Hastings ($\\texttt{ModifiedMetropolisHastings}$)</li>\n",
    "    <li>Delayed Rejection Adaptive Metropolis ($\\texttt{DRAM}$)</li>\n",
    "    <li>Differential Evolution Adaptive Metropolis ($\\texttt{DREAM}$)</li>\n",
    "    <li>Affine Invariance Ensemble  sampler with stretch moves ($\\texttt{Stretch}$)</li>\n",
    "</ul>\n",
    "\n",
    "Additional MCMC algorithms in development\n",
    "<ul>\n",
    "    <li>Transitional Markov Chain Monte Carlo</li>\n",
    "    <li>Parallel tempered Markov Chain Monte Carlo</li>\n",
    "    <li>Hamiltonian Monte Carlo</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Bayes' Theorem</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### <br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><b>Bayes' Theorem:</b> The posterior probability of event $H$ is proportional to the likelihood of event $D$ given $H$ times the prior probability of event $H$.</span> \n",
    "\n",
    "\\begin{align*}\n",
    "    & P(H|D) \\propto P(D|H) \\times P(H)\n",
    " \\end{align*}\n",
    " <br></br>\n",
    " \n",
    "<ol>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">The <b>prior probability</b> of event $H$ represents our knowledge (or lack thereof), belief, or intuition about $H$ before we collect information (data).</span> \n",
    "</li>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">The <b>likelihood</b> is probability of observing $D$ given that $H$ is true/ has occurred.</span></li>\n",
    "    <ul>\n",
    "        <li>The likelihood expresses the impact of the data on the prior probability</li>\n",
    "    </ul>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">The <b>posterior probability</b> is the probability of event $H$ after having observed $D$.</span></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Inference on probability models</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from UQpy.Distributions import Gamma\n",
    "data = Gamma(a=2, loc=0, scale=2).rvs(nsamples=500, random_state=12)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Define the models to be compared, for each model one must create an instance of the model class\n",
    "from UQpy.Distributions import Gamma, Exponential, ChiSquare\n",
    "from UQpy.Inference import InferenceModel, InfoModelSelection\n",
    "m0 = InferenceModel(dist_object=Gamma(a=None, loc=None, scale=None), nparams=3, name='gamma')\n",
    "m1 = InferenceModel(dist_object=Exponential(loc=None, scale=None), nparams=2, name='exponential')\n",
    "m2 = InferenceModel(dist_object=ChiSquare(df=None, loc=None, scale=None), nparams=3, name='chi-square')\n",
    "\n",
    "candidate_models = [m0, m1, m2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Perform model selection using different information criteria\n",
    "criteria = ['BIC', 'AIC', 'AICc']\n",
    "for criterion in criteria:\n",
    "    selector = InfoModelSelection(candidate_models=candidate_models, data=data, criterion=criterion)\n",
    "    selector.run(nopt=5)\n",
    "    selector.sort_models()\n",
    "    print('Sorted model using '+criterion+' criterion: '+', '.join(\n",
    "        m.name for m in selector.candidate_models))\n",
    "    if criterion == 'BIC':\n",
    "        criterion_value = selector.criterion_values\n",
    "        sorted_names = [m.name for m in selector.candidate_models]\n",
    "        param = [m.mle for m in selector.ml_estimators]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Example from MSEE on Parameter Estimation</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Vinet Model</b></span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.3em; font-family:Arial\"> Cold EOS for solid Carbon phase</span></li>\n",
    "</ul>\n",
    "\n",
    "\\begin{align*}\n",
    "    & E_{cold}(V)=\\phi_0+\\frac{4V_0B_0}{(B'-1)^2}[1-(1+X)e^{-X}] \\\\\n",
    "    & X= \\frac{3}{2}(B'-1)\\bigg[ \\bigg( \\frac{V}{V_0} \\bigg)^{1/3}-1 \\bigg]\n",
    "\\end{align*}\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"font-size:0.8em; font-family:Arial\">$V_0[Angstrom^3 /atom]$ - Equilibrium Volume</span>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"font-size:0.8em; font-family:Arial\">$B_0[GPa]$ - Bulk modulus at $V_0$</span>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"font-size:0.8em; font-family:Arial\">$B'[unitless]$ - Pressure derivative of bulk modulus at $V_0$</span>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"font-size:0.8em; font-family:Arial\">$\\phi_0$[eV / atom] - Internal energy at $V_0$</span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.3em; font-family:Arial\">Infer Vinet model parameters from data</span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"./photos/VinetModel_1.png\" width=\"900\"> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Example of Bayes Parameter Estimation</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<ul style=\"margin-top:40px\">\n",
    "    <li><span style=\"font-size:1.3em; font-family:Arial\">Vinet parameters from fitted data</span></li>\n",
    "</ul>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"./photos/VinetModel_2.png\" width=\"700\"> \n",
    "</div>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.3em; font-family:Arial\">Nominal parameters</span></li>\n",
    "    <br></br>\n",
    "    <ul>\n",
    "        <li>Estimate parameter uncertainty of Vinet Model</li>\n",
    "        <br></br>\n",
    "        <li>Bayesian inference of parameters in diamond phase</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<ul style=\"margin-top:40px\">\n",
    "    <li><span style=\"font-size:1.3em; font-family:Arial\">Diamond phase </span></li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"./photos/VinetModel_3.png\" width=\"1500\"> \n",
    "</div>\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "rise": {
   "autolaunch": true,
   "backimage": "./photos/MseeBackground.png",
   "enable_chalkboard": true,
   "height": "90%",
   "reveal_shortcuts": {
    "chalkboard": {
     "clear": "ctrl-k"
    }
   },
   "width": "90%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
