{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>MSEE Short course on UQ</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Introduction</b></span>\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Uncertainty quantification:</b> Why surrogate models ?</span>\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Polynomials chaos</b></span>\n",
    "<ul style=\"margin-top:0px;\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">PCE basis</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Computing the coefficients</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Post-processing</span></li>    \n",
    "</ul>\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Kriging (a.k.a. Gaussian process)</b></span>\n",
    "<ul style=\"margin-top:0px;\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Adaptive Kriging methods</span></li>\n",
    "    <ul style=\"margin-top:0px;\">\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">AKMCS</span></li>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">EGO</span></li>        \n",
    "    </ul>\n",
    "</ul>    \n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Global framework for UQ</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<div align=\"center\">\n",
    "  <img src=\"./photos/Day1_6.png\" width=\"2000\"> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Uncertainty propagation using Monte Carlo simulation</b></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><b>Principle:</b> Generate <span style=\"color:blue;\">realizations</span> of the system using <span style=\"color:blue;\">random numbers.</span></span>\n",
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">A sample set $\\textbf{X}=\\{\\mathbf{x}_1,...,\\mathbf{x}_N \\}$ (i.e., <span style=\"color:blue;\">experimental design</span>) is drawn according to the (joint) probability distribution of the input $f_\\textbf{X}$, where $\\boldsymbol{x}_1=[X_1,..., X_M]$.</span></li>\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">For each sample $\\boldsymbol{x}_i$, with $i=1,...,N$, the response $\\mathcal{M}(\\boldsymbol{x}_i)=Υ_i$ is evaluated</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">The set of responses $\\mathbf{Y}=\\{ Υ_1,...,Υ_N \\}$ is used to estimate the <span style=\"color:blue;\">moments, distribution</span> or perform <span style=\"color:blue;\">reliability analysis.</span></span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Usually, $N$ needs to be very <span style=\"color:blue;\">large</span> ($N \\sim 10^6$).</span></li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Surrogate models for uncertainty quantification</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"margin-top:20px\">\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">A <span style=\"color:blue;\">surrogate model</span> $\\tilde{\\mathcal{M}}$ is an <span style=\"color:blue;\">approximation</span> of the original model $\\mathcal{M}$, with the following features:</span></li>\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">It is built from a <span style=\"color:blue;\">small</span> number $n \\ll N$ of runs of model $\\mathcal{M}$. </span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Learn input-output <span style=\"color:blue;\">mappings</span> from <span style=\"color:blue;\">training data</span> $\\{ \\boldsymbol{x}_i, Υ_i \\}^n_{i=1}$</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\n",
    "    \">For regression purposes, we assume that $\\mathcal{M}(\\boldsymbol{x})$ is a <span style=\"color:blue;\">continuous</span> field.</span></li>\n",
    "</ul>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"./photos/Day2_slide4.png\" width=\"1200\"> \n",
    "</div>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Ingredients for building a surrogate model</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Select an <span style=\"color:blue;\">experimental design</span> $\\mathbf{X}=\\{ \\boldsymbol{x}_1,...,\\boldsymbol{x}_N \\}$that covers efficiently the input space, i.e., <span style=\"color:blue;\">Latin hypercube sampling (LHS)</span></span></li>\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Run the computational model $\\mathcal{M}$ using <span style=\"color:blue;\">Monte Carlo simulation</span>.</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Learn the training data $\\{ \\boldsymbol{x}_i, Υ_i \\}^n_{i=1}$</span></li>\n",
    "</ul>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"./photos/Day2_slide5.png\" width=\"1200\"> \n",
    "</div>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Advantages and disadvantages</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>What we gain</u></span>\n",
    "\n",
    "\\begin{align*}\n",
    "     \\mathcal{M}(\\boldsymbol{x}) & \\sim \\tilde{\\mathcal{M}}(\\boldsymbol{x})\\\\\n",
    "     \\color{red}{\\text{Hours} \\ \\text{per} \\ \\text{run}} & \\color{green}{\\quad \\ll \\text{Seconds} \\ \\text{per}  \\ \\text{run}}\n",
    " \\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>Advantages</u></span>\n",
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">Non-intrusive methods:</span> based on runs of the computational model using Monte Carlo simulation</span></li>\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">High-performance computing: </span>\"Embarrassingly parallel\"</span></li>\n",
    "  <br></br>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>Disadvantages</u></span>\n",
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">Validation:</span> Need for rigorous validation</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">Assumptions:</span> Typically makes strong assumptions about smoothness of the input - output relation</span></li>\n",
    "    <br></br>\n",
    "  <br></br>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Polynomial Chaos expansion</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "- <span style=\"font-size:1.1em; font-family:Arial\">Given the input random vector $\\boldsymbol{X} \\ (\\text{dim} \\ \\boldsymbol{X}=M)$ with joint probability density function (PDF):</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & f_\\boldsymbol{X}=\\prod_{i=1}^Mf_{X_i}(x_i)\\\\\n",
    " \\end{align*}\n",
    " \n",
    "- <span style=\"font-size:1.1em; font-family:Arial\">If the random output $Υ=\\mathcal{M}(\\boldsymbol{X})$ has finite variance, then it can be cast as a <span style=\"color:blue;\">Polynomial chaos expansion</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & Υ = \\sum_{\\boldsymbol{\\alpha} \\in \\mathbb{N}^M} \\color{purple}{y_{\\boldsymbol{\\alpha}}}\\color{orange}{\\Psi_{\\boldsymbol{\\alpha}}(\\mathbf{X})}\\\\\n",
    " \\end{align*}\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">where</span>\n",
    " - $\\color{orange}{\\Psi_{\\boldsymbol{\\alpha}}(\\textbf{X})}$: <span style=\"font-size:1.1em; font-family:Arial\"> <span style=\"color:blue;\">multivariate polynomials</span>, orthonormal with respect to $f_\\boldsymbol{X}$</span>\n",
    " - $\\color{purple}{y_{\\boldsymbol{\\alpha}}}$: <span style=\"font-size:1.1em; font-family:Arial\">coefficients to be computed</span> \n",
    " - $\\boldsymbol{\\alpha}=(\\alpha_1, \\alpha_2,...\\alpha_M)$, where $a_i \\in \\mathbb{N}$\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Multivariate polynomial basis</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">Univariate polynomials:</span> For each random variable $X_i$, univariate orthonormal polynomials $\\{ P_k^{(i)}, k \\in \\mathbb{N}\\}$ are built:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\langle P_j^{(i)}(x_i),P_k^{(i)}(x_i) \\rangle =\\int P_j^{(i)}(x_i) P_k^{(i)}(x_i) f_{X_i}(x_i)\n",
    "du =\\delta_{jk} \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.0em; font-family:Arial\">e.g. <span style=\"color:purple;\">Hermite:</span> Used when $X_i \\sim \\mathcal{N}(0,1)$, <span style=\"color:purple;\">Legendre:</span> Used when $X_i \\sim \\mathcal{U}(-1,1)$</span>\n",
    "\n",
    "\n",
    "<span style=\"color:blue; font-size:1.1em; font-family:Arial\">Tensor product construction:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{x})=\\prod_{i=1}^M P_{a_i}^{(i)}(x_i), \\qquad \\mathbb{E}[\\Psi_\\boldsymbol{\\alpha}(\\boldsymbol{x})\\Psi_\\boldsymbol{{\\beta}}(\\boldsymbol{x})]=\\delta_{\\boldsymbol{\\alpha} \\boldsymbol{\\beta}}, \\quad \\text{for} \\quad \\boldsymbol{\\alpha}, \\boldsymbol{\\beta} \\in \\mathbb{N}^M  \\end{align*}\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Multivariate polynomial basis</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.3em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Exact PCE</b></span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & Υ = \\sum_{\\boldsymbol{\\alpha} \\in \\mathbb{N}^M}y_{\\boldsymbol{\\alpha}}\\Psi_{\\boldsymbol{\\alpha}}(\\mathbf{X})\\\\\n",
    " \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.3em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Basis truncation</b></span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & |\\boldsymbol{\\alpha}|=\\sum_{i=1}^M a_i \n",
    "    \\end{align*}\n",
    "    \n",
    "\\begin{align*}\n",
    "    & \\mathcal{A}^{M, p}=\\{\\boldsymbol{\\alpha} \\in \\mathbb{R}^M: |\\boldsymbol{\\alpha}| \\leq p \\}\n",
    "    \\end{align*}\n",
    "    \n",
    "    \n",
    "\\begin{align*}\n",
    "& \\text{card}~\\mathcal{A}^{M, p}\\equiv P= \\binom{M+p}{p}=\\frac{(M+p)!}{M!p!}\n",
    "\\end{align*}\n",
    "<br></br>\n",
    "\n",
    "This leads to the truncated approximate expansion\n",
    "\n",
    "\\begin{align*}\n",
    "    & Υ \\approx \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}^{M, p}} y_{\\boldsymbol{\\alpha}}\\Psi_{\\boldsymbol{\\alpha}}(\\mathbf{X})\\\\\n",
    " \\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Computing the coefficients</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>Least-square minimization</u></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">The exact (infinite) series expansion is considered as the sum of a <span style=\"color:blue;\">truncated series</span> and a <span style=\"color:blue;\">residual:</span></span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & Υ=\\mathcal{M}(\\boldsymbol{x})=\\sum_{\\alpha \\in \\mathcal{A}^{M, p}}y_{\\alpha} \\Psi_{\\alpha}(\\boldsymbol{x})+\\epsilon_p \\equiv (\\mathbf{Y}^T \\Psi(\\boldsymbol{x})+\\epsilon_p(\\boldsymbol{x}))\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\mathbf{Y}=\\{ y_{\\alpha}, \\alpha \\in \\mathcal{A}^{M, p} \\} \\equiv \\{ y_0,..., y_{P-1} \\} \\qquad (\\text{P} \\ \\text{unknown} \\ \\text{coefficients}.)\\\\\n",
    "    & \\Psi(\\boldsymbol{x})=\\{ \\Psi_0(\\boldsymbol{x}),...,\\Psi_{P-1}(\\boldsymbol{x}) \\}\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">The unknown coefficients are estimated by minimizing the mean square residual error:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    \\hat{\\mathbf{Y}}=\\mathbb{E}[\\epsilon_p(\\boldsymbol{x})]\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\hat{\\textbf{Y}}=\\text{argmin}~ \\frac{1}{n}\\sum_{i=1}^n(\\mathbf{Y}^T \\Psi (\\boldsymbol{x}_i)-\\mathcal{M}(\\boldsymbol{x}_i))^2, \\ \\textbf{Y} \\in \\mathbb{R}^P\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Computing the coefficients</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>Ordinary least-square minimization</u></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">An average of the mean square error is minimized (over $n$ training samples)</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\hat{\\textbf{Y}}=\\text{argmin}~ \\frac{1}{n}\\sum_{i=1}^n(\\mathbf{Y}^T \\Psi (\\boldsymbol{x}_i)-\\mathcal{M}(\\boldsymbol{x}_i))^2, \\ \\textbf{Y} \\in \\mathbb{R}^P\n",
    "    \\end{align*}\n",
    "    \n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Steps:</span>\n",
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Gather the training data in matrix $\\mathbf{B}=\\{\\mathcal{M}(\\boldsymbol{x}_1),...,\\mathcal{M}(\\boldsymbol{x}_n) \\}$</span></li>\n",
    "      <li><span style=\"font-size:1.1em; font-family:Arial\">Select a truncation scheme, e.g., $\\mathcal{A}^{M,p}=\\{ \\boldsymbol{\\alpha}\\in \\mathbb{N}^M |\\boldsymbol{\\alpha}| \\le p \\}$</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Compute the matrix: $\\mathbf{A}_{ij}=\\Psi_j(\\boldsymbol{x}_i)$</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Solve the system: $\\hat{\\mathbf{Y}}=(\\mathbf{A}^\\intercal\\mathbf{A})^{-1}\\mathbf{A}^\\intercal\\mathbf{B}$</span></li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Computing the error</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Relative generalization error:\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\epsilon=\\mathbb{E}\\bigg[\\big(\\mathcal{M}(\\boldsymbol{x})-\\mathcal{M}^{PC}(\\boldsymbol{x})\\big)^2\\bigg]/\\text{Var}[Y] \\qquad \\text{where} \\qquad  \\mathcal{M}^{PC}(\\boldsymbol{x})=\\sum_{\\alpha \\in \\mathcal{A}^{M,p}}y_{\\alpha}\\Psi_{\\alpha}(\\mathbf{X})\n",
    "    \\end{align*}\n",
    "- Validation error:\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\epsilon_{val}=\\frac{N-1}{N}\\bigg[\\frac{\\sum_{i=1}^n\\big(\\mathcal{M}(\\boldsymbol{x}_i)-\\mathcal{M}^{PC}(\\boldsymbol{x}_i)\\big)^2}{\\sum_{i=1}^n\\big(\\mathcal{M}(\\boldsymbol{x}_i)-\\frac{1}{N}\\sum_{i=1}^N \\mathcal{M}(\\boldsymbol{x}_i)\\big)^2}\\bigg]\n",
    "    \\end{align*}    \n",
    "- Leave-one-out (LOO) cross validation error:\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\epsilon_{LOO}=\\frac{1}{N}\\frac{\\sum_{i=1}^n\\bigg(\\frac{\\mathcal{M}(\\boldsymbol{x}_i)-\\mathcal{M}^{PC}(\\boldsymbol{x}_i)}{1-h_i}\\bigg)^2}{\\sum_{i=1}^N\\big(\\mathcal{M}(\\boldsymbol{x}_i)-\\frac{1}{N}\\sum_{i=1}^N \\mathcal{M}(\\boldsymbol{x}_i)\\big)^2}\n",
    "    \\end{align*}\n",
    "where $h_i$ is the $i_{th}$ diagonal term of matrix: $\\mathbf{A}(\\mathbf{A}^\\intercal\\mathbf{A})^{-1}\\mathbf{A}^\\intercal$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Example</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Consider we have one random variable $X_1 \\sim \\mathcal{U}(0,10)$</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from UQpy.distributions import Uniform\n",
    "from UQpy.surrogates.polynomial_chaos.polynomials.TotalDegreeBasis import TotalDegreeBasis\n",
    "from UQpy.surrogates.polynomial_chaos.PolynomialChaosExpansion import PolynomialChaosExpansion\n",
    "from UQpy.surrogates.polynomial_chaos.regressions.LeastSquareRegression import LeastSquareRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Define the function to interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def function(x):                                \n",
    "    return x*np.sin(x)/10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Create a distribution object, generate training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "dist = Uniform(loc=0, scale=10)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Example</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Generate our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "n_samples = 30    \n",
    "x = dist.rvs(n_samples)  \n",
    "y = function(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x, y, c='r')\n",
    "plt.grid(True)\n",
    "plt.title('Training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Example</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the maximum order of the polynomials\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree = 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the polynomial basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_basis = TotalDegreeBasis(dist, max_degree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a least squares regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares = LeastSquareRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Example</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a PCE object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pce = PolynomialChaosExpansion(polynomial_basis=polynomial_basis, regression_method=least_squares)\n",
    "pce.fit(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test data and predict response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = dist.rvs(100)\n",
    "x_test.sort(axis=0) \n",
    "y_test = pce.predict(x_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_test, y_test, 'g', label='PCE predictor - OLS')\n",
    "plt.scatter(x, y, c='r', label='training data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Post-processing</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>Statistical moments</u></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Due to the <span style=\"color:blue;\">orthnormality</span> of the basis functions, i.e. $\\mathbb{E}[\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{x})\\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{x})]=\\delta_{\\boldsymbol{\\alpha \\beta}}$, and the fact that $\\mathbb{E}[\\Psi_{\\boldsymbol{\\alpha \\ne 0}}(\\boldsymbol{x})]=\\boldsymbol{0}$, the first two statistical moments are:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\color{blue}{\\text{Mean:}} \\ \\ \\mu_{\\tilde{{Y}}}=y_0 \\\\\n",
    "    & \\color{blue}{\\text{Variance:}} \\ \\ \\sigma^2_{\\tilde{Y}}=\\sum_{\\alpha \\in \\mathcal{A}\\setminus 0}y_{\\alpha}^2\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\">The PCE can be used as a <span style=\"color:blue;\">response surface</span> for predicting the respone of the model</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\tilde{{Y}}(\\boldsymbol{x})=\\sum_{\\alpha \\in \\mathcal{A}}y_{\\alpha} \\Psi_{\\alpha}(\\boldsymbol{x})\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">and the PDF of the response is estimated by Monte Carlo simulation on the response surface</span>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "n_mc = 1000000\n",
    "x_mc = dist.rvs(n_mc)  \n",
    "y_mc = function(x_mc)  \n",
    "mu = np.mean(y_mc)\n",
    "\n",
    "print('Moments from least squares regression :', pce.get_moments())\n",
    "print('Moments from Monte Carlo integration: ', \t(round((1/n_mc)*np.sum(y_mc),6), \t    \t\t round((1/n_mc)*np.sum((y_mc-mu)**2),6)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Post-processing</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><u>Sensitivity</u></span>\n",
    "\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><span style=\"color:blue;\" >High Dimensional Model Representation (HDMR)</span>*:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\mathcal{M}(\\boldsymbol{x})=\\mathcal{M}_0+ \\sum_{i=1}^M \\mathcal{M}_{i}(X_{i}) + \\sum_{i\\leq j <M} \\mathcal{M}_{ij}(X_{i}, X_j) +  \\mathcal{M}_{12...M}(\\mathbf{X})\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    " \\begin{align*}\n",
    "    & \\mathcal{M}(\\boldsymbol{x})=\\mathcal{M}_0+ \\sum_{ \\mathbf{u} \\neq 0}\\mathcal{M}_{\\mathbf{u}}(\\boldsymbol{x}_{\\mathbf{u}})\n",
    "    \\end{align*}\n",
    "  \n",
    " <span style=\"font-size:1.3em; font-family:Arial\">where</span> \n",
    " \n",
    " \\begin{align*}\n",
    " \\mathbf{u} = [i_1, \\ldots, i_s]\\subset \\{1,...,M \\}\n",
    "     \\end{align*}\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "*Saltelli A. et al, 2008, Global Sensitivity Analysis. The primer\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Post-processing</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><u>Variance decomposition</u></span>\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    & D = \\text{Var}[\\mathcal{M}(\\boldsymbol{x})]=\\sum_{\\mathbf{u} \\neq 0} D_{\\mathbf{u}}\n",
    "    \\end{align*}\n",
    "\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\">where</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & D_{\\mathbf{u}} = \\text{Var}[\\mathcal{M}_{\\mathbf{u}}(\\boldsymbol{x}_{\\mathbf{u}})]\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><u>Sobol' indices</u></span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\color{blue}{\\text{First}} \\ \\text{order}: S_{\\mathbf{u}}=\\frac{D_{\\mathbf{u}}}{D} \\\\\n",
    "     & \\color{blue}{\\text{Total}} \\ \\text{order}: S_{i}^T=\\sum_{\\mathbf{u} \\supset i} \\frac{D_{\\mathbf{u}}}{D}\n",
    "    \\end{align*}\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Post-processing</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><span style=\"color:blue;\">HDMR</span>* of a PCE is obtained by re-ordering the terms of the truncated PC expansion</span>\n",
    "\n",
    "\n",
    "\\begin{align*} \n",
    "    & \\mathcal{M}_{\\mathbf{u}}(\\boldsymbol{x}_{\\mathbf{u}}) =\\sum_{\\alpha \\in \\mathcal{A}_{\\boldsymbol{u}}} y_{\\alpha} \\Psi_{\\alpha}(\\mathbf{X})\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where $\\qquad \\mathcal{A}_{\\boldsymbol{u}}=\\{ \\alpha \\in A: k \\in \\mathbf{u} \\iff \\alpha_k \\ne 0 \\}$</span>\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\hat{D}_{\\mathbf{u}} = \\sum_{\\alpha \\in \\mathcal{A}_{\\mathbf{u}}}y_{\\alpha}^2 , \\quad \\hat{D} = \\sum_{\\alpha \\in \\mathcal{A}\\setminus \\{0\\}} y_{\\alpha}^2\n",
    "    \\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\color{blue}{\\text{First}} \\ \\text{order}: \\ \\hat{S}_{i}=\\frac{\\sum_{\\alpha \\in \\mathcal{A}_i} y_{\\alpha}^2}{\\hat{D}}, \\quad \\mathcal{A}_i=\\{\\alpha \\in \\mathcal{A}: a_i>0, i\\neq j=0\\} \\\\\n",
    "    & \\color{blue}{\\text{Total}} \\ \\text{order}: \\hat{S}_{i}^T= \\frac{\\sum_{\\alpha \\in \\mathcal{A}_{\\mathbf{u}}}y_{\\alpha}^2}{\\hat{D}}, \\quad \\mathcal{A}_i=\\{\\alpha \\in \\mathcal{A}: a_i>0\\}\n",
    "    \\end{align*}\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "*Saltelli A. et al, 2008, Global Sensitivity Analysis. The primer\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Gaussian Process Regression / Kriging</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Assumes that the model output $M(\\mathbf{x})$ is approximated by a Gaussian stochastic process i.e.,</span></li>\n",
    "    \\begin{align*}\n",
    "    & \\tilde{\\mathcal{M}}(\\boldsymbol{x})\\rightarrow \\mathcal{G}\\mathcal{P} (\\mathbf{m},\\boldsymbol{\\Sigma}) \\rightarrow \\mathcal{N}(\\mathbf{m}, \\boldsymbol{\\Sigma})\n",
    "    \\end{align*}\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">It is completely described by its <span style=\"color:blue;\">mean</span> ($\\mathbf{m}(x)$) and <span style=\"color:blue;\">correlation</span> ($\\mathbf{\\Sigma}(x_1, x_2)$) functions $\\mathcal{G}\\mathcal{P} \\rightarrow \\mathcal{G}\\mathcal{P}(\\mathbf{m,\\Sigma})$.</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">It is desribed by the following equation:</span></li>\n",
    "</ul>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\tilde{\\mathcal{M}}(\\boldsymbol{x})=\\boldsymbol{\\phi} (\\mathbf{x})^T \\boldsymbol{\\beta} + \\sigma_z^2 Z(\\boldsymbol{x},\\omega)\n",
    "    \\end{align*}\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where </span>\n",
    "<ul>\n",
    "  <li>$\\boldsymbol{\\phi} (\\boldsymbol{x})^T \\boldsymbol{\\beta} =\\beta_1\\phi_1(\\boldsymbol{x})+...+\\beta_P \\phi_P(\\boldsymbol{x})\\rightarrow \\color{blue}{\\text{trend}}$</li> \n",
    "<ul>\n",
    "    <li> $\\{ \\phi(\\boldsymbol{x}) \\}_{i=1}^P: \\ \\text{basis}  \\ \\text{functions}$</li>\n",
    "    <li>$\\{ \\beta_i \\}_{i=1}^P: \\ \\text{coefficients}$</li>\n",
    "    </ul>\n",
    "<li>$Z(\\boldsymbol{x}, \\omega) \\sim \\rightarrow \\color{blue}{\\text{Gaussian stochastic} \\ \\text{process}}$</li>\n",
    "  <li>$\\sigma_z^2\\rightarrow \\color{blue}{\\text{Variance}}$</li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Interpolation</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=margin-top:40px>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Kriging predicts the model output $\\tilde{\\mathcal{M}}(\\boldsymbol{x})$ for a new point $\\boldsymbol{x}$, given an experimental design $\\mathbf{X}=\\{ \\boldsymbol{x}_1,...,\\boldsymbol{x}_N \\}$ and the corresponding (noise-free) model $\\mathbf{Y}=\\{ Υ_1,...,Υ_N \\}$responses</span></li>\n",
    "    <ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">The Kriging provides a prediction based on the <span style=\"color:blue;\">Gaussian assumption</span>:</li>\n",
    "      <li><span style=\"font-size:1.1em; font-family:Arial\">The vector formed by the prediction $\\tilde{Υ}=\\tilde{\\mathcal{M}}(\\boldsymbol{x})$ and the true model responses $\\mathbf{Y}$, has a joint Gaussian distribution</span></li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\begin{bmatrix}\n",
    "        \\tilde{Υ} \\\\\n",
    "        \\mathbf{Y}\n",
    "    \\end{bmatrix} \\sim \n",
    "    \\mathcal{N} \\bigg(  \n",
    "    \\begin{bmatrix}\n",
    "        \\boldsymbol{\\phi}(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta} \\\\\n",
    "        \\mathbf{F} \\boldsymbol{\\beta}\n",
    "    \\end{bmatrix}, \\sigma_z^2\n",
    "    \\begin{bmatrix}\n",
    "        1 & \\mathbf{r}^\\intercal(\\boldsymbol{x}) \\\\\n",
    "        \\mathbf{r}(\\boldsymbol{x})&  \\mathbf{R}\n",
    "    \\end{bmatrix}\n",
    "    \\bigg)\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where</span>\n",
    "\n",
    "<ul>\n",
    "  <li>$R_{ij}=R(\\boldsymbol{x}_i, \\boldsymbol{x}_j, \\boldsymbol{\\theta}), \\quad i=1,...,N$</li>\n",
    "  <li>$F_{ij}=\\phi(\\boldsymbol{x}_i) \\quad i=1,...,N, \\ j=1,...,P$</li>\n",
    "  <li>$r_{i}=R(\\boldsymbol{x},\\boldsymbol{x}_i, \\boldsymbol{\\theta}) \\quad i=1,...,N$</li>  \n",
    "</ul> \n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Interpolation</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">The mean and the variance of Gaussian random variable $\\tilde{Υ}=\\tilde{\\mathcal{M}}(\\boldsymbol{x})$ conditional on the experimental data $\\mathbf{X}, \\mathbf{Y}$ is given by</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\mu_{\\tilde{Υ}}(\\boldsymbol{x})=\\phi(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta}+\\boldsymbol{r}^\\intercal(\\boldsymbol{x})\\mathbf{R}^{-1}(\\mathbf{Y}-\\mathbf{F}\\hat{\\boldsymbol{\\beta}}) \\\\\n",
    "        & \\sigma^2_{\\tilde{Υ}}=\\sigma^2_{z}\\big(1-\\boldsymbol{r}^\\intercal(\\boldsymbol{x})\\mathbf{R}^{-1}\\boldsymbol{r}(\\boldsymbol{x})+\\mathbf{u}^\\intercal(\\boldsymbol{x})(\\mathbf{F}^\\intercal\\mathbf{R}^{-1}\\mathbf{F})^{-1}\\mathbf{u}(\\mathbf{x})\\big)\n",
    "    \\end{align*}\n",
    "    \n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where</span>\n",
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">$\\hat{\\boldsymbol{\\beta}}$ is a generalized least square estimate of the coefficients.</span></li>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">$\\mathbf{u}(\\boldsymbol{x})=\\mathbf{F}^T\\mathbf{R}^{-1}\\boldsymbol{r}(\\boldsymbol{x})-\\boldsymbol{\\phi}(\\boldsymbol{x})$</span></li>\n",
    "</ul> \n",
    "<br></br>\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">The variance of the prediction at an experimental design point $\\rightarrow 0$ (interpolant with respect to the design points).</span></li>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">$\\mathbb{P}(\\tilde{Υ} \\le t)=\\Phi \\big( \\frac{t-\\mu_{\\tilde{Υ}(\\mathbf{x})}}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})} \\big)$, where $\\Phi$ is the Gaussian cumulative density function</span></li>\n",
    "</ul> \n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Gaussian Process Regression (GPR)</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">In many cases, the observed responses are noisy, i.e.,</span></li>\n",
    "    <br></br>\n",
    "    \\begin{align*}\n",
    "    & Y_1=\\mathcal{M}(\\boldsymbol{x})+\\epsilon, \\ \\text{where} \\ \\epsilon \\sim \\mathcal{N}(0, \\mathbf{\\Sigma}_N)\n",
    "    \\end{align*}\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Three classes of noise exist:</span></li>\n",
    "  <ol>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">$\\color{blue}{\\text{Homogeneous}:}\\mathbf{\\Sigma}_n=\\sigma_n^2\\mathbf{I}$, i.e., Same noise for each observation.</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">$\\color{blue}{\\text{Independent} \\ \\text{heterogeneous}:}\\mathbf{\\Sigma}_n=\\text{diag}(\\sigma^2_n)$, noise different for each observation but, not correlated</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">$\\color{blue}{\\text{General} \\ \\text{heterogeneous}:}$ noise different for each observation, with possible correlations</span></li>\n",
    "  </ol>\n",
    "</ul> \n",
    "\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">The joint Gaussian distribution formed by the prediction and the noise responses is:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\begin{bmatrix}\n",
    "        \\tilde{Υ} \\\\\n",
    "        \\mathbf{Y}\n",
    "    \\end{bmatrix} \\sim \n",
    "    \\mathcal{N} \\bigg(  \n",
    "    \\begin{bmatrix}\n",
    "        \\boldsymbol{\\phi}(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta} \\\\\n",
    "        \\mathbf{F} \\boldsymbol{\\beta}\n",
    "    \\end{bmatrix}, \n",
    "    \\begin{bmatrix}\n",
    "        \\sigma^2 & \\sigma^2\\boldsymbol{r}^\\intercal(\\boldsymbol{x}) \\\\\n",
    "        \\boldsymbol{c}(\\boldsymbol{x})&  \\mathbf{C}\n",
    "    \\end{bmatrix}\n",
    "    \\bigg)\n",
    "    \\end{align*} \n",
    "<br></br>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">$\\ \\text{where} \\ \\mathbf{C}=\\boldsymbol{\\sigma}^2\\mathbf{R}+\\mathbf{\\Sigma}_n, \\quad \\mathbf{c}(\\mathbf{x})=\\sigma^2 \\boldsymbol{r}(\\boldsymbol{x})$ (cross-covariance).</span>\n",
    "    \n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Gaussian Process Regression (GPR)</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">The mean and the variance of the Gaussian random variable $\\tilde{\\mathcal{Υ}}=\\tilde{\\mathcal{M}}(\\boldsymbol{x})$ conditional on the experimental data $\\mathbf{X}, \\mathbf{Y}$ are given by</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\mu_{\\tilde{Y}}(\\boldsymbol{x})=\\phi^\\intercal(\\boldsymbol{x})\\hat{\\boldsymbol{\\beta}}+\\mathbf{c}^\\intercal(\\boldsymbol{x})\\mathbf{C}^{-1}(\\mathbf{Y}-\\mathbf{F}\\hat{\\boldsymbol{\\beta}}) \\\\\n",
    "        & \\sigma^2_{\\tilde{Y}}=(\\sigma^2_{z}-\\mathbf{c}^\\intercal(\\boldsymbol{x})\\mathbf{C}^{-1}\\mathbf{c}(\\boldsymbol{x})+\\mathbf{u}_c^\\intercal(\\boldsymbol{x})(\\mathbf{F}^\\intercal\\mathbf{c}^{-1}\\mathbf{F})^{-1}\\mathbf{u}_c(\\boldsymbol{x}))\n",
    "    \\end{align*}\n",
    "    \n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\hat{\\boldsymbol{\\beta}}=(\\mathbf{F}^\\intercal\\mathbf{C}^{-1}\\mathbf{F})^{-1}\\mathbf{F}^\\intercal\\mathbf{C}^{-1}\\mathbf{Y}\\ (\\text{generalized} \\ \\text{least} \\ \\text{square} \\ \\text{estimate}) \\\\\n",
    "    & \\mathbf{u}_c(\\boldsymbol{x})=\\mathbf{F}^\\intercal \\mathbf{C}^{-1} \\mathbf{c}(\\boldsymbol{x})-\\boldsymbol{\\phi}(\\boldsymbol{x})\n",
    "    \\end{align*}\n",
    "    \n",
    "- <span style=\"font-size:1.1em; font-family:Arial\">The variance of the prediction at an experimental design point <u>does not</u> collapse to 0 (<span style=\"color:blue;\">regression</span> with respect to the design points).</span>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Gaussian Process Regression (GPR)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol style=\"margin-top:40px\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Selection of appropriate basis functions $\\{ \\phi_i (\\boldsymbol{x}) \\}^P_{i=1}$</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Selection of a correlation function $R(\\boldsymbol{x}_i, \\boldsymbol{x}_j, \\boldsymbol{\\theta})$</span></li>\n",
    "    <br></br>\n",
    "    <ul style=\"margin-top:0px;\">\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">Estimation of the hyperparameters $\\boldsymbol{\\theta}$ from the available data via an optimization problem.</span></li>\n",
    "        <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">Estimation of $\\{ \\beta_i\\}^P_{i=1}$:</span></li>\n",
    "        <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">In the case of regression, the noise $(\\sigma^2_n)$ variance or the process $(\\sigma_z^2)$ variance need to be estimated.</span></li>\n",
    "    </ul>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <ul style=\"margin-top:0px;\">\n",
    "  </ol>\n",
    "  <br></br>\n",
    "  <br></br>\n",
    "  <br></br>\n",
    "  <br></br>\n",
    "  <br></br>\n",
    "  <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Trend</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Different types of trend:</span>\n",
    "\n",
    "<ol>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Simple Kriging</b></span></li>\n",
    "    <center>\\begin{align*}\n",
    "    & \\boldsymbol{\\phi}(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta}=\\sum_{i=1}^P\\phi_i(\\boldsymbol{x})\n",
    "        \\end{align*}</center>  \n",
    "    <br></br>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">Coefficients $\\boldsymbol{\\beta}$ are all equal to 1, i.e., $\\{ \\beta_i=1\\}_{i=1}^P$</span>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Ordinary Kriging</b></span></li>\n",
    "    \\begin{align*}\n",
    "    & \\boldsymbol{\\phi}(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta}=\\beta_0\\phi_0(\\boldsymbol{x})=\\beta_0\n",
    "    \\end{align*}   \n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Universal Kriging</b></span></li>\n",
    "    \\begin{align*}\n",
    "    & \\boldsymbol{\\phi}(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta}=\\sum_{i=1}^P\\beta_i\\phi_i(\\boldsymbol{x})\n",
    "    \\end{align*}\n",
    "    <br></br>\n",
    "  </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br></br>\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Polynomial Chaos Expansion can be combined with Kriging to create a new surrogate approach*</span></li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:0.9em; font-family:Arial\">*Shoebi. R et al, 2015, Polynomial-Chaos-based Kriging, International Journal for Uncertainty Quantification.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Correlation</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"margin-top:40px\">\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Describes the degree of linear dependence between observations and new points.</span></li>\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">The correlation matrix $R_{ij}=R(\\boldsymbol{x}_i, \\boldsymbol{x}_j)$ should be <span style=\"color:blue;\">positive semi-definite</span>, and <span style=\"color:blue;\">symmetric</span>.</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">It can be expressed as $R_{ij}=R(\\boldsymbol{x}_i, \\boldsymbol{x}_j, \\boldsymbol{\\theta})$ where $\\boldsymbol{\\theta} \\in \\mathbb{R}^M$ is a vector that contains a set of hyperparameters.</span></li>\n",
    "  <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Several families of 1-d stationary correlation functions exist that depend on $x_i-x_j$, and are parameterized by $\\boldsymbol{\\theta}$:</span></li>\n",
    "    <br></br>\n",
    "  <ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Linear:</b> $R(x_i, x_j, \\theta)=\\max\\bigg( 0,1-\\frac{|x_i-x_j|}{\\theta} \\bigg)$</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Exponential:</b> $R(x_i, x_j, \\theta)=\\exp\\bigg(-\\frac{|x_i-x_j|}{\\theta} \\bigg)$</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Gaussian:</b> $R(x_i, x_j, \\theta)=\\exp\\bigg(-\\frac{1}{2}\\big(\\frac{|x_i-x_j|}{\\theta}\\big)^2 \\bigg)$</span></li>\n",
    "  </ul>\n",
    "</ul> \n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Hyperparameters</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">For the Kriging to learn the input-output mapping, the hyperparameters $\\{ \\boldsymbol{\\theta}, \\boldsymbol{\\beta}, \\sigma_z^2, \\sigma_n^2 \\}$ must be estimated. The estimation is achieved through optimization:</span>\n",
    "\n",
    "<ul>\n",
    "    <br></br>\n",
    "  <span style=\"font-size:1.1em; font-family:Arial\">Find parameters $\\{ \\boldsymbol{\\theta}, \\boldsymbol{\\beta}, \\sigma_{z}^2, \\sigma_n^2\\}$, such that the likelihood of the observations $\\mathbf{Y}=\\{Υ_1,\\ldots,Υ_N\\}$ is maximized (noise-free observations)</span>  \n",
    "  <br></br>\n",
    "  <br></br>\n",
    "  \\begin{align*}\n",
    "    & \\max \\mathcal{L}(\\boldsymbol{\\theta}, \\boldsymbol{\\beta}, \\sigma_{z}^2;\\mathbf{Y})=\\frac{\\det(\\mathbf{R})^{-1/2}}{(2 \\pi \\sigma_z^2)^{N/2}} \\exp \\big[ -\\frac{1}{2}(\\mathbf{Y}-\\mathbf{F}\\boldsymbol{\\beta})^\\intercal\\mathbf{R}^{-1}(\\mathbf{\\mathbf{Y}-\\mathbf{F}\\boldsymbol{\\beta}}) \\big]\n",
    "  \\end{align*}\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "  <ul>\n",
    "      <li>$\\hat{\\boldsymbol{\\beta}}=\\boldsymbol{\\beta}(\\boldsymbol{\\theta})=(\\mathbf{F}^\\intercal \\mathbf{R}^{-1}\\mathbf{F})^{-1}\\mathbf{F}^\\intercal\\mathbf{R}^{-1}\\mathbf{Y}$</li>\n",
    "    <br></br>\n",
    "      <li>$\\hat{\\sigma}_z^2=\\hat{\\sigma}_z^2(\\boldsymbol{\\theta})=\\frac{1}{N}(\\mathbf{Y}-\\mathbf{F}\\boldsymbol{\\beta})^\\intercal\\mathbf{R}^{-1}(\\mathbf{Y}-\\mathbf{F}\\boldsymbol{\\beta})$</li>\n",
    "            <br></br>\n",
    "            <li>$\\hat{\\boldsymbol{\\theta}}=\\text{argmin} [-\\mathcal{L}(\\boldsymbol{\\theta; \\mathbf{Y}})] \\equiv \\text{argmin} \\frac{1}{2}[\\log \\det(\\mathbf{R})+N\\log(2 \\pi \\sigma_z^2)+N]$</li>\n",
    "  </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Hyperparameters</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "from UQpy.surrogates.gaussian_process.regression_models import LinearRegression\n",
    "from UQpy.surrogates.gaussian_process. GaussianProcessRegression import GaussianProcessRegression\n",
    "from UQpy.surrogates.gaussian_process.kernels import RBF\n",
    "from UQpy.utilities.MinimizeOptimizer import MinimizeOptimizer\n",
    "\n",
    "K = GaussianProcessRegression(regression_model=LinearRegression(),\n",
    "                              kernel=RBF(), hyperparameters=[0.1, 0.1], \n",
    "                              random_state=1,optimizer=MinimizeOptimizer(method=\"l-bfgs-b\"), \n",
    "                              bounds=[[1e-4, 1e5], [1e-5, 1e-2]], optimizations_number=20)\n",
    "\n",
    "K.fit(samples=x, values=y)\n",
    "\n",
    "print(r'Parameter θ:', K. hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Use Gaussian Process Regression to predict the solution\n",
    "y_test = K.predict(x_test)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(x_test, y_test, label='Gaussian Process Regression')\n",
    "plt.scatter(x, y, c='r', label='Training data')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:2em; font-family:Arial\"><b><span style=\"color:blue;\">A</span>daptive <span style=\"color:blue;\">K</span>riging <span style=\"color:blue;\">M</span>onte <span style=\"color:blue;\">C</span>arlo <span style=\"color:blue;\">S</span>imulation </b></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Active Learning Framework for:</span>\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Reliability Analysis [1, 2, 3]</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Global Optimization [4]</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Best Global fit surrogate models [5]</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">User-defined objectives</span></li>\n",
    "  </ul>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">AKMCS term is adopted from:</span></li>\n",
    "    <span style=\"font-size:0.9em; font-family:Arial\"><span style=\"color:blue;\">Echard, N. Gayton and M. Lemaire, “AK-MCS: An active learning reliability method combining Kriging and Monte Carlo Simulation”, Structural Safety, Pages 145-154, 2011.</span></span>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"margin-top:40px\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">[1] Bichon. B et al., 2008, Efficient global reliability analysis for nonlinear implicit performance, AIAA Journal </span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">[2] Echard B. et al., 2011, AK-MCS: An active learning reliability method combining Kriging and Monte Carlo Simulation, Structural Safety </span></li>\n",
    "    <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">[3] Sundar V. et al., Reliability analysis using adaptive Kriging surrogates and multimodel inference, ASCE-ASME Journal of Risk and Uncertainty n Engineering Systems, Part A: Civil Engineering</span></li>\n",
    "        <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">[4] Jones D. et al, 1998, Efficient global optimization of expensive black-box functions, Journal of Global optimization</span></li>\n",
    "        <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">[5] Lam. C, 2008, Sequential adaptive designs in computer experiments for response surface model fit, PhD Thesis, Ohio State University</span></li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"margin-top:40px\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Adaptive kriging methods combine Monte Carlo simulation with adaptively build <span style=\"color:blue;\">Kriging</span> surrogates</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">The <span style=\"color:blue;\">model response</span> is approximated by the Kriging surrogate to reduce the computational cost.</span></li>\n",
    "    <br></br>\n",
    "</ul>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">Steps:</span></span>\n",
    "<br></br>\n",
    "<ol>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Generate a small experimental design $\\mathbf{X}=[\\boldsymbol{x}_1,...,\\boldsymbol{x}_{N_0}]$ and calculate the corresponding  responses $\\mathbf{Y}=[\\mathcal{M}(\\boldsymbol{x}_1),...,\\mathcal{M}(\\boldsymbol{x}_{N_0})]$.</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Train a Kriging surrogate $\\tilde{\\mathcal{M}}(\\boldsymbol{x})$ using the experimental design</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Generate a large number of candidate samples $\\mathbf{X}'=[\\boldsymbol{x}_1,...\\boldsymbol{x}_{N_{MC}}]$ and predict the corresponding surrogate responses $\\mathbf{Y}'=[\\tilde{\\mathcal{M}}(\\boldsymbol{x}_1),...,\\tilde{\\mathcal{M}}(\\boldsymbol{x}_{N_{MC}})]$</span></li>\n",
    "   </ol>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<ol start=\"4\">\n",
    "<li><span style=\"font-size:1.1em; font-family:Arial\">Select the next sample $\\boldsymbol{x}_*$ to be added to the experimental design $\\mathbf{X}$ based on an appropriate <span style=\"color:blue;\">learning</span> function. A learning function is a measure of how much candidate sample $\\boldsymbol{x}_*$ helps us reaching our goals when it is added in the experimental design.</span></li>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Check whether a convergence criterion is satisfied. If it is, stop, otherwise continue with step 6.</span></li>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Add sample $\\boldsymbol{x}_*$ and the corresponding respose $\\tilde{\\mathcal{M}}(\\boldsymbol{x}_*)$ to the experimental design and return to step 2.</span></li>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "</ol>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Learning functions</b></span>\n",
    "\n",
    "<ul>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">U-function: based on the concept of <i>misclassification</i> (i.e., estimate the probability that the sign of the surrogate performance function and the sign of the true performance function do not match).</span></li>\n",
    "    </ul>\n",
    "     \\begin{align*}\n",
    "    & U(\\boldsymbol{x})=\\frac{|\\mu_{\\tilde{Υ}}(\\boldsymbol{x})|}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\\\\n",
    "    & P_U(\\boldsymbol{x})=\\Phi(-U(\\boldsymbol{x}))\n",
    "     \\end{align*}\n",
    "    <br></br>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">Select the sample $\\boldsymbol{x}_*$ to add in the design experimental:</span>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "\\begin{align*}\n",
    "& \\boldsymbol{x}_*=\\text{arg} \\max(P_U(\\mathbf{s})) \\ \\text{where} \\ s \\in \\mathbf{X}'=[\\boldsymbol{x}_1,...,\\boldsymbol{x}_{N_{MC}}]\n",
    " \\end{align*}\n",
    "\n",
    "<br></br>\n",
    " <br></br>\n",
    " <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Learning functions</b></span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Probability weighted U-function: A weighted version of the U- function</span></li>\n",
    "    \\begin{align*}\n",
    "        & U(\\boldsymbol{x})=w(\\boldsymbol{x})\\frac{|\\mu_{\\tilde{Υ}}(\\boldsymbol{x})|}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})} \\\\\n",
    "        & w(\\boldsymbol{x})=\\frac{\\max f_{\\mathbf{X}}(\\boldsymbol{x})-f_{\\mathbf{X}}(\\boldsymbol{x})}{\\max f_{\\mathbf{X}}(\\boldsymbol{x})}\n",
    "    \\end{align*}\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Expected feasibility function (EFF):</span></li>\n",
    "    <br></br>\n",
    "    \\begin{align*}\n",
    "        & EFF(\\boldsymbol{x})=\\mu_{\\tilde{Υ}}(\\boldsymbol{x})\\bigg[ 2\\Phi \\bigg( \\frac{-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})} \\bigg)-\\Phi \\bigg( \\frac{\\epsilon-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg) -\\Phi \\bigg(\\frac{\\epsilon-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg) \\bigg]\\\\\n",
    "    & \\\\\n",
    "        & - \\sigma_{\\tilde{Υ}}(\\boldsymbol{x}) \\bigg[ 2\\varphi \\bigg( \\frac{-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})} \\bigg)-\\varphi \\bigg( \\frac{\\epsilon-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Y}}(\\mathbf{x})}\\bigg) -\\varphi \\bigg(\\frac{\\epsilon-\\mu_{\\tilde{Y}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Y}}(\\boldsymbol{x})}\\bigg)  \\bigg] + \\epsilon \\bigg[\\Phi \\bigg( \\frac{\\epsilon-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg)-\\Phi \\bigg( \\frac{-\\epsilon-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg) \\bigg]\n",
    "    \\end{align*}\n",
    "    <br></br>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">Where $\\epsilon=2\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})$ and $\\boldsymbol{x}_*=\\arg \\max(EFF_U(\\mathbf{s}))$ </span>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "<br></br>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Expected Improvement function (EIF): Balances global and local searches to find the minimum $f_{\\min}$ </span></li>\n",
    "    <br></br>\n",
    "\n",
    "\\begin{align*}\n",
    "         \\mathbb{E}[I(\\boldsymbol{x})] =\\mathbb{E}[\\max (f_{\\min} - \\mathbf{Y}', 0)] \n",
    "         = \\bigg(f_{\\min} - \\mu_{\\tilde{Υ}}(\\boldsymbol{x})\\bigg)\\Phi \\bigg(\\frac{f_{\\min} - \\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg)+\\sigma_{\\tilde{Υ}(\\boldsymbol{x})}\\varphi\\bigg(\\frac{f_{\\min} - \\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg)\n",
    "    \\end{align*}\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\\begin{align*}\n",
    "f_{\\min} = \\min (\\mathcal{M}(\\boldsymbol{x}_1), \\ldots, \\mathcal{M}(\\boldsymbol{x}_{N_0})\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS/Optimization</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "## Branin-Hoo function\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"./photos/branin.png\" width=\"500\"> \n",
    "</div>\n",
    "\n",
    "- Evaluated on the square $x_1 \\in [-5, 10], \\ x_2 \\in [0, 15]$\n",
    "- Two local minima and one global minimum\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "from UQpy import PythonModel \n",
    "from UQpy.surrogates import GaussianProcessRegression \n",
    "from UQpy.sampling import MonteCarloSampling, AdaptiveKriging \n",
    "from UQpy.run_model.RunModel import RunModel \n",
    "from UQpy.distributions import Uniform \n",
    "from BraninHoo import function \n",
    "from UQpy.utilities.MinimizeOptimizer import MinimizeOptimizer\n",
    "\n",
    "marginals = [Uniform(loc=-5, scale=15), Uniform(loc=0, scale=15)] \n",
    "x = MonteCarloSampling(distributions=marginals, nsamples=20)\n",
    "\n",
    "model = PythonModel(model_script='BraninHoo.py', model_object_name='function')\n",
    "rmodel = RunModel(model=model)\n",
    "\n",
    "from UQpy.surrogates.gaussian_process.regression_models import LinearRegression \n",
    "from UQpy.surrogates.gaussian_process.kernels import RBF \n",
    "\n",
    "bounds = [[10**(-3), 10**3], [10**(-3), 10**2], [10**(-3), 10**2]] \n",
    "optimizer = MinimizeOptimizer(method=\"L-BFGS-B\", bounds=bounds) \n",
    "K = GaussianProcessRegression(regression_model=LinearRegression(), kernel=RBF(),\n",
    "                              optimizer=optimizer, hyperparameters=[1, 1, 0.1],\n",
    "                              optimizations_number=10)\n",
    "\n",
    "from UQpy.sampling.adaptive_kriging_functions.ExpectedImprovement import ExpectedImprovement\n",
    "\n",
    "learning_function = ExpectedImprovement() \n",
    "a = AdaptiveKriging(runmodel_object=rmodel, samples=x.samples, surrogate=K, \n",
    "                    learning_nsamples=10 ** 3, n_add=1, learning_function=learning_function, \t\t       distributions=marginals) \n",
    "a.run(nsamples=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "rise": {
   "autolaunch": true,
   "backimage": "./photos/MseeBackground.png",
   "enable_chalkboard": true,
   "height": "90%",
   "reveal_shortcuts": {
    "chalkboard": {
     "clear": "ctrl-k"
    }
   },
   "width": "90%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
