{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>MSEE Short course on UQ</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Introduction</b></span>\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Uncertainty quantification:</b> Why surrogate models ?</span>\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Polynomials chaos</b></span>\n",
    "<ul style=\"margin-top:0px;\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">PCE basis</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Computing the coefficients</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Post-processing</span></li>    \n",
    "</ul>\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><b>Kriging (a.k.a. Gaussian process)</b></span>\n",
    "<ul style=\"margin-top:0px;\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Adaptive Kriging methods</span></li>\n",
    "    <ul style=\"margin-top:0px;\">\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">AKMCS</span></li>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">EGO</span></li>        \n",
    "    </ul>\n",
    "</ul>    \n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Global framework for UQ</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<div align=\"center\">\n",
    "  <img src=\"Day1_6.png\" width=\"2000\"> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Uncertainty propagation using Monte Carlo simulation</b></span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><b>Principle:</b> Generate <span style=\"color:blue;\">realizations</span> of the system using <span style=\"color:blue;\">random numbers.</span></span>\n",
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">A sample set $\\textbf{X}=\\{\\mathbf{x}_1,...,\\mathbf{x}_N \\}$ (i.e., <span style=\"color:blue;\">experimental design</span>) is drawn according to the (joint) probability distribution of the input $f_\\textbf{X}$, where $\\boldsymbol{x}_1=[X_1,..., X_M]$.</span></li>\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">For each sample $\\boldsymbol{x}_i$, with $i=1,...,N$, the response $\\mathcal{M}(\\boldsymbol{x}_i)=Υ_i$ is evaluated</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">The set of responses $\\mathbf{Y}=\\{ Υ_1,...,Υ_N \\}$ is used to estimate the <span style=\"color:blue;\">moments, distribution</span> or perform <span style=\"color:blue;\">reliability analysis.</span></span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Usually, $N$ needs to be very <span style=\"color:blue;\">large</span> ($N \\sim 10^6$).</span></li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Surrogate models for uncertainty quantification</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"margin-top:20px\">\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">A <span style=\"color:blue;\">surrogate model</span> $\\tilde{\\mathcal{M}}$ is an <span style=\"color:blue;\">approximation</span> of the original model $\\mathcal{M}$, with the following features:</span></li>\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">It is built from a <span style=\"color:blue;\">small</span> number $n \\ll N$ of runs of model $\\mathcal{M}$. </span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Learn input-output <span style=\"color:blue;\">mappings</span> from <span style=\"color:blue;\">training data</span> $\\{ \\boldsymbol{x}_i, Υ_i \\}^n_{i=1}$</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\n",
    "    \">For regression purposes, we assume that $\\mathcal{M}(\\boldsymbol{x})$ is a <span style=\"color:blue;\">continuous</span> field.</span></li>\n",
    "</ul>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"Day2_slide4.png\" width=\"1200\"> \n",
    "</div>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Ingredients for building a surrogate model</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Select an <span style=\"color:blue;\">experimental design</span> $\\mathbf{X}=\\{ \\boldsymbol{x}_1,...,\\boldsymbol{x}_N \\}$that covers efficiently the input space, i.e., <span style=\"color:blue;\">Latin hypercube sampling (LHS)</span></span></li>\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Run the computational model $\\mathcal{M}$ using <span style=\"color:blue;\">Monte Carlo simulation</span>.</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Learn the training data $\\{ \\boldsymbol{x}_i, Υ_i \\}^n_{i=1}$</span></li>\n",
    "</ul>\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"Day2_slide5.png\" width=\"1200\"> \n",
    "</div>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Advantages and disadvantages</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>What we gain</u></span>\n",
    "\n",
    "\\begin{align*}\n",
    "     \\mathcal{M}(\\boldsymbol{x}) & \\sim \\tilde{\\mathcal{M}}(\\boldsymbol{x})\\\\\n",
    "     \\color{red}{\\text{Hours} \\ \\text{per} \\ \\text{run}} & \\color{green}{\\quad \\ll \\text{Seconds} \\ \\text{per}  \\ \\text{run}}\n",
    " \\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>Advantages</u></span>\n",
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">Non-intrusive methods:</span> based on runs of the computational model using Monte Carlo simulation</span></li>\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">High-performance computing: </span>\"Embarrassingly parallel\"</span></li>\n",
    "  <br></br>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>Disadvantages</u></span>\n",
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">Validation:</span> Need for rigorous validation</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">Assumptions:</span> Typically makes strong assumptions about smoothness of the input - output relation</span></li>\n",
    "    <br></br>\n",
    "  <br></br>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Polynomial Chaos expansion</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "- <span style=\"font-size:1.1em; font-family:Arial\">Given the input random vector $\\boldsymbol{X} \\ (\\text{dim} \\ \\boldsymbol{X}=M)$ with joint probability density function (PDF):</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & f_\\boldsymbol{X}=\\prod_{i=1}^Mf_{X_i}(x_i)\\\\\n",
    " \\end{align*}\n",
    " \n",
    "- <span style=\"font-size:1.1em; font-family:Arial\">If the random output $Υ=\\mathcal{M}(\\boldsymbol{X})$ has finite variance, then it can be cast as a <span style=\"color:blue;\">Polynomial chaos expansion</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & Υ = \\sum_{\\boldsymbol{\\alpha} \\in \\mathbb{N}^M} \\color{purple}{y_{\\boldsymbol{\\alpha}}}\\color{orange}{\\Psi_{\\boldsymbol{\\alpha}}(\\mathbf{X})}\\\\\n",
    " \\end{align*}\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">where</span>\n",
    " - $\\color{orange}{\\Psi_{\\boldsymbol{\\alpha}}(\\textbf{X})}$: <span style=\"font-size:1.1em; font-family:Arial\"> <span style=\"color:blue;\">multivariate polynomials</span>, orthonormal with respect to $f_\\boldsymbol{X}$</span>\n",
    " - $\\color{purple}{y_{\\boldsymbol{\\alpha}}}$: <span style=\"font-size:1.1em; font-family:Arial\">coefficients to be computed</span> \n",
    " - $\\boldsymbol{\\alpha}=(\\alpha_1, \\alpha_2,...\\alpha_M)$, where $a_i \\in \\mathbb{N}$\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Multivariate polynomial basis</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">Univariate polynomials:</span> For each random variable $X_i$, univariate orthonormal polynomials $\\{ P_k^{(i)}, k \\in \\mathbb{N}\\}$ are built:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\langle P_j^{(i)}(x_i),P_k^{(i)}(x_i) \\rangle =\\int P_j^{(i)}(x_i) P_k^{(i)}(x_i) f_{X_i}(x_i)\n",
    "du =\\delta_{jk} \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.0em; font-family:Arial\">e.g. <span style=\"color:purple;\">Hermite:</span> Used when $X_i \\sim \\mathcal{N}(0,1)$, <span style=\"color:purple;\">Legendre:</span> Used when $X_i \\sim \\mathcal{U}(-1,1)$</span>\n",
    "\n",
    "\n",
    "<span style=\"color:blue; font-size:1.1em; font-family:Arial\">Tensor product construction:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{x})=\\prod_{i=1}^M P_{a_i}^{(i)}(x_i), \\qquad \\mathbb{E}[\\Psi_\\boldsymbol{\\alpha}(\\boldsymbol{x})\\Psi_\\boldsymbol{{\\beta}}(\\boldsymbol{x})]=\\delta_{\\boldsymbol{\\alpha} \\boldsymbol{\\beta}}, \\quad \\text{for} \\quad \\boldsymbol{\\alpha}, \\boldsymbol{\\beta} \\in \\mathbb{N}^M  \\end{align*}\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Multivariate polynomial basis</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.3em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Exact PCE</b></span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & Υ = \\sum_{\\boldsymbol{\\alpha} \\in \\mathbb{N}^M}y_{\\boldsymbol{\\alpha}}\\Psi_{\\boldsymbol{\\alpha}}(\\mathbf{X})\\\\\n",
    " \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.3em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Basis truncation</b></span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & |\\boldsymbol{\\alpha}|=\\sum_{i=1}^M a_i \n",
    "    \\end{align*}\n",
    "    \n",
    "    \n",
    "\\begin{align*}\n",
    "    & \\mathcal{A}^{M, p}=\\{\\boldsymbol{\\alpha} \\in \\mathbb{R}^M: |\\boldsymbol{\\alpha}| \\leq p \\}\n",
    "    \\end{align*}\n",
    "    \n",
    "    \n",
    "\\begin{align*}\n",
    "& \\text{card}~\\mathcal{A}^{M, p}\\equiv P= \\binom{M+p}{p}=\\frac{(M+p)!}{M!p!}\n",
    "\\end{align*}\n",
    "<br></br>\n",
    "\n",
    "This leads to the truncated approximate expansion\n",
    "\n",
    "\\begin{align*}\n",
    "    & Υ \\approx \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}^{M, p}} y_{\\boldsymbol{\\alpha}}\\Psi_{\\boldsymbol{\\alpha}}(\\mathbf{X})\\\\\n",
    " \\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Computing the coefficients</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>Least-square minimization</u></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">The exact (infinite) series expansion is considered as the sum of a <span style=\"color:blue;\">truncated series</span> and a <span style=\"color:blue;\">residual:</span></span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & Υ=\\mathcal{M}(\\boldsymbol{x})=\\sum_{\\alpha \\in \\mathcal{A}^{M, p}}y_{\\alpha} \\Psi_{\\alpha}(\\boldsymbol{x})+\\epsilon_p \\equiv (\\mathbf{Y}^T \\Psi(\\boldsymbol{x})+\\epsilon_p(\\boldsymbol{x}))\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\mathbf{Y}=\\{ y_{\\alpha}, \\alpha \\in \\mathcal{A}^{M, p} \\} \\equiv \\{ y_0,..., y_{P-1} \\} \\qquad (\\text{P} \\ \\text{unknown} \\ \\text{coefficients}.)\\\\\n",
    "    & \\Psi(\\boldsymbol{x})=\\{ \\Psi_0(\\boldsymbol{x}),...,\\Psi_{P-1}(\\boldsymbol{x}) \\}\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">The unknown coefficients are estimated by minimizing the mean square residual error:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    \\hat{\\mathbf{Y}}=\\mathbb{E}[\\epsilon_p(\\boldsymbol{x})]\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\hat{\\textbf{Y}}=\\text{argmin}~ \\frac{1}{n}\\sum_{i=1}^n(\\mathbf{Y}^T \\Psi (\\boldsymbol{x}_i)-\\mathcal{M}(\\boldsymbol{x}_i))^2, \\ \\textbf{Y} \\in \\mathbb{R}^P\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Computing the coefficients</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>Ordinary least-square minimization</u></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">An average of the mean square error is minimized (over $n$ training samples)</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\hat{\\textbf{Y}}=\\text{argmin}~ \\frac{1}{n}\\sum_{i=1}^n(\\mathbf{Y}^T \\Psi (\\boldsymbol{x}_i)-\\mathcal{M}(\\boldsymbol{x}_i))^2, \\ \\textbf{Y} \\in \\mathbb{R}^P\n",
    "    \\end{align*}\n",
    "    \n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Steps:</span>\n",
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Gather the training data in matrix $\\mathbf{B}=\\{\\mathcal{M}(\\boldsymbol{x}_1),...,\\mathcal{M}(\\boldsymbol{x}_n) \\}$</span></li>\n",
    "      <li><span style=\"font-size:1.1em; font-family:Arial\">Select a truncation scheme, e.g., $\\mathcal{A}^{M,p}=\\{ \\boldsymbol{\\alpha}\\in \\mathbb{N}^M |\\boldsymbol{\\alpha}| \\le p \\}$</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Compute the matrix: $\\mathbf{A}_{ij}=\\Psi_j(\\boldsymbol{x}_i)$</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Solve the system: $\\hat{\\mathbf{Y}}=(\\mathbf{A}^\\intercal\\mathbf{A})^{-1}\\mathbf{A}^\\intercal\\mathbf{B}$</span></li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Computing the error</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Relative generalization error:\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\epsilon=\\mathbb{E}\\bigg[\\big(\\mathcal{M}(\\boldsymbol{x})-\\mathcal{M}^{PC}(\\boldsymbol{x})\\big)^2\\bigg]/\\text{Var}[Y] \\qquad \\text{where} \\qquad  \\mathcal{M}^{PC}(\\boldsymbol{x})=\\sum_{\\alpha \\in \\mathcal{A}^{M,p}}y_{\\alpha}\\Psi_{\\alpha}(\\mathbf{X})\n",
    "    \\end{align*}\n",
    "- Validation error:\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\epsilon_{val}=\\frac{N-1}{N}\\bigg[\\frac{\\sum_{i=1}^n\\big(\\mathcal{M}(\\boldsymbol{x}_i)-\\mathcal{M}^{PC}(\\boldsymbol{x}_i)\\big)^2}{\\sum_{i=1}^n\\big(\\mathcal{M}(\\boldsymbol{x}_i)-\\frac{1}{N}\\sum_{i=1}^N \\mathcal{M}(\\boldsymbol{x}_i)\\big)^2}\\bigg]\n",
    "    \\end{align*}    \n",
    "- Leave-one-out (LOO) cross validation error:\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\epsilon_{LOO}=\\frac{1}{N}\\frac{\\sum_{i=1}^n\\bigg(\\frac{\\mathcal{M}(\\boldsymbol{x}_i)-\\mathcal{M}^{PC}(\\boldsymbol{x}_i)}{1-h_i}\\bigg)^2}{\\sum_{i=1}^N\\big(\\mathcal{M}(\\boldsymbol{x}_i)-\\frac{1}{N}\\sum_{i=1}^N \\mathcal{M}(\\boldsymbol{x}_i)\\big)^2}\n",
    "    \\end{align*}\n",
    "where $h_i$ is the $i_{th}$ diagonal term of matrix: $\\mathbf{A}(\\mathbf{A}^\\intercal\\mathbf{A})^{-1}\\mathbf{A}^\\intercal$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Example</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Consider we have one random variable $X_1 \\sim \\mathcal{U}(0,10)$</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/UQpyv4/lib/python3.9/site-packages/beartype-0.9.1-py3.9.egg/beartype/_util/hint/pep/utilpeptest.py:373: BeartypeDecorHintPep585DeprecationWarning: PEP 484 type hint typing.Callable deprecated by PEP 585 scheduled for removal in the first Python version released after October 5th, 2025. To resolve this, either drop Python < 3.9 support and globally replace this hint by the equivalent PEP 585 type hint (e.g., \"typing.List[int]\" by \"list[int]\") or see this discussion topic for saner and more portable solutions:\n",
      "    https://github.com/beartype/beartype#pep-484-deprecations\n",
      "  warn(\n",
      "The selected optimizer method does not support bounds and thus will be ignored.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from UQpy.distributions import Uniform\n",
    "from UQpy.surrogates.polynomial_chaos.polynomials.TotalDegreeBasis import TotalDegreeBasis\n",
    "from UQpy.surrogates.polynomial_chaos.PolynomialChaosExpansion import PolynomialChaosExpansion\n",
    "from UQpy.surrogates.polynomial_chaos.regressions.LeastSquareRegression import LeastSquareRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Define the function to interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def function(x):                                \n",
    "    return x*np.sin(x)/10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Create a distribution object, generate training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "dist = Uniform(loc=0, scale=10)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Example</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Generate our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "n_samples = 30    \n",
    "x = dist.rvs(n_samples)  \n",
    "y = function(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x, y, c='r')\n",
    "plt.grid(True)\n",
    "plt.title('Training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Example</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the maximum order of the polynomials\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree = 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_basis = TotalDegreeBasis(dist, max_degree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a least squares object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares = LeastSquareRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Example</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a PCE object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pce = PolynomialChaosExpansion(polynomial_basis=polynomial_basis, regression_method=least_squares)\n",
    "pce.fit(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate test data and predict response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test = dist.rvs(100)\n",
    "x_test.sort(axis=0) \n",
    "y_test = pce.predict(x_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_test, y_test, 'g', label='PCE predictor - OLS')\n",
    "plt.scatter(x, y, c='r', label='training data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Post-processing</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\"><u>Statistical moments</u></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Due to the <span style=\"color:blue;\">orthnormality</span> of the basis functions, i.e. $\\mathbb{E}[\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{x})\\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{x})]=\\delta_{\\boldsymbol{\\alpha \\beta}}$, and the fact that $\\mathbb{E}[\\Psi_{\\boldsymbol{\\alpha \\ne 0}}(\\boldsymbol{x})]=\\boldsymbol{0}$, the first two statistical moments are:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\color{blue}{\\text{Mean:}} \\ \\ \\mu_{\\tilde{{Y}}}=y_0 \\\\\n",
    "    & \\color{blue}{\\text{Variance:}} \\ \\ \\sigma^2_{\\tilde{Y}}=\\sum_{\\alpha \\in \\mathcal{A}\\setminus 0}y_{\\alpha}^2\n",
    "    \\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<span style=\"font-size:1.1em; font-family:Arial\">The PCE can be used as a <span style=\"color:blue;\">response surface</span> for predicting the respone of the model</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\tilde{{Y}}(\\boldsymbol{x})=\\sum_{\\alpha \\in \\mathcal{A}}y_{\\alpha} \\Psi_{\\alpha}(\\boldsymbol{x})\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">and the PDF of the response is estimated by Monte Carlo simulation on the response surface</span>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moments from least squares regression : (0.1227, 0.1626)\n",
      "Moments from Monte Carlo integration:  (0.078777, 0.136557)\n"
     ]
    }
   ],
   "source": [
    "n_mc = 1000000\n",
    "x_mc = dist.rvs(n_mc)  \n",
    "y_mc = function(x_mc)  \n",
    "mu = np.mean(y_mc)\n",
    "\n",
    "print('Moments from least squares regression :', pce.get_moments())\n",
    "print('Moments from Monte Carlo integration: ', \t(round((1/n_mc)*np.sum(y_mc),6), \t    \t\t round((1/n_mc)*np.sum((y_mc-mu)**2),6)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Post-processing</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><u>Sensitivity</u></span>\n",
    "\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><span style=\"color:blue;\" >High Dimensional Model Representation (HDMR)</span>*:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\mathcal{M}(\\boldsymbol{x})=\\mathcal{M}_0+ \\sum_{i=1}^M \\mathcal{M}_{i}(X_{i}) + \\sum_{i\\leq j <M} \\mathcal{M}_{ij}(X_{i}, X_j) +  \\mathcal{M}_{12...M}(\\mathbf{X})\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    " \\begin{align*}\n",
    "    & \\mathcal{M}(\\boldsymbol{x})=\\mathcal{M}_0+ \\sum_{ \\mathbf{u} \\neq 0}\\mathcal{M}_{\\mathbf{u}}(\\boldsymbol{x}_{\\mathbf{u}})\n",
    "    \\end{align*}\n",
    "  \n",
    " <span style=\"font-size:1.3em; font-family:Arial\">where</span> \n",
    " \n",
    " \\begin{align*}\n",
    " \\mathbf{u} = [i_1, \\ldots, i_s]\\subset \\{1,...,M \\}\n",
    "     \\end{align*}\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "*Saltelli A. et al, 2008, Global Sensitivity Analysis. The primer\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Post-processing</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><u>Variance decomposition</u></span>\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    & D = \\text{Var}[\\mathcal{M}(\\boldsymbol{x})]=\\sum_{\\mathbf{u} \\neq 0} D_{\\mathbf{u}}\n",
    "    \\end{align*}\n",
    "\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\">where</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & D_{\\mathbf{u}} = \\text{Var}[\\mathcal{M}_{\\mathbf{u}}(\\boldsymbol{x}_{\\mathbf{u}})]\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.3em; font-family:Arial\"><u>Sobol' indices</u></span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\color{blue}{\\text{First}} \\ \\text{order}: S_{\\mathbf{u}}=\\frac{D_{\\mathbf{u}}}{D} \\\\\n",
    "     & \\color{blue}{\\text{Total}} \\ \\text{order}: S_{i}^T=\\sum_{\\mathbf{u} \\supset i} \\frac{D_{\\mathbf{u}}}{D}\n",
    "    \\end{align*}\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>PCE/Post-processing</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.3em; font-family:Arial\"><span style=\"color:blue;\">HDMR</span>* of a PCE is obtained by re-ordering the terms of the truncated PC expansion</span>\n",
    "\n",
    "\n",
    "\\begin{align*} \n",
    "    & \\mathcal{M}_{\\mathbf{u}}(\\boldsymbol{x}_{\\mathbf{u}}) =\\sum_{\\alpha \\in \\mathcal{A}_{\\boldsymbol{u}}} y_{\\alpha} \\Psi_{\\alpha}(\\mathbf{X})\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where $\\qquad \\mathcal{A}_{\\boldsymbol{u}}=\\{ \\alpha \\in A: k \\in \\mathbf{u} \\iff \\alpha_k \\ne 0 \\}$</span>\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\hat{D}_{\\mathbf{u}} = \\sum_{\\alpha \\in \\mathcal{A}_{\\mathbf{u}}}y_{\\alpha}^2 , \\quad \\hat{D} = \\sum_{\\alpha \\in \\mathcal{A}\\setminus \\{0\\}} y_{\\alpha}^2\n",
    "    \\end{align*}\n",
    "\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\color{blue}{\\text{First}} \\ \\text{order}: \\ \\hat{S}_{i}=\\frac{\\sum_{\\alpha \\in \\mathcal{A}_i} y_{\\alpha}^2}{\\hat{D}}, \\quad \\mathcal{A}_i=\\{\\alpha \\in \\mathcal{A}: a_i>0, i\\neq j=0\\} \\\\\n",
    "    & \\color{blue}{\\text{Total}} \\ \\text{order}: \\hat{S}_{i}^T= \\frac{\\sum_{\\alpha \\in \\mathcal{A}_{\\mathbf{u}}}y_{\\alpha}^2}{\\hat{D}}, \\quad \\mathcal{A}_i=\\{\\alpha \\in \\mathcal{A}: a_i>0\\}\n",
    "    \\end{align*}\n",
    "\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "*Saltelli A. et al, 2008, Global Sensitivity Analysis. The primer\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Gaussian Process Regression / Kriging</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Assumes that the model output $M(\\mathbf{x})$ is approximated by a Gaussian stochastic process i.e.,</span></li>\n",
    "    \\begin{align*}\n",
    "    & \\tilde{\\mathcal{M}}(\\boldsymbol{x})\\rightarrow \\mathcal{G}\\mathcal{P} (\\mathbf{m},\\boldsymbol{\\Sigma}) \\rightarrow \\mathcal{N}(\\mathbf{m}, \\boldsymbol{\\Sigma})\n",
    "    \\end{align*}\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">It is completely described by its <span style=\"color:blue;\">mean</span> ($\\mathbf{m}(x)$) and <span style=\"color:blue;\">correlation</span> ($\\mathbf{\\Sigma}(x_1, x_2)$) functions $\\mathcal{G}\\mathcal{P} \\rightarrow \\mathcal{G}\\mathcal{P}(\\mathbf{m,\\Sigma})$.</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">It is desribed by the following equation:</span></li>\n",
    "</ul>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\tilde{\\mathcal{M}}(\\boldsymbol{x})=\\boldsymbol{\\phi} (\\mathbf{x})^T \\boldsymbol{\\beta} + \\sigma_z^2 Z(\\boldsymbol{x},\\omega)\n",
    "    \\end{align*}\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where </span>\n",
    "<ul>\n",
    "  <li>$\\boldsymbol{\\phi} (\\boldsymbol{x})^T \\boldsymbol{\\beta} =\\beta_1\\phi_1(\\boldsymbol{x})+...+\\beta_P \\phi_P(\\boldsymbol{x})\\rightarrow \\color{blue}{\\text{trend}}$</li> \n",
    "<ul>\n",
    "    <li> $\\{ \\phi(\\boldsymbol{x}) \\}_{i=1}^P: \\ \\text{basis}  \\ \\text{functions}$</li>\n",
    "    <li>$\\{ \\beta_i \\}_{i=1}^P: \\ \\text{coefficients}$</li>\n",
    "    </ul>\n",
    "<li>$Z(\\boldsymbol{x}, \\omega) \\sim \\rightarrow \\color{blue}{\\text{Gaussian stochastic} \\ \\text{process}}$</li>\n",
    "  <li>$\\sigma_z^2\\rightarrow \\color{blue}{\\text{Variance}}$</li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Interpolation</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=margin-top:40px>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Kriging predicts the model output $\\tilde{\\mathcal{M}}(\\boldsymbol{x})$ for a new point $\\boldsymbol{x}$, given an experimental design $\\mathbf{X}=\\{ \\boldsymbol{x}_1,...,\\boldsymbol{x}_N \\}$ and the corresponding (noise-free) model $\\mathbf{Y}=\\{ Υ_1,...,Υ_N \\}$responses</span></li>\n",
    "    <ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">The Kriging provides a prediction based on the <span style=\"color:blue;\">Gaussian assumption</span>:</li>\n",
    "      <li><span style=\"font-size:1.1em; font-family:Arial\">The vector formed by the prediction $\\tilde{Υ}=\\tilde{\\mathcal{M}}(\\boldsymbol{x})$ and the true model responses $\\mathbf{Y}$, has a joint Gaussian distribution</span></li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\begin{bmatrix}\n",
    "        \\tilde{Υ} \\\\\n",
    "        \\mathbf{Y}\n",
    "    \\end{bmatrix} \\sim \n",
    "    \\mathcal{N} \\bigg(  \n",
    "    \\begin{bmatrix}\n",
    "        \\boldsymbol{\\phi}(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta} \\\\\n",
    "        \\mathbf{F} \\boldsymbol{\\beta}\n",
    "    \\end{bmatrix}, \\sigma_z^2\n",
    "    \\begin{bmatrix}\n",
    "        1 & \\mathbf{r}^\\intercal(\\boldsymbol{x}) \\\\\n",
    "        \\mathbf{r}(\\boldsymbol{x})&  \\mathbf{R}\n",
    "    \\end{bmatrix}\n",
    "    \\bigg)\n",
    "    \\end{align*}\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where</span>\n",
    "\n",
    "<ul>\n",
    "  <li>$R_{ij}=R(\\boldsymbol{x}_i, \\boldsymbol{x}_j, \\boldsymbol{\\theta}), \\quad i=1,...,N$</li>\n",
    "  <li>$F_{ij}=\\phi(\\boldsymbol{x}_i) \\quad i=1,...,N, \\ j=1,...,P$</li>\n",
    "  <li>$r_{i}=R(\\boldsymbol{x},\\boldsymbol{x}_i, \\boldsymbol{\\theta}) \\quad i=1,...,N$</li>  \n",
    "</ul> \n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Interpolation</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">The mean and the variance of Gaussian random variable $\\tilde{Υ}=\\tilde{\\mathcal{M}}(\\boldsymbol{x})$ conditional on the experimental data $\\mathbf{X}, \\mathbf{Y}$ is given by</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\mu_{\\tilde{Υ}}(\\boldsymbol{x})=\\phi(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta}+\\boldsymbol{r}^\\intercal(\\boldsymbol{x})\\mathbf{R}^{-1}(\\mathbf{Y}-\\mathbf{F}\\hat{\\boldsymbol{\\beta}}) \\\\\n",
    "        & \\sigma^2_{\\tilde{Υ}}=\\sigma^2_{z}\\big(1-\\boldsymbol{r}^\\intercal(\\boldsymbol{x})\\mathbf{R}^{-1}\\boldsymbol{r}(\\boldsymbol{x})+\\mathbf{u}^\\intercal(\\boldsymbol{x})(\\mathbf{F}^\\intercal\\mathbf{R}^{-1}\\mathbf{F})^{-1}\\mathbf{u}(\\mathbf{x})\\big)\n",
    "    \\end{align*}\n",
    "    \n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where</span>\n",
    "\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">$\\hat{\\boldsymbol{\\beta}}$ is a generalized least square estimate of the coefficients.</span></li>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">$\\mathbf{u}(\\boldsymbol{x})=\\mathbf{F}^T\\mathbf{R}^{-1}\\boldsymbol{r}(\\boldsymbol{x})-\\boldsymbol{\\phi}(\\boldsymbol{x})$</span></li>\n",
    "</ul> \n",
    "<br></br>\n",
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">The variance of the prediction at an experimental design point $\\rightarrow 0$ (interpolant with respect to the design points).</span></li>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">$\\mathbb{P}(\\tilde{Υ} \\le t)=\\Phi \\big( \\frac{t-\\mu_{\\tilde{Υ}(\\mathbf{x})}}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})} \\big)$, where $\\Phi$ is the Gaussian cumulative density function</span></li>\n",
    "</ul> \n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Gaussian Process Regression (GPR)</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">In many cases, the observed responses are noisy, i.e.,</span></li>\n",
    "    <br></br>\n",
    "    \\begin{align*}\n",
    "    & Y_1=\\mathcal{M}(\\boldsymbol{x})+\\epsilon, \\ \\text{where} \\ \\epsilon \\sim \\mathcal{N}(0, \\mathbf{\\Sigma}_N)\n",
    "    \\end{align*}\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Three classes of noise exist:</span></li>\n",
    "  <ol>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">$\\color{blue}{\\text{Homogeneous}:}\\mathbf{\\Sigma}_n=\\sigma_n^2\\mathbf{I}$, i.e., Same noise for each observation.</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">$\\color{blue}{\\text{Independent} \\ \\text{heterogeneous}:}\\mathbf{\\Sigma}_n=\\text{diag}(\\sigma^2_n)$, noise different for each observation but, not correlated</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">$\\color{blue}{\\text{General} \\ \\text{heterogeneous}:}$ noise different for each observation, with possible correlations</span></li>\n",
    "  </ol>\n",
    "</ul> \n",
    "\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">The joint Gaussian distribution formed by the prediction and the noise responses is:</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\begin{bmatrix}\n",
    "        \\tilde{Υ} \\\\\n",
    "        \\mathbf{Y}\n",
    "    \\end{bmatrix} \\sim \n",
    "    \\mathcal{N} \\bigg(  \n",
    "    \\begin{bmatrix}\n",
    "        \\boldsymbol{\\phi}(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta} \\\\\n",
    "        \\mathbf{F} \\boldsymbol{\\beta}\n",
    "    \\end{bmatrix}, \n",
    "    \\begin{bmatrix}\n",
    "        \\sigma^2 & \\sigma^2\\boldsymbol{r}^\\intercal(\\boldsymbol{x}) \\\\\n",
    "        \\boldsymbol{c}(\\boldsymbol{x})&  \\mathbf{C}\n",
    "    \\end{bmatrix}\n",
    "    \\bigg)\n",
    "    \\end{align*} \n",
    "<br></br>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">$\\ \\text{where} \\ \\mathbf{C}=\\boldsymbol{\\sigma}^2\\mathbf{R}+\\mathbf{\\Sigma}_n, \\quad \\mathbf{c}(\\mathbf{x})=\\sigma^2 \\boldsymbol{r}(\\boldsymbol{x})$ (cross-covariance).</span>\n",
    "    \n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Gaussian Process Regression (GPR)</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">The mean and the variance of the Gaussian random variable $\\tilde{\\mathcal{Υ}}=\\tilde{\\mathcal{M}}(\\boldsymbol{x})$ conditional on the experimental data $\\mathbf{X}, \\mathbf{Y}$ are given by</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\mu_{\\tilde{Y}}(\\boldsymbol{x})=\\phi^\\intercal(\\boldsymbol{x})\\hat{\\boldsymbol{\\beta}}+\\mathbf{c}^\\intercal(\\boldsymbol{x})\\mathbf{C}^{-1}(\\mathbf{Y}-\\mathbf{F}\\hat{\\boldsymbol{\\beta}}) \\\\\n",
    "        & \\sigma^2_{\\tilde{Y}}=(\\sigma^2_{z}-\\mathbf{c}^\\intercal(\\boldsymbol{x})\\mathbf{C}^{-1}\\mathbf{c}(\\boldsymbol{x})+\\mathbf{u}_c^\\intercal(\\boldsymbol{x})(\\mathbf{F}^\\intercal\\mathbf{c}^{-1}\\mathbf{F})^{-1}\\mathbf{u}_c(\\boldsymbol{x}))\n",
    "    \\end{align*}\n",
    "    \n",
    "<span style=\"font-size:1.1em; font-family:Arial\">where</span>\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\hat{\\boldsymbol{\\beta}}=(\\mathbf{F}^\\intercal\\mathbf{C}^{-1}\\mathbf{F})^{-1}\\mathbf{F}^\\intercal\\mathbf{C}^{-1}\\mathbf{Y}\\ (\\text{generalized} \\ \\text{least} \\ \\text{square} \\ \\text{estimate}) \\\\\n",
    "    & \\mathbf{u}_c(\\boldsymbol{x})=\\mathbf{F}^\\intercal \\mathbf{C}^{-1} \\mathbf{c}(\\boldsymbol{x})-\\boldsymbol{\\phi}(\\boldsymbol{x})\n",
    "    \\end{align*}\n",
    "    \n",
    "- <span style=\"font-size:1.1em; font-family:Arial\">The variance of the prediction at an experimental design point <u>does not</u> collapse to 0 (<span style=\"color:blue;\">regression</span> with respect to the design points).</span>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Gaussian Process Regression (GPR)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol style=\"margin-top:40px\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Selection of appropriate basis functions $\\{ \\phi_i (\\boldsymbol{x}) \\}^P_{i=1}$</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Selection of a correlation function $R(\\boldsymbol{x}_i, \\boldsymbol{x}_j, \\boldsymbol{\\theta})$</span></li>\n",
    "    <br></br>\n",
    "    <ul style=\"margin-top:0px;\">\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">Estimation of the hyperparameters $\\boldsymbol{\\theta}$ from the available data via an optimization problem.</span></li>\n",
    "        <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">Estimation of $\\{ \\beta_i\\}^P_{i=1}$:</span></li>\n",
    "        <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">In the case of regression, the noise $(\\sigma^2_n)$ variance or the process $(\\sigma_z^2)$ variance need to be estimated.</span></li>\n",
    "    </ul>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <ul style=\"margin-top:0px;\">\n",
    "  </ol>\n",
    "  <br></br>\n",
    "  <br></br>\n",
    "  <br></br>\n",
    "  <br></br>\n",
    "  <br></br>\n",
    "  <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Trend</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Different types of trend:</span>\n",
    "\n",
    "<ol>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Simple Kriging</b></span></li>\n",
    "    <center>\\begin{align*}\n",
    "    & \\boldsymbol{\\phi}(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta}=\\sum_{i=1}^P\\phi_i(\\boldsymbol{x})\n",
    "        \\end{align*}</center>  \n",
    "    <br></br>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">Coefficients $\\boldsymbol{\\beta}$ are all equal to 1, i.e., $\\{ \\beta_i=1\\}_{i=1}^P$</span>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Ordinary Kriging</b></span></li>\n",
    "    \\begin{align*}\n",
    "    & \\boldsymbol{\\phi}(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta}=\\beta_0\\phi_0(\\boldsymbol{x})=\\beta_0\n",
    "    \\end{align*}   \n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Universal Kriging</b></span></li>\n",
    "    \\begin{align*}\n",
    "    & \\boldsymbol{\\phi}(\\boldsymbol{x})^\\intercal\\boldsymbol{\\beta}=\\sum_{i=1}^P\\beta_i\\phi_i(\\boldsymbol{x})\n",
    "    \\end{align*}\n",
    "    <br></br>\n",
    "  </ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<br></br>\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Polynomial Chaos Expansion can be combined with Kriging to create a new surrogate approach*</span></li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "<span style=\"font-size:0.9em; font-family:Arial\">*Shoebi. R et al, 2015, Polynomial-Chaos-based Kriging, International Journal for Uncertainty Quantification.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Correlation</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"margin-top:40px\">\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">Describes the degree of linear dependence between observations and new points.</span></li>\n",
    "    <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">The correlation matrix $R_{ij}=R(\\boldsymbol{x}_i, \\boldsymbol{x}_j)$ should be <span style=\"color:blue;\">positive semi-definite</span>, and <span style=\"color:blue;\">symmetric</span>.</span></li>\n",
    "  <br></br>\n",
    "  <li><span style=\"font-size:1.1em; font-family:Arial\">It can be expressed as $R_{ij}=R(\\boldsymbol{x}_i, \\boldsymbol{x}_j, \\boldsymbol{\\theta})$ where $\\boldsymbol{\\theta} \\in \\mathbb{R}^M$ is a vector that contains a set of hyperparameters.</span></li>\n",
    "  <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Several families of 1-d stationary correlation functions exist that depend on $x_i-x_j$, and are parameterized by $\\boldsymbol{\\theta}$:</span></li>\n",
    "    <br></br>\n",
    "  <ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Linear:</b> $R(x_i, x_j, \\theta)=\\max\\bigg( 0,1-\\frac{|x_i-x_j|}{\\theta} \\bigg)$</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Exponential:</b> $R(x_i, x_j, \\theta)=\\exp\\bigg(-\\frac{|x_i-x_j|}{\\theta} \\bigg)$</span></li>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\"><b>Gaussian:</b> $R(x_i, x_j, \\theta)=\\exp\\bigg(-\\frac{1}{2}\\big(\\frac{|x_i-x_j|}{\\theta}\\big)^2 \\bigg)$</span></li>\n",
    "  </ul>\n",
    "</ul> \n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Hyperparameters</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">For the Kriging to learn the input-output mapping, the hyperparameters $\\{ \\boldsymbol{\\theta}, \\boldsymbol{\\beta}, \\sigma_z^2, \\sigma_n^2 \\}$ must be estimated. The estimation is achieved through optimization:</span>\n",
    "\n",
    "<ul>\n",
    "    <br></br>\n",
    "  <span style=\"font-size:1.1em; font-family:Arial\">Find parameters $\\{ \\boldsymbol{\\theta}, \\boldsymbol{\\beta}, \\sigma_{z}^2, \\sigma_n^2\\}$, such that the likelihood of the observations $\\mathbf{Y}=\\{Υ_1,\\ldots,Υ_N\\}$ is maximized (noise-free observations)</span>  \n",
    "  <br></br>\n",
    "  <br></br>\n",
    "  \\begin{align*}\n",
    "    & \\max \\mathcal{L}(\\boldsymbol{\\theta}, \\boldsymbol{\\beta}, \\sigma_{z}^2;\\mathbf{Y})=\\frac{\\det(\\mathbf{R})^{-1/2}}{(2 \\pi \\sigma_z^2)^{N/2}} \\exp \\big[ -\\frac{1}{2}(\\mathbf{Y}-\\mathbf{F}\\boldsymbol{\\beta})^\\intercal\\mathbf{R}^{-1}(\\mathbf{\\mathbf{Y}-\\mathbf{F}\\boldsymbol{\\beta}}) \\big]\n",
    "  \\end{align*}\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "  <ul>\n",
    "      <li>$\\hat{\\boldsymbol{\\beta}}=\\boldsymbol{\\beta}(\\boldsymbol{\\theta})=(\\mathbf{F}^\\intercal \\mathbf{R}^{-1}\\mathbf{F})^{-1}\\mathbf{F}^\\intercal\\mathbf{R}^{-1}\\mathbf{Y}$</li>\n",
    "    <br></br>\n",
    "      <li>$\\hat{\\sigma}_z^2=\\hat{\\sigma}_z^2(\\boldsymbol{\\theta})=\\frac{1}{N}(\\mathbf{Y}-\\mathbf{F}\\boldsymbol{\\beta})^\\intercal\\mathbf{R}^{-1}(\\mathbf{Y}-\\mathbf{F}\\boldsymbol{\\beta})$</li>\n",
    "            <br></br>\n",
    "            <li>$\\hat{\\boldsymbol{\\theta}}=\\text{argmin} [-\\mathcal{L}(\\boldsymbol{\\theta; \\mathbf{Y}})] \\equiv \\text{argmin} \\frac{1}{2}[\\log \\det(\\mathbf{R})+N\\log(2 \\pi \\sigma_z^2)+N]$</li>\n",
    "  </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/Hyperparameters</b></span>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         1 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38309D+04    |proj g|=  6.00000D+00\n",
      "\n",
      "At iterate    1    f=  9.25867D+03    |proj g|=  5.50347D+00\n",
      "\n",
      "At iterate    2    f=  7.92447D+03    |proj g|=  5.20888D+00\n",
      "\n",
      "At iterate    3    f=  7.91198D+03    |proj g|=  3.82543D+00\n",
      "\n",
      "At iterate    4    f=  7.91179D+03    |proj g|=  5.18306D+00\n",
      "\n",
      "At iterate    5    f=  7.91147D+03    |proj g|=  5.17952D+00\n",
      "\n",
      "At iterate    6    f=  7.91147D+03    |proj g|=  6.25369D-01\n",
      "\n",
      "At iterate    7    f=  7.91147D+03    |proj g|=  2.30648D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     21      8     0     1   2.306D-01   7.911D+03\n",
      "  F =   7911.4719894981426     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.82925D+08    |proj g|=  7.27022D+00\n",
      "\n",
      "At iterate    1    f=  1.64055D+08    |proj g|=  7.18234D+00\n",
      "\n",
      "At iterate    2    f=  5.46604D+07    |proj g|=  6.38906D+00\n",
      "\n",
      "At iterate    3    f=  7.03424D+06    |proj g|=  3.89125D+00\n",
      "\n",
      "At iterate    4    f=  6.37872D+06    |proj g|=  3.92736D+00\n",
      "\n",
      "At iterate    5    f=  1.80367D+06    |proj g|=  5.24698D+00\n",
      "\n",
      "At iterate    6    f=  1.10568D+06    |proj g|=  5.25252D+00\n",
      "\n",
      "At iterate    7    f=  5.08886D+05    |proj g|=  5.25798D+00\n",
      "\n",
      "At iterate    8    f=  2.62714D+05    |proj g|=  5.26040D+00\n",
      "\n",
      "At iterate    9    f=  1.29858D+05    |proj g|=  5.26177D+00\n",
      "\n",
      "At iterate   10    f=  6.52001D+04    |proj g|=  5.26321D+00\n",
      "\n",
      "At iterate   11    f=  3.24223D+04    |proj g|=  5.26645D+00\n",
      "\n",
      "At iterate   12    f=  1.60936D+04    |proj g|=  5.27255D+00\n",
      "\n",
      "At iterate   13    f=  8.01871D+03    |proj g|=  5.28259D+00\n",
      "\n",
      "At iterate   14    f=  7.96959D+03    |proj g|=  5.25658D+00\n",
      "\n",
      "At iterate   15    f=  7.93034D+03    |proj g|=  5.21718D+00\n",
      "\n",
      "At iterate   16    f=  7.91171D+03    |proj g|=  3.82398D+00\n",
      "\n",
      "At iterate   17    f=  7.91147D+03    |proj g|=  2.72121D-01\n",
      "\n",
      "At iterate   18    f=  7.91147D+03    |proj g|=  1.73350D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     26     19     0     1   1.733D-01   7.911D+03\n",
      "  F =   7911.4719763988014     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.09810D+06    |proj g|=  4.25002D+00\n",
      "\n",
      "At iterate    1    f=  2.15219D+04    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1      2      2     0     2   0.000D+00   2.152D+04\n",
      "  F =   21521.869766093121     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.02901D+07    |proj g|=  4.00371D+00\n",
      "\n",
      "At iterate    1    f=  2.15219D+04    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1      2      2     0     2   0.000D+00   2.152D+04\n",
      "  F =   21521.869766093121     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.33502D+08    |proj g|=  7.56883D+00\n",
      "\n",
      "At iterate    1    f=  3.15073D+07    |proj g|=  6.41392D+00\n",
      "\n",
      "At iterate    2    f=  6.58206D+06    |proj g|=  5.45556D+00\n",
      "\n",
      "At iterate    3    f=  4.59412D+06    |proj g|=  5.17817D+00\n",
      "\n",
      "At iterate    4    f=  2.81692D+06    |proj g|=  3.84532D+00\n",
      "\n",
      "At iterate    5    f=  1.28117D+06    |proj g|=  3.81435D+00\n",
      "\n",
      "At iterate    6    f=  6.58552D+05    |proj g|=  5.20194D+00\n",
      "\n",
      "At iterate    7    f=  3.25035D+05    |proj g|=  5.21015D+00\n",
      "\n",
      "At iterate    8    f=  1.63274D+05    |proj g|=  5.21318D+00\n",
      "\n",
      "At iterate    9    f=  8.15148D+04    |proj g|=  5.21331D+00\n",
      "\n",
      "At iterate   10    f=  4.07761D+04    |proj g|=  5.21129D+00\n",
      "\n",
      "At iterate   11    f=  2.03339D+04    |proj g|=  5.20811D+00\n",
      "\n",
      "At iterate   12    f=  1.00936D+04    |proj g|=  5.20607D+00\n",
      "\n",
      "At iterate   13    f=  7.91926D+03    |proj g|=  5.20082D+00\n",
      "\n",
      "At iterate   14    f=  7.91219D+03    |proj g|=  5.18509D+00\n",
      "\n",
      "At iterate   15    f=  7.91191D+03    |proj g|=  3.82510D+00\n",
      "\n",
      "At iterate   16    f=  7.91148D+03    |proj g|=  5.17963D+00\n",
      "\n",
      "At iterate   17    f=  7.91147D+03    |proj g|=  1.22327D-01\n",
      "\n",
      "At iterate   18    f=  7.91147D+03    |proj g|=  1.29876D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     29     20     0     1   1.299D+00   7.911D+03\n",
      "  F =   7911.4719779442448     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.14623D+10    |proj g|=  5.97951D+00\n",
      "\n",
      "At iterate    1    f=  2.15219D+04    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1      2      2     0     2   0.000D+00   2.152D+04\n",
      "  F =   21521.869766093121     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.16324D+10    |proj g|=  2.09323D+00\n",
      "\n",
      "At iterate    1    f=  2.16324D+10    |proj g|=  6.95664D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1     17      2     0     2   6.957D+00   2.163D+10\n",
      "  F =   21632439474.056839     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.66001D+07    |proj g|=  1.82591D+00\n",
      "\n",
      "At iterate    1    f=  2.15219D+04    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1      2      2     0     1   0.000D+00   2.152D+04\n",
      "  F =   21521.869766093121     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.16325D+10    |proj g|=  8.01753D+00\n",
      "\n",
      "At iterate    1    f=  1.88442D+07    |proj g|=  3.95832D+00\n",
      "\n",
      "At iterate    2    f=  4.04523D+06    |proj g|=  5.58668D+00\n",
      "\n",
      "At iterate    3    f=  1.72542D+06    |proj g|=  5.32291D+00\n",
      "\n",
      "At iterate    4    f=  1.02057D+06    |proj g|=  3.85240D+00\n",
      "\n",
      "At iterate    5    f=  6.48565D+05    |proj g|=  3.93775D+00\n",
      "\n",
      "At iterate    6    f=  3.38317D+05    |proj g|=  4.02531D+00\n",
      "\n",
      "At iterate    7    f=  1.81533D+05    |proj g|=  4.08667D+00\n",
      "\n",
      "At iterate    8    f=  9.40693D+04    |proj g|=  4.12801D+00\n",
      "\n",
      "At iterate    9    f=  4.80171D+04    |proj g|=  4.15402D+00\n",
      "\n",
      "At iterate   10    f=  2.42375D+04    |proj g|=  4.16930D+00\n",
      "\n",
      "At iterate   11    f=  1.20926D+04    |proj g|=  4.17681D+00\n",
      "\n",
      "At iterate   12    f=  1.06886D+04    |proj g|=  4.14740D+00\n",
      "\n",
      "At iterate   13    f=  9.47921D+03    |proj g|=  4.08010D+00\n",
      "\n",
      "At iterate   14    f=  8.90069D+03    |proj g|=  4.02187D+00\n",
      "\n",
      "At iterate   15    f=  8.08532D+03    |proj g|=  3.89752D+00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iterate   16    f=  7.96653D+03    |proj g|=  5.25439D+00\n",
      "\n",
      "At iterate   17    f=  7.93202D+03    |proj g|=  5.21945D+00\n",
      "\n",
      "At iterate   18    f=  7.91155D+03    |proj g|=  3.82263D+00\n",
      "\n",
      "At iterate   19    f=  7.91147D+03    |proj g|=  3.37423D-02\n",
      "\n",
      "At iterate   20    f=  7.91147D+03    |proj g|=  7.85803D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     20     27     22     0     1   7.858D-02   7.911D+03\n",
      "  F =   7911.4719800421890     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.16313D+10    |proj g|=  5.83686D+00\n",
      "\n",
      "At iterate    1    f=  2.15219D+04    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1      2      2     0     2   0.000D+00   2.152D+04\n",
      "  F =   21521.869766093121     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.59536D+10    |proj g|=  5.14825D+00\n",
      "\n",
      "At iterate    1    f=  2.15219D+04    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1      2      2     0     2   0.000D+00   2.152D+04\n",
      "  F =   21521.869766093121     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.09427D+07    |proj g|=  4.32909D+00\n",
      "\n",
      "At iterate    1    f=  2.15219D+04    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1      2      2     0     2   0.000D+00   2.152D+04\n",
      "  F =   21521.869766093121     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.16325D+10    |proj g|=  1.29283D+00\n",
      "\n",
      "At iterate    1    f=  2.16325D+10    |proj g|=  7.70717D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1     17      2     0     2   7.707D+00   2.163D+10\n",
      "  F =   21632478019.032082     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.12973D+07    |proj g|=  1.49682D+00\n",
      "\n",
      "At iterate    1    f=  2.15219D+04    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1      2      2     0     1   0.000D+00   2.152D+04\n",
      "  F =   21521.869766091011     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.23671D+05    |proj g|=  3.78823D-01\n",
      "\n",
      "At iterate    1    f=  2.15219D+04    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1      2      2     0     1   0.000D+00   2.152D+04\n",
      "  F =   21521.869766093121     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.77544D+06    |proj g|=  5.96992D+00\n",
      "\n",
      "At iterate    1    f=  1.06863D+06    |proj g|=  5.20418D+00\n",
      "\n",
      "At iterate    2    f=  7.90776D+05    |proj g|=  5.20428D+00\n",
      "\n",
      "At iterate    3    f=  3.34863D+05    |proj g|=  5.21755D+00\n",
      "\n",
      "At iterate    4    f=  1.77844D+05    |proj g|=  5.20161D+00\n",
      "\n",
      "At iterate    5    f=  8.66656D+04    |proj g|=  5.22749D+00\n",
      "\n",
      "At iterate    6    f=  4.34342D+04    |proj g|=  3.81675D+00\n",
      "\n",
      "At iterate    7    f=  2.12964D+04    |proj g|=  5.23592D+00\n",
      "\n",
      "At iterate    8    f=  1.05273D+04    |proj g|=  5.20334D+00\n",
      "\n",
      "At iterate    9    f=  7.91588D+03    |proj g|=  5.19477D+00\n",
      "\n",
      "At iterate   10    f=  7.91194D+03    |proj g|=  5.18393D+00\n",
      "\n",
      "At iterate   11    f=  7.91156D+03    |proj g|=  3.82276D+00\n",
      "\n",
      "At iterate   12    f=  7.91147D+03    |proj g|=  5.17940D+00\n",
      "\n",
      "At iterate   13    f=  7.91147D+03    |proj g|=  8.83847D-01\n",
      "\n",
      "At iterate   14    f=  7.91147D+03    |proj g|=  1.37015D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     50     17     0     1   1.370D+00   7.911D+03\n",
      "  F =   7911.4719763616713     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.16325D+10    |proj g|=  7.41424D+00\n",
      "\n",
      "At iterate    1    f=  2.15219D+04    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1      2      2     0     2   0.000D+00   2.152D+04\n",
      "  F =   21521.869766093121     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.35271D+09    |proj g|=  7.10131D+00\n",
      "\n",
      "At iterate    1    f=  2.92747D+08    |proj g|=  5.79813D+00\n",
      "\n",
      "At iterate    2    f=  1.67156D+08    |proj g|=  5.52292D+00\n",
      "\n",
      "At iterate    3    f=  9.45006D+07    |proj g|=  5.28650D+00\n",
      "\n",
      "At iterate    4    f=  5.87929D+07    |proj g|=  4.05086D+00\n",
      "\n",
      "At iterate    5    f=  2.17199D+07    |proj g|=  5.13957D+00\n",
      "\n",
      "At iterate    6    f=  1.32616D+07    |proj g|=  5.14630D+00\n",
      "\n",
      "At iterate    7    f=  6.03642D+06    |proj g|=  5.15674D+00\n",
      "\n",
      "At iterate    8    f=  3.07446D+06    |proj g|=  3.83323D+00\n",
      "\n",
      "At iterate    9    f=  1.50348D+06    |proj g|=  3.82203D+00\n",
      "\n",
      "At iterate   10    f=  7.50910D+05    |proj g|=  3.81106D+00\n",
      "\n",
      "At iterate   11    f=  3.74026D+05    |proj g|=  5.19991D+00\n",
      "\n",
      "At iterate   12    f=  1.87263D+05    |proj g|=  5.21073D+00\n",
      "\n",
      "At iterate   13    f=  9.38225D+04    |proj g|=  5.22151D+00\n",
      "\n",
      "At iterate   14    f=  4.70471D+04    |proj g|=  5.23225D+00\n",
      "\n",
      "At iterate   15    f=  2.34701D+04    |proj g|=  5.23908D+00\n",
      "\n",
      "At iterate   16    f=  1.16135D+04    |proj g|=  5.24741D+00\n",
      "\n",
      "At iterate   17    f=  7.96196D+03    |proj g|=  5.25093D+00\n",
      "\n",
      "At iterate   18    f=  7.95468D+03    |proj g|=  5.24480D+00\n",
      "\n",
      "At iterate   19    f=  7.91950D+03    |proj g|=  5.20122D+00\n",
      "\n",
      "At iterate   20    f=  7.91166D+03    |proj g|=  5.18218D+00\n",
      "\n",
      "At iterate   21    f=  7.91157D+03    |proj g|=  3.82281D+00\n",
      "\n",
      "At iterate   22    f=  7.91147D+03    |proj g|=  3.22761D+00\n",
      "\n",
      "At iterate   23    f=  7.91147D+03    |proj g|=  7.10952D-01\n",
      "\n",
      "At iterate   24    f=  7.91147D+03    |proj g|=  5.42059D-02\n",
      "\n",
      "At iterate   25    f=  7.91147D+03    |proj g|=  1.93813D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     25     31     27     0     1   1.938D-01   7.911D+03\n",
      "  F =   7911.4719798038668     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.05449D+09    |proj g|=  4.09023D+00\n",
      "\n",
      "At iterate    1    f=  2.15219D+04    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1      2      2     0     2   0.000D+00   2.152D+04\n",
      "  F =   21521.869766093121     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.21227D+05    |proj g|=  7.36271D+00\n",
      "\n",
      "At iterate    1    f=  1.02052D+05    |proj g|=  3.85814D+00\n",
      "\n",
      "At iterate    2    f=  9.94393D+04    |proj g|=  5.31038D+00\n",
      "\n",
      "At iterate    3    f=  3.04996D+04    |proj g|=  5.24057D+00\n",
      "\n",
      "At iterate    4    f=  1.81977D+04    |proj g|=  5.23004D+00\n",
      "\n",
      "At iterate    5    f=  8.39896D+03    |proj g|=  5.21979D+00\n",
      "\n",
      "At iterate    6    f=  7.93075D+03    |proj g|=  5.21773D+00\n",
      "\n",
      "At iterate    7    f=  7.91238D+03    |proj g|=  5.18587D+00\n",
      "\n",
      "At iterate    8    f=  7.91147D+03    |proj g|=  5.17952D+00\n",
      "\n",
      "At iterate    9    f=  7.91147D+03    |proj g|=  7.86622D-01\n",
      "\n",
      "Parameter θ: [0.66187136 0.01      ]\n",
      "At iterate   10    f=  7.91147D+03    |proj g|=  4.08454D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     10     24     12     0     1   4.085D-01   7.911D+03\n",
      "  F =   7911.4719777625669     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    }
   ],
   "source": [
    "from UQpy.surrogates.gaussian_process.regression_models import LinearRegression\n",
    "from UQpy.surrogates.gaussian_process. GaussianProcessRegression import GaussianProcessRegression\n",
    "from UQpy.surrogates.gaussian_process.kernels import RBF\n",
    "from UQpy.utilities.MinimizeOptimizer import MinimizeOptimizer\n",
    "\n",
    "K = GaussianProcessRegression(regression_model=LinearRegression(),\n",
    "                              kernel=RBF(), hyperparameters=[0.1, 0.1], \n",
    "                              random_state=1,optimizer=MinimizeOptimizer(method=\"l-bfgs-b\"), bounds=[[1e-4, 1e5], [1e-5, 1e-2]], \toptimizations_number=20)\n",
    "\n",
    "K.fit(samples=x, values=y)\n",
    "print(r'Parameter θ:', K. hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA/y0lEQVR4nO3dd3hUVfrA8e+ZSSOFBJJQ0+gQQhIgdEE6KChF8SdGBV3FCi66uqxZy7JiWXt30bVHsaIgKAIiIFIMVVIglCQEAoQACSGElDm/P2aIAUPNJHfK+3mePJm5c2fOe8Pwzp1zz3mP0lojhBDC9ZmMDkAIIUT9kIQvhBBuQhK+EEK4CUn4QgjhJiThCyGEm/AwOoCzCQkJ0VFRUUaHIYQQTmX9+vWHtNahNT3msAk/KiqKlJQUo8MQQginopTKPttj0qUjhBBuQhK+EEK4CUn4QgjhJhy2D78m5eXl5ObmUlpaanQoQtSaj48PYWFheHp6Gh2KcBN2SfhKqZHAy4AZeEdr/fQZj0cAHwBBtn1maK0XXmw7ubm5BAQEEBUVhVKq9oELYRCtNQUFBeTm5tKqVSujwxFuotZdOkopM/A6cAUQDUxUSkWfsds/gc+11l2B64E3LqWt0tJSgoODJdkLp6eUIjg4WL6t1iQ5GaKiwGSy/k5ONjoil2GPM/yewA6t9S4ApdQcYAyQVm0fDTS03Q4E9l1qY5LshauQ93INkpNhyhQoKbHez8623gdITDQuLhdhj4u2LYE91e7n2rZV9zhwo1IqF1gITK3phZRSU5RSKUqplPz8fDuEJoRwGsnJMGnSH8keKDV78mtIW979YDEHj8m3odqqr1E6E4H3tdZhwJXAR0qpP7WttZ6ttU7QWieEhtY4UcxwBw4c4IYbbqB169Z0796dPn36MHfu3DpvNyUlhWnTptnltQYOHEiHDh2Ii4ujX79+bNu2zS6va0/VY+zRowebNm0yOqQq8+bN4+mnnz7/juLC2c7sLZUWUpu0YnbPcdx03Uzi7/uUGyY+ycxuExj6/HI+/20PsobHpbNHl85eILza/TDbtur+AowE0FqvVkr5ACHAQTu0X2+01owdO5ZJkybxySefAJCdnc28efPqvO2EhAQSEhLs9nrJyckkJCQwe/ZsHnzwwT8dQ2VlJWaz2W7tXYpTMb733ns8+OCDLF68uNavaY/juvrqq7n66qtrHYv4w8lHHuM/vW/gm+iBFPgFAdDuUDbXb/6R/lkbaervxcy7nuWhr7bwzaa9PDmuC1EhfsYG7YTscYb/G9BOKdVKKeWF9aLsmRkwBxgCoJTqBPgATtdn89NPP+Hl5cWdd95ZtS0yMpKpU609VFlZWfTv359u3brRrVs3fv31VwB+/vlnRo8eXfWce++9l/fffx+AGTNmEB0dTWxsLH/7298A+OKLL4iJiSEuLo4BAwb86TXWrVtHnz596Nq1K3379q06Q3///fcZP348I0eOpF27djz00EPnPaYBAwawY8cOAPz9/XnggQeIi4tj9erVvPDCC8TExBATE8NLL71U9ZwPP/yQ2NhY4uLiuOmmmwDIz8/nmmuuoUePHvTo0YNVq1YBsHz5cuLj44mPj6dr164cO3aMvLw8BgwYQHx8PDExMaxcufKcMfbp04e9e63nEMePH+fWW2+lZ8+edO3alW+//RaAkpISrrvuOqKjoxk3bhy9evWqKs1x5nF9/PHH9OzZk/j4eO644w4qKyuprKxk8uTJxMTE0KVLF1588UUAXnnllap/n+uvv77q73zvvfdW/ZsPHjyY2NhYhgwZQk5ODgCTJ09m2rRp9O3bl9atW/Pll1+e99/CXeUfO0li3zv4X4+x9M7ZwnMLXmDN65NY/L97eHzpbIbkpRLz4F3Mub03T47rwu+5hYx4aQVvLd9JRaXF6PCdSq3P8LXWFUqpe4FFWIdcvqu1TlVKzQRStNbzgAeAt5VS07FewJ2sa/m97F/zU0nbV1Tb8E8T3aIhj13V+ayPp6am0q1bt7M+3qRJExYvXoyPjw+ZmZlMnDjxnPWACgoKmDt3LhkZGSilOHr0KAAzZ85k0aJFtGzZsmpbdR07dmTlypV4eHiwZMkSHn74Yb766isANm3axMaNG/H29qZDhw5MnTqV8PDwP73GKfPnz6dLly6ANZn26tWL559/nvXr1/Pee++xdu1atNb06tWLyy+/HC8vL5544gl+/fVXQkJCOHz4MAD33Xcf06dP57LLLiMnJ4cRI0aQnp7Oc889x+uvv06/fv0oLi7Gx8eH2bNnM2LECJKSkqisrKSkWp9tTX744QfGjh0LwKxZsxg8eDDvvvsuR48epWfPngwdOpQ333yTRo0akZaWxtatW4mPj696fvXjSk9P55lnnmHVqlV4enpy9913k5ycTOfOndm7dy9bt24FqPq7P/300+zevRtvb+8a/y2mTp3KpEmTmDRpEu+++y7Tpk3jm2++ASAvL49ffvmFjIwMrr76aq699tpzHqc7yi44zg1vr6WgWVte/+YpRm1bdfoOZjPMng2JiZiAG3pFMKRTEx75ZitPf5/B/M37eOaaWGJaBhoSv7Oxyzh825j6hWdse7Ta7TSgnz3aciT33HMPv/zyC15eXvz222+Ul5dz7733smnTJsxmM9u3bz/n8wMDA/Hx8eEvf/kLo0ePrjqD79evH5MnT+a6665j/Pjxf3peYWEhkyZNIjMzE6UU5eXlVY8NGTKEwEDrmz86Oprs7OwaE35iYiINGjQgKiqKV199FQCz2cw111wDwC+//MK4cePw87N+bR4/fjwrV65EKcWECRMICQkBoHHjxgAsWbKEtLQ/BmYVFRVRXFxMv379uP/++0lMTGT8+PGEhYXRo0cPbr31VsrLyxk7duxpyfnMGMvKyiguLq7qw//xxx+ZN28ezz33HGAdqpuTk8Mvv/zCfffdB0BMTAyxsbFVr1P9uJYuXcr69evp0aMHACdOnKBJkyZcddVV7Nq1i6lTpzJq1CiGDx8OQGxsLImJiYwdO7bqQ6e61atX8/XXXwNw0003nfatauzYsZhMJqKjozlw4ECNx+jODhSVcsPbaykpq+CLjifp8ubG03fw9a1K9tU1bejD7JsT+GFrHo98m8qY11eRdGUnbr1M5jOcj1PNtK3uXGfidaVz585VZ9IAr7/+OocOHarqW3/xxRdp2rQpmzdvxmKx4OPjA4CHhwcWyx9fPU+Nvfbw8GDdunUsXbqUL7/8ktdee42ffvqJt956i7Vr17JgwQK6d+/O+vXrT4vjkUceYdCgQcydO5esrCwGDhxY9Zi3t3fVbbPZTEVFRY3Hcqp/vDofH59L7t+2WCysWbOm6phPmTFjBqNGjWLhwoX069ePRYsWMWDAAFasWMGCBQuYPHky999/PzfffHONMXbv3p0HH3yQqVOn8vXXX6O15quvvqJDhw4XHFv149JaM2nSJJ566qk/7bd582YWLVrEW2+9xeeff867777LggULWLFiBfPnz2fWrFn8/vvvF9xu9X8LudB4utLySm557zeOlJTx2ZQ+dAkLhAaVkJQEOTkQEQGzZp1zKObImOb0aRPCg19sZuZ3aUQG+zKkU9N6PArnI7V0LsLgwYMpLS3lzTffrNpWvTuisLCQ5s2bYzKZ+Oijj6isrASs/fxpaWmcPHmSo0ePsnTpUgCKi4spLCzkyiuv5MUXX2Tz5s0A7Ny5k169ejFz5kxCQ0PZs6f6qFdrOy1bWke+nroWYG/9+/fnm2++oaSkhOPHjzN37lz69+/P4MGD+eKLLygoKACo6tIZPnx41TcFoOqMfOfOnXTp0oW///3v9OjRg4yMDLKzs2natCm33347t912Gxs2bDhrHEop/v3vf7NmzRoyMjIYMWIEr776alUC3bjRelbYr18/Pv/8cwDS0tLOmpiHDBnCl19+ycGDB6viz87O5tChQ1gsFq655hqeeOIJNmzYgMViYc+ePQwaNIhnnnmGwsJCiouLT3u9vn37MmfOHMD6AdW/f/+L+ju7q5nfpZGWV8RrN3S1JnuwJvesLLBYrL8vYNx9YANPXpnYlZiWDfnrZ5vYd/REncbt7Jz2DN8ISim++eYbpk+fzn/+8x9CQ0Px8/PjmWeeAeDuu+/mmmuu4cMPP2TkyJFV3SHh4eFcd911xMTE0KpVK7p27QrAsWPHGDNmDKWlpWiteeGFFwB48MEHyczMRGvNkCFDiIuLY/ny5VVxPPTQQ0yaNIknnniCUaNG1cmxduvWjcmTJ9OzZ08Abrvttqq4k5KSuPzyyzGbzXTt2pX333+fV155hXvuuYfY2FgqKioYMGAAb731Fi+99BLLli3DZDLRuXNnrrjiCubMmcOzzz6Lp6cn/v7+fPjhh+eMpUGDBjzwwAM8++yzvPbaa/z1r38lNjYWi8VCq1at+O6777j77ruZNGkS0dHRdOzYkc6dO1d1bVUXHR3NE088wfDhw7FYLHh6evL666/ToEEDbrnllqpvYk899RSVlZXceOONFBYWorVm2rRpBAUFnfZ6r776KrfccgvPPvssoaGhvPfee3b467u273/P45O1OUwZ0JrBHWt/Ru7jaeaNG7oz/KXlPD4vldk32280m6tRjvpVMyEhQZ95wTM9PZ1OnToZFJFwZJWVlZSXl+Pj48POnTsZOnQo27Ztw8vLy+jQzsnd3tO5R0q48uWVtArx44s7++LlYb9OhreW7+Tp7zOYfVN3hnduZrfXdTZKqfVa6xo/9eQMX7iEkpISBg0aRHl5OVpr3njjDYdP9u6motLCfXM2YdHwysSudk32AH+5rBXfbNzL4/NS6dc2BD9vSW9nkr+IcAkBAQGyJKaD+3RdDuuzj/DS/8UTGWz/SVOeZhOzxsVwzZureXHxdv45+swajkIu2goh6tzRkjKeX7ydPq2DGRPfos7a6R7ZmIk9I3jv1yy27i2ss3aclSR8IUSde2lJJkUnynn0qug6rxI6Y2RHGvl6kjT3dywWx7xGaRRJ+EKIOpV54Bgfrcnmhl4RdGre8PxPqKVAX08evrITm3ML+SF1f52350wk4Qsh6ozWmpnfpeHnZeb+YRc+Wa62xsS3pHWoH68szZSz/Gok4V+EgoKCqkJgzZo1o2XLllX3y8rKzvncCy1v3LdvX3uFe5qBAwee96LmSy+9dN66NkJcjKXpB1mZeYjpw9rT2K/+Rk2ZTYqpg9uSsf8Yi9OlrMUpkvAvQnBwMJs2bWLTpk3ceeedTJ8+veq+l5fXWcsYgLW88SuvvHLeNk5V2DSCJHxhTxaL5j+LMmgT6seNvSPrvf2rYlsQFezLK0szpbSFjWsn/HpYG3Py5Mnceeed9OrVi4ceeuispYurlzd+/PHHufXWWxk4cCCtW7c+7YPA39+/av+BAwdy7bXX0rFjRxITE6vetAsXLqRjx450796dadOmnVZ6+ZQTJ05w/fXX06lTJ8aNG8eJE39MOb/rrrtISEigc+fOPPbYY4C1DPC+ffsYNGgQgwYNOut+QlyoRan72X6gmGlD2uFprv9U42E2cc+gtqTuK+LnbU5Xjb1OuO44/HpcGzM3N5dff/0Vs9lMUVHRWUsXV5eRkcGyZcs4duwYHTp04K677sLT0/O0fTZu3EhqaiotWrSgX79+rFq1ioSEBO644w5WrFhBq1atmDhxYo0xvfnmm/j6+pKens6WLVtOK+s8a9YsGjduTGVlJUOGDGHLli1MmzaNF154gWXLllVVwqxpv+pVKIU4G601r/y0g9YhfoyOrbthmOcztmtLnvtxG+//msWgjk0Mi8NRuO4ZflLSaWtjAtb7SUl2b2rChAlV1RgLCwuZMGECMTExTJ8+ndTU1BqfM2rUKLy9vQkJCaFJkyY1ls/t2bMnYWFhmEwm4uPjycrKIiMjg9atW9OqlbUU7NkS/ooVK7jxxhsBa4nf6on6888/p1u3bnTt2pXU1NTTyhpXd6H7CXGmJekHSc8r4p5BbTGbjFus3dNsYmLPCJZvzyfr0HHD4nAUrpvwbSsPXfD2WjhVJA3+KF28detW5s+fX1UK+UwXUsb4QksdX4zdu3fz3HPPsXTpUrZs2cKoUaNqjPFC9xPiTFprXv0pk4jGvnU6yepC3dAzAg+T4qM12UaHYjjXTfgRERe33U7qunRxhw4d2LVrF1lZWQB89tlnNe43YMCAqnV3t27dypYtWwDrwiR+fn4EBgZy4MABvv/++6rnBAQEcOzYsfPuJ8S5rMg8xJbcQu4e2AYPA/ruz9SkoQ8jY5rxRcoeTpRVGh2OoYz/16grs2ZZV8ypztfXur0OPfTQQ/zjH/+ga9eudjkjP1ODBg144403GDlyJN27dycgIKDGMsB33XUXxcXFdOrUiUcffZTu3bsDEBcXR9euXenYsSM33HAD/fr9sRDZlClTGDlyJIMGDTrnfkKcy/urdtMkwJvx3cKMDqXKzX2iKCqt4NtNe40OxVCuXR45OfmiVtBxFsXFxfj7+6O15p577qFdu3ZMnz7d6LDEJXC18sg5BSVc/twypg5ux/3D2hsdThWtNVe8bF2ic+G0y+q8vIORzlUe2XXP8OGSVtBxBm+//Tbx8fF07tyZwsJC7rjjDqNDEgKA5HXZmJRiYs8/r6NsJKUUN/eJIj2viPXZR4wOxzCunfBd1KkJX2lpaSQnJ+N7ZteVEAYoLa/ki5RchnVqSvPABkaH8ydju7bA39uDOb/tOf/OLsouCV8pNVIptU0ptUMpNeMs+1ynlEpTSqUqpT651LYctQtKiIvlau/l77fmcfh4mSGzai+Er5cHo7o0Z+HveZSU2f/6mjOodcJXSpmB14ErgGhgolIq+ox92gH/APpprTsDf72Utnx8fCgoKHC5/yjC/WitKSgowMfHx+hQ7Oaj1dm0DvGjb5tgo0M5q/HdWlJSVsniNPesr2OPmbY9gR1a610ASqk5wBig+iyd24HXtdZHALTWBy+lobCwMHJzc8nPl2nSwvn5+PgQFuY4I1lqI3VfIRtyjvLI6GhMBk60Op8eUY1pEejDNxv3Mia+pdHh1Dt7JPyWQPVOsVyg1xn7tAdQSq0CzMDjWusfznwhpdQUYApARA3j5T09PatmmAohHMfHa3Lw8TRxrQMNxayJyaS4Or4lb6/cRUHxSYL9vc//JBdSXxdtPYB2wEBgIvC2UirozJ201rO11gla64TQ0NB6Ck0IURtFpeV8s3EvV8e1INDX8/xPMNjYri2otGgW/J5ndCj1zh4Jfy9QfQxWmG1bdbnAPK11udZ6N7Ad6weAEMLJzd2wlxPlldzUO8roUC5Ix2YN6dgsgG82ut8kLHsk/N+AdkqpVkopL+B6YN4Z+3yD9ewepVQI1i6eXXZoWwhhIK01H63JJi48iC5hf57x7ajGxLdkQ85Rcgrca/2HWid8rXUFcC+wCEgHPtdapyqlZiqlrrbttggoUEqlAcuAB7XWBbVtWwhhrDW7DrPjYDE39qrbGlX2Njq2OQA/prnXmrd2qYevtV4ILDxj26PVbmvgftuPEMJFfLwmm8AGnlwVZ3xVzIsR3tiXjs0CWJx2gNv6tzY6nHojM22FEJfkYFEpi1L3c11CGD6eZqPDuWjDo5vyW9Zhjhw/93rUrkQSvhDiknz22x4qLJobejnmzNrzGRrdFIuGZdsuaVqQU5KEL4S4aFprvtqQS+/WjWkV4nf+JzigmBaBNG3o7VazbiXhCyEu2qY9R8kqKGF8V8eeaHUuJpNiaKemLN+eT2m5eyyMIglfCHHR5m7ci7eHiSu6NDM6lFoZGt2UkrJK1uxyj0GDkvCFEBelrMLC/M37GBbdlAAfx59Zey592wTj52V2m24dSfhCiAuTnAxRUSyP7suRknLGF2YaHVGteXuYGdA+lCXpB9yiCq8kfCHE+SUnw5QpkJ3N3OhBBB8/Sv+Hbrdud3JDOzXlQNFJft9baHQodU4SvhDi/JKSoKSEQm8/lrTtydXpy/EsPmbd7uQGd2yCScESN+jWkYQvhDi/nBwAFna8jDIPL8Zv/em07c6skZ8XCVGNWZzu+uPxJeELIc7Ptj7F/I4DaF2wh5gDO0/b7uyGdWpKel4Rew67djE1SfhCiPObNYtDwc1YExHD6IxfUAC+vjBrltGR2cXQ6KYALE137W4dSfhCiPNLTOSHR1/BYjJz5bZVEBkJs2dDYqLRkdlFqxA/2jbxZ4mLd+tIwhdCnJttOObC1Zm0KdxPhxeegKwsl0n2pwzt1JQ1uwooPFFudCh1RhK+EOLsbMMxD+UfZU14DKO2LkPdMcUlhmOeaVh0UyosmuXb840Opc5IwhdCnJ1tOOYP7ftiMZkZlfELlJS4xHDMM8WHBxHi7+XSs24l4Qshzs427HJBx8toU7CH9oeyT9vuSswmxeXtm7AyM59Ki2vOupWEL4Q4u4gI8n2DWBsew6iMldbRObbtrmhA+xCOlpS77KxbSfhCiLObNYsfYi63deessm5zoeGYZ+q/eTkAK6+/E6KiXO5ahSR8IcTZJSaycPRk2hbm0b4gx+WGY54mOZnGd99O9IGdrA6Phexsa/0gF0r6kvCFEGeVf+wka0s8uXL8AJTF4pLDMavYLlD3zd5CSlgnSs2eLneB2i4JXyk1Uim1TSm1Qyk14xz7XaOU0kqpBHu0K4SoWz+k7seiYXRsc6NDqXu2C9F9szdT5uHFhpYdT9vuCmqd8JVSZuB14AogGpiolIquYb8A4D5gbW3bFELUjwVb9tG2iT/tmwYYHUrds12I7pGbitlSyerIOOv2xo0NDMq+7HGG3xPYobXepbUuA+YAY2rY79/AM0CpHdoUQtSxg8dKWbf7MFd2cYOze7BeiPbyIqDsBLF5mfwaEWvdXlTkMv349kj4LYE91e7n2rZVUUp1A8K11gvs0J4Qoh4s2upG3TlgvTYRYP0m0ydnC5ubt6fYqwGUl7tMP36dX7RVSpmAF4AHLmDfKUqpFKVUSn6+605vFsIZLPg9z326c045fBiw9uNXmD34LczWO+0i/fj2SPh7gfBq98Ns204JAGKAn5VSWUBvYF5NF2611rO11gla64TQ0FA7hCaEuBQHj5WydvdhRrlLd84ptn787nsz8KooZ/Wpbh0XmWhmj4T/G9BOKdVKKeUFXA/MO/Wg1rpQax2itY7SWkcBa4CrtdYpdmhbCFEHFm3dj9Ywyl26c06ZNQt8fWlQcZKu+zL4NTLOpSaa1Trha60rgHuBRUA68LnWOlUpNVMpdXVtX18IUf/csjsHrP34s2dDZCR9c7aQ2rQ1R99422XmHtilD19rvVBr3V5r3UZrPcu27VGt9bwa9h0oZ/dCOK6C4pPW0TkxzYwOxRiJiZCVRd+PX0MrE2u6DzY6IruRmbZCiNMsTT+IRcPwzm6a8G3iwoJo4Glm9c5DRodiN5LwhRCnWZS6n5ZBDejcoqHRoRjKy8NEj1aN+XVngdGh2I0kfCFEleKTFazMPMSIzs1QSp3/CS6ub5tgMg8Wc/CYa8wXlYQvhKjy87aDlFVaGNG5qdGhOIS+bYIBWO0iZ/mS8IUQVRalHiDYz4uEKNepH1MbnVsEEuDjIQlfCOFaTlZUsizjIEM7NcVsku4csC572Lt1sMv040vCF0IA8OvOAopPVjAiRrpzquvbJpicwyXkHikxOpRak4QvhABgcdoBfL3M9G0TYnQoDuXU38MVunUk4QshsFg0i9MOMLBDKD6eZqPDcSjtm/oT7OclCV8I4Ro25x4l/9hJhkVLd86ZlFL0bmPtx9daGx1OrUjCF0LwY9oBzCbF4A6S8GvSt00w+4tK2X3ouNGh1IokfCEEP6bup3frxgT6ehodikM61Y/v7KN1JOEL4eZ25RezM/84wzrJ2f3ZRAX70rShN+t2HzY6lFqRhC+Em1uSfgCAodJ/f1ZKKXpENWbd7sNO3Y8vCV8IN7c47QCdmjckrJGv0aE4tJ6HdrK/qJTcxi0gKsopFzaXhC+EGysoPsn67CMyOud8kpPp8dyjAKxrGQ3Z2TBlitMlfUn4QrixpRm22veS8M8tKYkOe7bRsLSY38I7W7eVlEBSkrFxXSRJ+EK4sSVpB2ge6OP2te/PKycHE5qE3DTWhUWftt2ZSMIXwk2VlleyMvMQQzs1ldr35xMRAUDPPansCg7nkG/gadudhSR8IdzUL5mHOFFeKf33F2LWLPD1pUduKgApYdHg62vd7kQk4QvhppakH8Df24PerYONDsXxJSbC7Nl08S7Dp/wk66L7wOzZ1u1ORBK+EG7IYtEsST/I5R1C8fKQNHBBEhPx2rWT+A7NWTd4rNMle7BTwldKjVRKbVNK7VBKzajh8fuVUmlKqS1KqaVKqUh7tCuEuDQb9xzlUPFJGZ1zCXpGNSZtXxHHT1YYHcpFq3XCV0qZgdeBK4BoYKJSKvqM3TYCCVrrWOBL4D+1bVcIcemWpB/Aw6QY2L6J0aE4na6RjbBoa4VRZ2OPM/yewA6t9S6tdRkwBxhTfQet9TKt9anlYtYAYXZoVwhxiRanHaBnKymWdim6hTcCYEP2EYMjuXj2SPgtgT3V7ufatp3NX4Dva3pAKTVFKZWilErJz8+3Q2guKjnZOrXbZDr3FO8L3U+4ld2HjrPjYLGMzrlEgb6etG3iz4aco0aHctHq9WqNUupGIAF4tqbHtdaztdYJWuuE0NDQ+gzNcZ2ZtO++2zqlOzsbtKZ8Ty57/pbEjv99SnpeEdsPHKO0vNL6vGr7kZ0NN91kfb5wa0vSbMXSpDrmJese0YgNOUecrpCahx1eYy8QXu1+mG3baZRSQ4Ek4HKt9Uk7tOv6TiXtEmtvWNmevaQs/JUtMVewLTSS9Cat2BkcRrnZEzKBl1cCYFIQWXiSdiOm0/5QNu0P5dAvaxPBJ4rgrbegXz+nHGEg7GNx2gE6NgsgvLEUS7tU3SKD+CxlD7sOHadNqL/R4VwweyT834B2SqlWWBP99cAN1XdQSnUF/guM1FoftEOb7iEpiYoTpfzcpiffdB7I8tbdOebtB0Dzonw65GczcFcKrY7sw6eiDK85n1JWaWHnwWK2v/krmSHhLG3bk0qTGbOlkn5Zm5jw+xKu+Ot0PJKSrNPCIyKsk0fkA8AtHD5eRkr2Ye4d1NboUJxa90hrP/767CPulfC11hVKqXuBRYAZeFdrnaqUmgmkaK3nYe3C8Qe+sE3hztFaX13btl3ZwaJSPowYwGejh5Hv35jg40cZlfELQzPXkrA3jaDS4tOfEBkJXZr/cX9KMmRnc9LswfaQSBZ2uIx50QOYOubvhB3dz9TVnzFB52A6VfUPJOm7gaXpB7BoGBbdzOhQnFrrEH8a+niwMecI1yWEn/8JDkI5ah9UQkKCTklJMTqMerf36Ale+ymTr9bvpaK8gsE7f+O6LT8yaFcKnpZK605KWfvlT/H1/fOsv+Rka599tf0sKJa07ckbfSawqUVHEnJTmbXoDTocyrZ+YGRl1c9BCsPc8VEKm/cUsvofg6V+Ti1Nfm8d+46e4MfplxsdymmUUuu11gk1PSZT7BxE/rGT/Gt+KoOe/Zmv1u/luh5hLOtYzDs/PM/wHWv/SPa+vnDnndYErZT1d01TvBMTrftV+09tQjN8x1rmfvQ3nl3wIjsbhzFq8ss8dflkSvIO1OPRCiOUlleyYvshhkY3kWRvB90iGpF5sJjCE+VGh3LBJOHXtzNG3ZR+lMzry3Zw+bPL+HB1NuO7tWTZgwN5YmwXIm+daE3mZyb3N96wno1bLNbfZ+uKeeMN+Oij058fHIwCJmxdytJ37mJc6jL+2/tahk35L2t3OfcCzeIckpNZdfkYa7G0px+SIbp20C2iEVrDpj1HjQ7lgknCr09nDJVcZg5l+K+lPLtoG/3bhbB4+gCeviaWlkEN/nhOYuKFJfezOfP5L79s/ZYAND5RxLPfv8xnXz2GV6MgbnhnLe+s3OV0Q83Eedx9N9x0E0satsL/ZAm9U5Y45WpNjiYuPBCTcq4JWJLw61NSEpSUkO8bxL1XP8QtEx7Hq7yM5GWv8N+bEmhdH1f7bVX/qp/193p8OvMevoJhnZryxIJ0nv4+Q5K+q0hOhrfewqJhSdueXL57Pd6VFU65WpOjCfDxpH3TADbkOE/Ct8ewTHGBdE4OX3QZxqxBt3LC04f7V37MnWu+xEtX1m8giYl/+qYQALyR2I3H5qXy3xW7KKu08OjoaOnrdXZJSaA1m1p0IN+/McMy1/7xmJOt1uSIukc2Yt6mfVRaNGaT4/9fkYRfT/YdPcHfb/4PK5t1oseeVJ764VXaHs61PhjpGMVDTSbFzDGd8TSbeHfVbsorLcy8OgaTE7yRxVnYkvqP7XrjUVnBoJ2//fGYk63W5Ii6RTQieW0OmQeP0bGZ4y8TKQm/jmmt+XJ9LjPnp1HZoiP/Xvo2ievmYcLWZeJgq+YopXhkdCc8PRT/Xb6L8grNU+O7SNJ3VhERkJ3Nj+1603vP7wSePG7drpRDve+c1akJWBuyjzpFwpc+fHurNgrnYMdYbn/yWx78cgudWjTkhwcGc9O0CZgiI849pNJgSilmjOzItMFt+SxlD3/7cjOVFunTd0qzZrGjZVt2BYczfPsa6zalrEN2Hex954wig31p7OflNP34coZvT7ZROLqkhPmdBvDosDs5cUTzSPgJbrm9t/UsuYb+c0eklOL+4R3wNJt4fvF2yis1L14Xh4dZzhGcSmIiiw56wwEYtmOt9SRDSmnYjVKKbhFBTjNSRxK+PSUlscfDn0evfZBlbXoQt28bzy94kbYBZrjvWqOjuyRTh7TD08PE099n4O/twZPjYuRCrpP50as5cWGa5kVScrwudItsxJL0gxw+XkZjPy+jwzknSfh2UlFp4d2m3Xlx/A0oNI8snc2k9d/hoS1wxLkT5J2Xt6HoRDlv/LyT1iF+3D6gtdEhiQu0v7CUzXuO8uCIDkaH4rK6RVj78TfmHGGIg5ecloRvB5v3HOUfX/9O2qBbGZq5ln8tfouWx6qdTbnAaIi/De/A7kPHeer7dDq3aEjftiFGhyQuwOK0/QCM6OzYiciZxYUFYTYpNjhBwpcO2VooPlnB4/NSGffGKg4Vn+TNiOO8/cPzpyd7BxuFc6lMJsWzE+JoE+rPPZ9sIPdIyfmfJAz3Y9oBWof4OVUJX2fTwMtMdPOGrHeCfnxJ+Jfox9T9DHthOR+szuLG3pEseeByrrj7OlRNtW9c5AKZv7cH/72pOxWVmjs/Xm9dWUs4puRkCtt1YnXGfoavmIv65BOjI3Jp3SMbsXlPIRWVFqNDOSdJ+Bdp2/5jTPkwhSkfrSewgSdf3dWXmWNiaOhjWwy6trVvHFzrUH9euj6erXuLeHju71KCwRHZRost82pGhdmD4esXSe2cOtY1IogT5ZVk7D9mdCjnJAn/Am3MOcJtH6Qw4qUV/LLjEH8f2ZH5Uy+rumDjToZ0asr0oe35esNePk/Zc/4niPplq9m0qH0fmhwrIH7fdqmdU8eqJmA5+Hh8l7xou2BLHt0ig2ge2OD8O5/DkeNlLEk/wOcpe/gt6wiBDTz569B2TO4bRZCvYw+/qmtTB7dlza4CZs5Po2+bEFkf1ZHk5FDq4cXyVt0Yl7rsj1ndUjunzrQMakCTAG/WZx/h5j5RRodzVi6X8HOPlHDPJxsA6yy4ruFBxIUH0SKoAQ08zfh4mm2/TfjY7vt4mmjgaeZ4WSXbDxxjzc4Cft6ez8acI1g0tArxI+nKTkzsFYG/t8v9yS6J9SJuLCNfWskDX2xmzqmJZcJ4ERH84tGUEq8GDM9cc9p2UTesE7AayRl+fWsR2IAF0y5j9c4C1u0+zK87C/hm076Lfp24sEDuHdyOQR1CiQ8PkslGNQhr5MtjV0Xz4JdbeHfVbm7rL+PzHcKsWfw4ZwMBJ4/TJ3uLdZuLjBZzZN0jG/FD6n4OHiulSYCP0eHUyOUSvsmk6NwikM4tAqsS0P7CUg4Vn6S0vJIT5ZWUlltsvys5WW2bl4eJdk38iQ8PItjf2+AjcQ7Xdg9jUeoB/rNoG5e3D6Vd0wCjQ3J7lRNvYElaQwbtWm8tvS3lFOpFt8ggwFpIbWSMYy4S73IJvybNAn1oFuiYn7jOTinFU+O7MOKlFUz/fBNz7+6Hp9TbMVRK1mEOV5oY8Y874NPHjQ7HbXRuEYiX2cSGnCMOm/Dt8j9TKTVSKbVNKbVDKTWjhse9lVKf2R5fq5SKske7wjGEBnjz5LgubN1bxKs/7TA6HLf3Y9oBvMwmLu8QanQobsXH00znlg0dupBarRO+UsoMvA5cAUQDE5VS0Wfs9hfgiNa6LfAi8Ext2xWOZWRMM8Z3bcnry3aw2YkWdXY1WmsWpe6nX9tgGWBggG4Rjdiyt5CyCsecgGWPM/yewA6t9S6tdRkwBxhzxj5jgA9st78Ehii5CupyHru6M00CvJn++SaZhWuQ9Lxj5B45wYjOjtml4Oriw4Moq7CQsb/I6FBqZI+E3xKoPvsm17atxn201hVAIRB85gsppaYopVKUUin5+VLK1dkENvDk2Wvj2JV/nNeka8cQi1L3oxQOX8TLVcWHBwGwyUG/5TrU1TWt9WytdYLWOiE0VPofndFl7UIY360l/12xkx0HHXuauSv6Me0ACZGNCA2QUWZGCGvUgBB/LzblHDU6lBrZI+HvBcKr3Q+zbatxH6WUBxAIFNihbeGAHr6yE75eHjw8d6vU2qlH2QXHSc8rku4cAymliA9v5NJn+L8B7ZRSrZRSXsD1wLwz9pkHTLLdvhb4SUsmcFkh/t7MuKIj63Yf5qsNZ372i7ry/VZr7XtHHRLoLrpGBLHr0HEKS8qNDuVPap3wbX3y9wKLgHTgc611qlJqplLqattu/wOClVI7gPuBPw3dFK7l/xLC6RYRxJML0zlyvMzocNzCwt/ziA0LJKyR1DUyUlxYEABb9h41NI6a2KUPX2u9UGvdXmvdRms9y7btUa31PNvtUq31BK11W611T631Lnu0KxyXyaSYNa4LhSfKeeaHDKPDcXnZBcfZklvI6NjmRofi9rqEBQI45PBkh7poK1xLp+YN+ctlrZjz2x6HLyrl7Bb8ngfAlV0k4RstsIEnbUL92LSn0OhQ/kQSvqhT04a0o0mAN4/PS8Vikcs2deW7zXl0jQiS7hwHERcexKY9Rx1u0IIkfFGn/L09ePjKTmzJLeSL9bJYSl3YlV9MWl4Ro2NbGB2KsIkPD+JQ8Un2FZYaHcppJOGLOjcmvgUJkY34zw/bKDzheCMXnN13W/JQCkZJd47DOHXh1tH68SXhizqnlOLxqztzuKSMl5dkGh2Oy/luyz56RDaWirAOpGPzALzMJkn4wj3FtAzk+h7hfLg6ix0Hi40Ox2VsP3CM7QeKGR0nZ/eOxNvDTKcWDR1uApYkfFFvHhjegQaeZmYtSDM6FJfx3eZ9mBRcESMJ39HEhwXy+95CKh1osIIkfFFvQvy9mTqkLcu25bNiuxTHqy2tNd9tyaN362CpneOA4iOCKCmrdKhvtJLwRb2a1DeKyGBfnliQRkWlY9YMdxZpeUXsOnRcRuc4KEe8cCsJX9Qrbw8z/7iiI9sPFPNZigzTrI3vtuRhNimpneOgooL9aOjjwUZJ+MKdjejcjJ5RjXlx8XaOlcowzUth7c7ZR982wTT28zI6HFEDk0kRGxbEltyjRodSRRK+qHdKKf45uhOHist4a8L9YDJBVBQkJxsdmtPYklvInsMnuEq6cxxal7BAtu0/5jArwEnCF4aIXb6AsRkreaf9IPb5B0N2NkyZIkn/Ai34PQ9Ps5La9w4uLiyQCosmLc8xljyUhC+MkZTE35a9i1aK5/rfZN1WUgJJScbG5QS01izYkkf/dqEE+noaHY44h9hTpZIdpB9fEr4wRk4OYUX53JryLXNjBrG1Seuq7eLcNuQcZe/RE1IK2Qk0D/QhxN+bLbmOUTlTEr4wRkQEAHev/oKgE8d4ctBf0NW2i7ObuzEXH08Tw6JloXJHp5QiLiyQzQ5y4VYSvjDGrFng60vDshLuW/Upv0bF8XOnftbt4qxKyyuZt2kfIzo3I8BHunOcQWyYdclDRxiRJglfGCMxEWbPhshIbti8iKhjB3lywkNUXD/R6Mgc2tL0gxSVVnBNtzCjQxEXKDY8EK1h617jL9xKwhfGSUyErCy8KsqYcddIMk+a+WJ9rtFRObSvNuTSrKEP/dqGGB2KuEBVa9w6QLeOJHzhEEZ0bkZCZCOe/3E7x09WGB2OQ8o/dpLl2/MZ160lZpMyOhxxgRr7eRHWqIFDXLiVhC8cglKKh0d14lDxSWavkDXua/Ltpr1UWrR05zihuLAgh7hwW6uEr5RqrJRarJTKtP1uVMM+8Uqp1UqpVKXUFqXU/9WmTeG6ukU0YlRsc2av2MWBIsdaGs5oWmu+XJ9LXHgQbZv4Gx2OuEixYYHkHjlBQfFJQ+Oo7Rn+DGCp1rodsNR2/0wlwM1a687ASOAlpVRQLdsVLurvIzpSYbHwwo/bjQ7FoaTuKyJj/zGu7dbS6FDEJaiagLXX2G6d2ib8McAHttsfAGPP3EFrvV1rnWm7vQ84CITWsl3hoiKCfbm5TxRfrN9Dxn7jRzU4iq825OJlNnFVnNTOcUZdwgJRCrbsce6E31RrnWe7vR8450wQpVRPwAvYeZbHpyilUpRSKfn5skCGu5o6uC3+3h48tTDD6FAcQnmlhXmb9jGkUxOCfKUypjPy9/agTai/4SN1zpvwlVJLlFJba/gZU30/rbUGzrqWl1KqOfARcIvWusaVL7TWs7XWCVrrhNBQ+RLgroJ8vZg6uB3Lt+ezMlM++H/elk/B8TKu7S4Xa51ZbFggm3MLsaZKY5w34Wuth2qtY2r4+RY4YEvkpxL6wZpeQynVEFgAJGmt19jzAIRrurlvJGGelcx67msqzR5uXT75s9/2EOLvzYD2chLkzOLCgjhUfJK8QuMGJNS2S2ceMMl2exLw7Zk7KKW8gLnAh1rrL2vZnnAT3p/N4aH5r5LRKIyvowe6bfnkPYdLWLbtIBMSwvA0yyhqZxYbFggYOwGrtu+gp4FhSqlMYKjtPkqpBKXUO7Z9rgMGAJOVUptsP/G1bFe4uqQkrtq8hLh923h+wE2c8PB2y/LJ763KQgE39Y40OhRRS52aN8TDpNhs4ASsWiV8rXWB1nqI1rqdrevnsG17itb6Ntvtj7XWnlrr+Go/m+wQu3BlOTkoIGnZu+wPCOF/PcZUbXcXRaXlfPZbDqNim9MiqIHR4Yha8vE007F5gFOf4QtRN2xlknvmpjJ8+2re7HUt+b5BblU+ec66HI6XVXJ7/9ZGhyLsxLrGbSEWizEXbiXhC8dkK58M8Pfl71Pq6c1LA292m/LJ5ZUW3luVRe/WjYlpGWh0OMJO4sICOVZaQVbBcUPal4QvHFO18sltjuzjxh0r+bTLMNIGXWV0ZPVi4e955BWWytm9i6macWtQP74kfOG4bOWTsViY/vEsAn29eHxeqqHjmOuD1pq3V+6idagfgzo0MTocYUftls7Hp6KMzQ/+y5ChxpLwhVMI8vXibyM6sC7rMPO35J3/CU5sza7DbN1bxG2XtcYkZZBdR3IyHndMIWZ/JluatTNkqLEkfOE0ru8RQecWDXlyQbpL18x/Z+Uugv28GC+F0lxLUhKUlBCbl0lq09ZUKFO9DzWWhC+chtmk+NfVndlfVMobP+8wOpw6sTO/mKUZB7mxdyQ+nmajwxH2ZBtSHJeXSamnD9tDIk/bXh8k4QunkhDVmHFdW/L2it1kHTJmpENd+t8vu/HyMHFTH5lo5XJsQ4pj92cCsKV5u9O21wdJ+MLpzLiiI55mxRML0owOxa4Kik/y1fpcxndtSYi/t9HhCHuzDTWOOrKPhqXFbG7e3jr0uB6HGkvCF06naUMfpg5px5L0gyzbVmO9Pqf08ZocTlZYuK1/K6NDEXXBNtRYRUYSuz+TzZGdrUOPExPrLQRJ+MIp3dqvFa1D/Jg5P42yihqrbTuV0vJKPlqTxaAOobRtEmB0OKKu2IYax06+lm3BEZRed329Ni8JXzglLw8Tj14Vze5Dx3l31W6jw6m1bzbu5VBxmUy0chOxYUFUWjSp++p3VTdJ+MJpDezQhKGdmvDq0kz2G1hjvLYsFs07v+wmunlD+rQJNjocUQ/iwo0plSwJXzi1R0ZHU2HRPPjlZsMKUtXW8sx8dhws5vYBrVBKJlq5g2YNfQgN8K73EguS8IVTiwz245HR0azMPOS0XTvvrNxFs4Y+jI6VBcrdhVKKuLBANssZvhAXJ7FXBMOim/LMDxls3Wvc4hKXInVfIat2FDC5X5SsaOVmYsOC2JV/nKLS8nprU95hwukppXjmmlga+3lx35yNnCirNDqkC6K15unvMwjw8WBiT/ep8y+s4sKDANhaj906kvCFS2js58UL18WzK7+Yf9+QBCaT4y58npwMUVEs6dCHlZmHuL9REYENPI2OStSzWNs6B/W55KEkfOEy+q1dxJT18/ikbX9+aNvbMRc+T06GKVMozd3HvwfdRvv8bG78518cK0ZRLxr5eRHR2LdeR+pIwheuIymJB356jy55mcy4Yir7/YMdb+FzW8XE//UYS06j5jy2dDaexcccK0ZRb2LDAut1pI4kfOE6cnLwslTw8vxnOWn2Yvro+6lUJsda+Dwnh7yAYF7r839csW0V/bI3V20X7icuLIi9R09wqPhkvbQnCV+4DlvVwdZH9vGvJf9ldWQcs3uOc6yFzyMieGrgLViU4uGf/nfaduF+YsPqdwJWrRK+UqqxUmqxUirT9rvROfZtqJTKVUq9Vps2hTiragufT/h9MaMyVvJ8/5vYnPS0wYH9Yd3DTzMveiB3rv2K8CJb4bd6rpgoHEdMy0BMCjbtqZ9undqe4c8Almqt2wFLbffP5t/Ailq2J8TZVVv4XCnFk6nf0sTHxH17fDnetoPhI3cqKi08dqIlLT0t3Jm3DpSCyMh6r5goHIeftwftmwawec/Remmvtgl/DPCB7fYHwNiadlJKdQeaAj/Wsj0hzq3awueBmem8GH6cnFLF4+2vAK0NHbnz3xW7SM8r4p/XJdBgZyZYLNZYJdm7tfjwIDbnHkXrui8NUtuE31RrfWpF6f1Yk/pplFIm4Hngb+d7MaXUFKVUilIqJT8/v5ahCQG9npzBPWs+54vYYczv2N+60YCRO6n7CnlpyXZGxTZnZEyzem1bOLa48CCOlpSTXVBS522dN+ErpZYopbbW8DOm+n7a+vFU00fU3cBCrXXu+drSWs/WWidorRNCQ0Mv+CCEOKucHKat+pSuezN4eMQ95DYMrdpeX46VlnPvJxtp7OfFE2NipECaOE28bcbtpnro1jlvwtdaD9Vax9Tw8y1wQCnVHMD2u6blh/oA9yqlsoDngJuVUo5zFU24togIPC2VvDz/WbQyMWX8PznoF1Rvo2IsFs2Mr34n53AJr1zflUZ+XvXSrnAe7ZsG8M9RnaoSf12qbZfOPGCS7fYk4Nszd9BaJ2qtI7TWUVi7dT7UWp/r4q4Q9mMbuRNReIDXvn2a3Y1aMv6mF9jxyFN1225yMjoqiieH3c6C3/N4qEkJvVpLrXvxZ2aT4rb+rYkK8avztmqb8J8GhimlMoGhtvsopRKUUu/UNjghaq3ayJ2BWRv5bNnLlAaHcE1uML9lHa6bNm3lE/7bNIF3eoxj0vr5TEmaJOUThOFUfVwZvhQJCQk6JSXF6DCEC8opKGHye+vIPXqCF6+LZ1Rsc/s2EBXFFwFteXDUdEanr+CVec9iQluHYGZl2bctIc6glFqvtU6o6TGZaSvcTkSwL1/d1ZcuLQO599MNvPPyl9bx+bUZp2+rgInJxA9eLZhxxTQuy9rI8wtesCZ7kPIJwnCS8IVbauTnRfJtvRgZUMYTeQ2Y2WYYFo11nP6NN0JIyIUnflsXjs7O5oOuo7h77Ay67M/krblP4l1Z8cd+Uj5BGMzD6ACEMIqPp5nX3r6fWa2H8m6PseQ1DOXF757Hp6IMCgqsE7Sg5olRycnWsfw5OWAysbthU14efBffdB7E0My1vDL/P/iWVyuIJeUThAOQPnzh3kwm0Jp3EsYwa/BfaHV4H39d9Qmj01f+ud/9VJLPzgalKPHwYmGHfnweO5x14TGYLZVM/XUOU3/9DLO2WJ+jlPXMftYsmVEr6sW5+vAl4Qv3FhVlTeDAz6268dSgW9kWGkX7/Gwm/L6EXrlb6bQnA885n1q7bUpK2NS8PZ/HDmd+pwEUe/vS6vBeJmxZzDWpP9G0uNrIH7lIKwwgCV+Is7H1v1NindZeqUx817E/b/ccx9ZmbQHw8TTRMW8nDY4XcdC/MTuDw2lQVsqV237h/7YspkduKn+aO+vrK0XRhCEk4QtxLsnJcN991n77avJCw1j/2POsj+jMtk++pcJkxruijCu3rWJ0+goCyk6c/jpms7UgmnThCANJwhfiQlS/EHtm0q7W9VMjOaMXDkLG4QtxIaqVVv5T2eJqi6tUOVUETWraC3upNp+jLtZukGGZQlyIU8n8bN8AhKitM64nVa3dAHZ7n0mXjhBCOIKzdRte5Ggv6dIRQghHd7bSG3YsySEJXwghHMHZSm/YsSSHJHwhhHAENQ0MsHNJDkn4QgjhCKqt3YBSdTL6S0bpCCGEo0hMrNORX3KGL4QQbkISvhBCuAlJ+EII4SYk4QshhJuQhC+EEG7CYUsrKKXygXOUJzynEOCQHcNxBu54zOCexy3H7B4u9ZgjtdahNT3gsAm/NpRSKWerJeGq3PGYwT2PW47ZPdTFMUuXjhBCuAlJ+EII4SZcNeHPNjoAA7jjMYN7Hrccs3uw+zG7ZB++EEKIP3PVM3whhBBnkIQvhBBuwuUSvlJqpFJqm1Jqh1JqhtHx1DWlVLhSaplSKk0plaqUus/omOqLUsqslNqolPrO6Fjqg1IqSCn1pVIqQymVrpTqY3RMdU0pNd32vt6qlPpUKeVjdEx1QSn1rlLqoFJqa7VtjZVSi5VSmbbfjWrbjkslfKWUGXgduAKIBiYqpaKNjarOVQAPaK2jgd7APW5wzKfcB6QbHUQ9ehn4QWvdEYjDxY9dKdUSmAYkaK1jADNwvbFR1Zn3gZFnbJsBLNVatwOW2u7XikslfKAnsENrvUtrXQbMAcYYHFOd0lrnaa032G4fw5oEWhobVd1TSoUBo4B3jI6lPiilAoEBwP8AtNZlWuujhgZVPzyABkopD8AX2GdwPHVCa70COHzG5jHAB7bbHwBja9uOqyX8lsCeavdzcYPkd4pSKgroCqw1OJT68BLwEGAxOI760grIB96zdWO9o5TyMzqouqS13gs8B+QAeUCh1vpHY6OqV0211nm22/uBprV9QVdL+G5LKeUPfAX8VWtdZHQ8dUkpNRo4qLVeb3Qs9cgD6Aa8qbXuChzHDl/xHZmtz3oM1g+7FoCfUupGY6MyhraOn6/1GHpXS/h7gfBq98Ns21yaUsoTa7JP1lp/bXQ89aAfcLVSKgtrt91gpdTHxoZU53KBXK31qW9vX2L9AHBlQ4HdWut8rXU58DXQ1+CY6tMBpVRzANvvg7V9QVdL+L8B7ZRSrZRSXlgv8MwzOKY6pZRSWPt107XWLxgdT33QWv9Dax2mtY7C+m/8k9bapc/8tNb7gT1KqQ62TUOANANDqg85QG+llK/tfT4EF79QfYZ5wCTb7UnAt7V9QZdaxFxrXaGUuhdYhPWK/rta61SDw6pr/YCbgN+VUpts2x7WWi80LiRRR6YCybaTmV3ALQbHU6e01muVUl8CG7CORtuIi5ZYUEp9CgwEQpRSucBjwNPA50qpv2AtFX9drduR0gpCCOEeXK1LRwghxFlIwhdCCDchCV8IIdyEJHwhhHATkvCFEMJNSMIXQgg3IQlfCCHcxP8DKoBMJa+htEkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use Gaussian Process Regression to predict the solution\n",
    "y_test = K.predict(x_test)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(x_test, y_test, label='Gaussian Process Regression')\n",
    "plt.scatter(x, y, c='r', label='Training data')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"font-size:2em; font-family:Arial\"><b><span style=\"color:blue;\">A</span>daptive <span style=\"color:blue;\">K</span>riging <span style=\"color:blue;\">M</span>onte <span style=\"color:blue;\">C</span>arlo <span style=\"color:blue;\">S</span>imulation </b></span>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\">Active Learning Framework for:</span>\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Reliability Analysis [1, 2, 3]</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Global Optimization [4]</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Best Global fit surrogate models [5]</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">User-defined objectives</span></li>\n",
    "  </ul>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">AKMCS term is adopted from:</span></li>\n",
    "    <span style=\"font-size:0.9em; font-family:Arial\"><span style=\"color:blue;\">Echard, N. Gayton and M. Lemaire, “AK-MCS: An active learning reliability method combining Kriging and Monte Carlo Simulation”, Structural Safety, Pages 145-154, 2011.</span></span>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"margin-top:40px\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">[1] Bichon. B et al., 2008, Efficient global reliability analysis for nonlinear implicit performance, AIAA Journal </span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">[2] Echard B. et al., 2011, AK-MCS: An active learning reliability method combining Kriging and Monte Carlo Simulation, Structural Safety </span></li>\n",
    "    <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">[3] Sundar V. et al., Reliability analysis using adaptive Kriging surrogates and multimodel inference, ASCE-ASME Journal of Risk and Uncertainty n Engineering Systems, Part A: Civil Engineering</span></li>\n",
    "        <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">[4] Jones D. et al, 1998, Efficient global optimization of expensive black-box functions, Journal of Global optimization</span></li>\n",
    "        <br></br>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">[5] Lam. C, 2008, Sequential adaptive designs in computer experiments for response surface model fit, PhD Thesis, Ohio State University</span></li>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul style=\"margin-top:40px\">\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Adaptive kriging methods combine Monte Carlo simulation with adaptively build <span style=\"color:blue;\">Kriging</span> surrogates</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">The <span style=\"color:blue;\">model response</span> is approximated by the Kriging surrogate to reduce the computational cost.</span></li>\n",
    "    <br></br>\n",
    "</ul>\n",
    "\n",
    "<span style=\"font-size:1.1em; font-family:Arial\"><span style=\"color:blue;\">Steps:</span></span>\n",
    "<br></br>\n",
    "<ol>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Generate a small experimental design $\\mathbf{X}=[\\boldsymbol{x}_1,...,\\boldsymbol{x}_{N_0}]$ and calculate the corresponding  responses $\\mathbf{Y}=[\\mathcal{M}(\\boldsymbol{x}_1),...,\\mathcal{M}(\\boldsymbol{x}_{N_0})]$.</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Train a Kriging surrogate $\\tilde{\\mathcal{M}}(\\boldsymbol{x})$ using the experimental design</span></li>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Generate a large number of candidate samples $\\mathbf{X}'=[\\boldsymbol{x}_1,...\\boldsymbol{x}_{N_{MC}}]$ and predict the corresponding surrogate responses $\\mathbf{Y}'=[\\tilde{\\mathcal{M}}(\\boldsymbol{x}_1),...,\\tilde{\\mathcal{M}}(\\boldsymbol{x}_{N_{MC}})]$</span></li>\n",
    "   </ol>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<ol start=\"4\">\n",
    "<li><span style=\"font-size:1.1em; font-family:Arial\">Select the next sample $\\boldsymbol{x}_*$ to be added to the experimental design $\\mathbf{X}$ based on an appropriate <span style=\"color:blue;\">learning</span> function. A learning function is a measure of how much candidate sample $\\boldsymbol{x}_*$ helps us reaching our goals when it is added in the experimental design.</span></li>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Check whether a convergence criterion is satisfied. If it is, stop, otherwise continue with step 6.</span></li>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Add sample $\\boldsymbol{x}_*$ and the corresponding respose $\\tilde{\\mathcal{M}}(\\boldsymbol{x}_*)$ to the experimental design and return to step 2.</span></li>\n",
    "    <br></br>\n",
    "    <br></br>\n",
    "</ol>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Learning functions</b></span>\n",
    "\n",
    "<ul>\n",
    "        <li><span style=\"font-size:1.1em; font-family:Arial\">U-function: based on the concept of <i>misclassification</i> (i.e., estimate the probability that the sign of the surrogate performance function and the sign of the true performance function do not match).</span></li>\n",
    "    </ul>\n",
    "     \\begin{align*}\n",
    "    & U(\\boldsymbol{x})=\\frac{|\\mu_{\\tilde{Υ}}(\\boldsymbol{x})|}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\\\\n",
    "    & P_U(\\boldsymbol{x})=\\Phi(-U(\\boldsymbol{x}))\n",
    "     \\end{align*}\n",
    "    <br></br>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">Select the sample $\\boldsymbol{x}_*$ to add in the design experimental:</span>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "\\begin{align*}\n",
    "& \\boldsymbol{x}_*=\\text{arg} \\max(P_U(\\mathbf{s})) \\ \\text{where} \\ s \\in \\mathbf{X}'=[\\boldsymbol{x}_1,...,\\boldsymbol{x}_{N_{MC}}]\n",
    " \\end{align*}\n",
    "\n",
    "<br></br>\n",
    " <br></br>\n",
    " <br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue; font-size:1.3em; font-family:Arial\"><b>Learning functions</b></span>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Probability weighted U-function: A weighted version of the U- function</span></li>\n",
    "    \\begin{align*}\n",
    "        & U(\\boldsymbol{x})=w(\\boldsymbol{x})\\frac{|\\mu_{\\tilde{Υ}}(\\boldsymbol{x})|}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})} \\\\\n",
    "        & w(\\boldsymbol{x})=\\frac{\\max f_{\\mathbf{X}}(\\boldsymbol{x})-f_{\\mathbf{X}}(\\boldsymbol{x})}{\\max f_{\\mathbf{X}}(\\boldsymbol{x})}\n",
    "    \\end{align*}\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Expected feasibility function (EFF):</span></li>\n",
    "    <br></br>\n",
    "    \\begin{align*}\n",
    "        & EFF(\\boldsymbol{x})=\\mu_{\\tilde{Υ}}(\\boldsymbol{x})\\bigg[ 2\\Phi \\bigg( \\frac{-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})} \\bigg)-\\Phi \\bigg( \\frac{\\epsilon-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg) -\\Phi \\bigg(\\frac{\\epsilon-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg) \\bigg]\\\\\n",
    "    & \\\\\n",
    "        & - \\sigma_{\\tilde{Υ}}(\\boldsymbol{x}) \\bigg[ 2\\varphi \\bigg( \\frac{-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})} \\bigg)-\\varphi \\bigg( \\frac{\\epsilon-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Y}}(\\mathbf{x})}\\bigg) -\\varphi \\bigg(\\frac{\\epsilon-\\mu_{\\tilde{Y}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Y}}(\\boldsymbol{x})}\\bigg)  \\bigg] + \\epsilon \\bigg[\\Phi \\bigg( \\frac{\\epsilon-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg)-\\Phi \\bigg( \\frac{-\\epsilon-\\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg) \\bigg]\n",
    "    \\end{align*}\n",
    "    <br></br>\n",
    "    <span style=\"font-size:1.1em; font-family:Arial\">Where $\\epsilon=2\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})$ and $\\boldsymbol{x}_*=\\arg \\max(EFF_U(\\mathbf{s}))$ </span>\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "<br></br>\n",
    "\n",
    "<ul>\n",
    "    <li><span style=\"font-size:1.1em; font-family:Arial\">Expected Improvement function (EIF): Balances global and local searches to find the minimum $f_{\\min}$ </span></li>\n",
    "    <br></br>\n",
    "\n",
    "\\begin{align*}\n",
    "         \\mathbb{E}[I(\\boldsymbol{x})] =\\mathbb{E}[\\max (f_{\\min} - \\mathbf{Y}', 0)] \n",
    "         = \\bigg(f_{\\min} - \\mu_{\\tilde{Υ}}(\\boldsymbol{x})\\bigg)\\Phi \\bigg(\\frac{f_{\\min} - \\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg)+\\sigma_{\\tilde{Υ}(\\boldsymbol{x})}\\varphi\\bigg(\\frac{f_{\\min} - \\mu_{\\tilde{Υ}}(\\boldsymbol{x})}{\\sigma_{\\tilde{Υ}}(\\boldsymbol{x})}\\bigg)\n",
    "    \\end{align*}\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\\begin{align*}\n",
    "f_{\\min} = \\min (\\mathcal{M}(\\boldsymbol{x}_1), \\ldots, \\mathcal{M}(\\boldsymbol{x}_{N_0})\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "</ul>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"font-size:2em;\"> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <b>Kriging/AKMCS/Optimization</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "## Branin-Hoo function\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"branin.png\" width=\"500\"> \n",
    "</div>\n",
    "\n",
    "- Evaluated on the square $x_1 \\in [-5, 10], \\ x_2 \\in [0, 15]$\n",
    "- Two local minima and one global minimum\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.23952D+05    |proj g|=  3.00000D+00\n",
      "\n",
      "At iterate    1    f=  1.11107D+02    |proj g|=  5.00000D+00\n",
      "\n",
      "At iterate    2    f=  9.37073D+01    |proj g|=  6.90706D-01\n",
      "\n",
      "At iterate    3    f=  9.27510D+01    |proj g|=  2.56090D-01\n",
      "\n",
      "At iterate    4    f=  9.27508D+01    |proj g|=  4.88157D-02\n",
      "\n",
      "At iterate    5    f=  9.27508D+01    |proj g|=  1.39266D-04\n",
      "\n",
      "At iterate    6    f=  9.27508D+01    |proj g|=  1.42109D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      6     15      8     0     2   1.421D-06   9.275D+01\n",
      "  F =   92.750833966875845     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.84412D+01    |proj g|=  7.99007D-01\n",
      "\n",
      "At iterate    1    f=  9.28996D+01    |proj g|=  4.43639D+00\n",
      "\n",
      "At iterate    2    f=  9.27747D+01    |proj g|=  3.11022D+00\n",
      "\n",
      "At iterate    3    f=  9.27510D+01    |proj g|=  2.99033D-01\n",
      "\n",
      "At iterate    4    f=  9.27508D+01    |proj g|=  1.05274D-02\n",
      "\n",
      "At iterate    5    f=  9.27508D+01    |proj g|=  3.41061D-05\n",
      "\n",
      "At iterate    6    f=  9.27508D+01    |proj g|=  1.42109D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      6      8      7     0     0   1.421D-06   9.275D+01\n",
      "  F =   92.750833966875831     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34391D+04    |proj g|=  2.16619D+00\n",
      "\n",
      "At iterate    1    f=  1.11107D+02    |proj g|=  5.00000D+00\n",
      "\n",
      "At iterate    2    f=  9.34476D+01    |proj g|=  4.48426D+00\n",
      "\n",
      "At iterate    3    f=  9.27579D+01    |proj g|=  1.71535D+00\n",
      "\n",
      "At iterate    4    f=  9.27512D+01    |proj g|=  3.75120D-01\n",
      "\n",
      "At iterate    5    f=  9.27508D+01    |proj g|=  7.12816D-03\n",
      "\n",
      "At iterate    6    f=  9.27508D+01    |proj g|=  2.70006D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      6     12      7     0     0   2.700D-05   9.275D+01\n",
      "  F =   92.750833966877479     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.21925D+05    |proj g|=  2.64525D+00\n",
      "\n",
      "At iterate    1    f=  1.11107D+02    |proj g|=  5.00000D+00\n",
      "\n",
      "At iterate    2    f=  9.99405D+01    |proj g|=  4.72238D+00\n",
      "\n",
      "At iterate    3    f=  9.28801D+01    |proj g|=  6.36181D-01\n",
      "\n",
      "At iterate    4    f=  9.28438D+01    |proj g|=  4.42812D+00\n",
      "\n",
      "At iterate    5    f=  9.27514D+01    |proj g|=  4.98112D-01\n",
      "\n",
      "At iterate    6    f=  9.27508D+01    |proj g|=  3.58384D-02\n",
      "\n",
      "At iterate    7    f=  9.27508D+01    |proj g|=  1.93268D-04\n",
      "\n",
      "At iterate    8    f=  9.27508D+01    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      8     15      9     0     0   0.000D+00   9.275D+01\n",
      "  F =   92.750833966875831     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07559D+02    |proj g|=  4.91660D+00\n",
      "\n",
      "At iterate    1    f=  9.32488D+01    |proj g|=  4.47016D+00\n",
      "\n",
      "At iterate    2    f=  9.27534D+01    |proj g|=  1.03252D+00\n",
      "\n",
      "At iterate    3    f=  9.27509D+01    |proj g|=  1.84706D-01\n",
      "\n",
      "At iterate    4    f=  9.27508D+01    |proj g|=  2.09610D-03\n",
      "\n",
      "At iterate    5    f=  9.27508D+01    |proj g|=  4.26326D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      5      9      6     0     0   4.263D-06   9.275D+01\n",
      "  F =   92.750833966875845     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45683D+02    |proj g|=  1.06495D+00\n",
      "\n",
      "At iterate    1    f=  1.11107D+02    |proj g|=  5.00000D+00\n",
      "\n",
      "At iterate    2    f=  9.27536D+01    |proj g|=  1.08354D+00\n",
      "\n",
      "At iterate    3    f=  9.27508D+01    |proj g|=  6.38494D-03\n",
      "\n",
      "At iterate    4    f=  9.27508D+01    |proj g|=  7.81597D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      4      7      5     0     0   7.816D-05   9.275D+01\n",
      "  F =   92.750833966890568     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.82684D+02    |proj g|=  4.58818D+00\n",
      "\n",
      "At iterate    1    f=  1.11107D+02    |proj g|=  5.00000D+00\n",
      "\n",
      "At iterate    2    f=  9.35564D+01    |proj g|=  4.49123D+00\n",
      "\n",
      "At iterate    3    f=  9.27602D+01    |proj g|=  1.96581D+00\n",
      "\n",
      "At iterate    4    f=  9.27513D+01    |proj g|=  4.69196D-01\n",
      "\n",
      "At iterate    5    f=  9.27508D+01    |proj g|=  1.02375D-02\n",
      "\n",
      "At iterate    6    f=  9.27508D+01    |proj g|=  5.40012D-05\n",
      "\n",
      "At iterate    7    f=  9.27508D+01    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      7     11      9     0     2   0.000D+00   9.275D+01\n",
      "  F =   92.750833966875831     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.54877D+07    |proj g|=  4.06813D+00\n",
      "\n",
      "At iterate    1    f=  1.11107D+02    |proj g|=  5.00000D+00\n",
      "\n",
      "At iterate    2    f=  9.28019D+01    |proj g|=  6.23759D-01\n",
      "\n",
      "At iterate    3    f=  9.27508D+01    |proj g|=  6.06377D-03\n",
      "\n",
      "At iterate    4    f=  9.27508D+01    |proj g|=  2.97007D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      4     16      5     0     0   2.970D-04   9.275D+01\n",
      "  F =   92.750833967079785     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.38317D+06    |proj g|=  4.64655D+00\n",
      "\n",
      "At iterate    1    f=  1.11107D+02    |proj g|=  5.00000D+00\n",
      "\n",
      "At iterate    2    f=  1.02562D+02    |proj g|=  4.79280D+00\n",
      "\n",
      "At iterate    3    f=  9.38963D+01    |proj g|=  6.98441D-01\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iterate    4    f=  9.36671D+01    |proj g|=  4.49791D+00\n",
      "\n",
      "At iterate    5    f=  9.27999D+01    |proj g|=  4.41377D+00\n",
      "\n",
      "At iterate    6    f=  9.27541D+01    |proj g|=  6.07712D-01\n",
      "\n",
      "At iterate    7    f=  9.27508D+01    |proj g|=  5.98092D-02\n",
      "\n",
      "At iterate    8    f=  9.27508D+01    |proj g|=  7.60281D-04\n",
      "\n",
      "At iterate    9    f=  9.27508D+01    |proj g|=  1.42109D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      9     19     11     0     2   1.421D-06   9.275D+01\n",
      "  F =   92.750833966875817     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.58726D+02    |proj g|=  4.07040D+00\n",
      "\n",
      "At iterate    1    f=  1.11107D+02    |proj g|=  5.00000D+00\n",
      "\n",
      "At iterate    2    f=  9.30198D+01    |proj g|=  4.45021D+00\n",
      "\n",
      "At iterate    3    f=  9.27519D+01    |proj g|=  6.63638D-01\n",
      "\n",
      "At iterate    4    f=  9.27509D+01    |proj g|=  8.41737D-02\n",
      "\n",
      "At iterate    5    f=  9.27508D+01    |proj g|=  6.13909D-04\n",
      "\n",
      "At iterate    6    f=  9.27508D+01    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      6     10      8     0     2   0.000D+00   9.275D+01\n",
      "  F =   92.750833966875831     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45116D+02    |proj g|=  6.02178D-01\n",
      "\n",
      "At iterate    1    f=  1.19644D+02    |proj g|=  5.00000D+00\n",
      "\n",
      "At iterate    2    f=  1.17500D+02    |proj g|=  4.92430D+00\n",
      "\n",
      "At iterate    3    f=  1.15542D+02    |proj g|=  4.80978D+00\n",
      "\n",
      "At iterate    4    f=  1.15406D+02    |proj g|=  2.46719D-01\n",
      "\n",
      "At iterate    5    f=  1.15375D+02    |proj g|=  3.42990D-01\n",
      "\n",
      "At iterate    6    f=  1.15375D+02    |proj g|=  1.29347D-02\n",
      "\n",
      "At iterate    7    f=  1.15375D+02    |proj g|=  3.97904D-05\n",
      "\n",
      "At iterate    8    f=  1.15375D+02    |proj g|=  5.68434D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      8     10      9     0     2   5.684D-06   1.154D+02\n",
      "  F =   115.37468429310070     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.23517D+02    |proj g|=  2.30209D-01\n",
      "\n",
      "At iterate    1    f=  1.23242D+02    |proj g|=  3.71193D-01\n",
      "\n",
      "At iterate    2    f=  1.23241D+02    |proj g|=  3.87757D-02\n",
      "\n",
      "At iterate    3    f=  1.23241D+02    |proj g|=  1.53477D-04\n",
      "\n",
      "At iterate    4    f=  1.23241D+02    |proj g|=  8.52651D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      4      6      5     0     2   8.527D-06   1.232D+02\n",
      "  F =   123.24138346661333     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.32398D+02    |proj g|=  1.83371D-01\n",
      "\n",
      "At iterate    1    f=  1.31941D+02    |proj g|=  1.74478D-01\n",
      "\n",
      "At iterate    2    f=  1.31941D+02    |proj g|=  2.24759D-02\n",
      "\n",
      "At iterate    3    f=  1.31941D+02    |proj g|=  3.12639D-05\n",
      "\n",
      "At iterate    4    f=  1.31941D+02    |proj g|=  2.84217D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      4      6      5     0     2   2.842D-06   1.319D+02\n",
      "  F =   131.94072075089525     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38047D+02    |proj g|=  1.24884D-01\n",
      "\n",
      "At iterate    1    f=  1.38041D+02    |proj g|=  3.24803D-02\n",
      "\n",
      "At iterate    2    f=  1.38041D+02    |proj g|=  4.91696D-04\n",
      "\n",
      "At iterate    3    f=  1.38041D+02    |proj g|=  2.84217D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      5      4     0     2   2.842D-06   1.380D+02\n",
      "  F =   138.04144117079875     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45558D+02    |proj g|=  1.18294D-01\n",
      "\n",
      "At iterate    1    f=  1.45444D+02    |proj g|=  6.44377D-02\n",
      "\n",
      "At iterate    2    f=  1.45444D+02    |proj g|=  4.16378D-03\n",
      "\n",
      "At iterate    3    f=  1.45444D+02    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      5      4     0     2   0.000D+00   1.454D+02\n",
      "  F =   145.44405836125654     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.51547D+02    |proj g|=  8.96151D-02\n",
      "\n",
      "At iterate    1    f=  1.51543D+02    |proj g|=  1.35941D-02\n",
      "\n",
      "At iterate    2    f=  1.51543D+02    |proj g|=  1.44951D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      2      4      3     0     2   1.450D-04   1.515D+02\n",
      "  F =   151.54344706260912     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.56976D+02    |proj g|=  1.82545D+00\n",
      "\n",
      "At iterate    1    f=  1.56970D+02    |proj g|=  2.61565D-02\n",
      "\n",
      "At iterate    2    f=  1.56970D+02    |proj g|=  3.92220D-04\n",
      "\n",
      "At iterate    3    f=  1.56970D+02    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   0.000D+00   1.570D+02\n",
      "  F =   156.96974637411549     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.62350D+02    |proj g|=  1.99403D+00\n",
      "\n",
      "At iterate    1    f=  1.62344D+02    |proj g|=  5.78666D-02\n",
      "\n",
      "At iterate    2    f=  1.62344D+02    |proj g|=  9.03810D-04\n",
      "\n",
      "At iterate    3    f=  1.62344D+02    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   0.000D+00   1.623D+02\n",
      "  F =   162.34360416866991     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.67723D+02    |proj g|=  1.92724D+00\n",
      "\n",
      "At iterate    1    f=  1.67717D+02    |proj g|=  4.47642D-02\n",
      "\n",
      "At iterate    2    f=  1.67717D+02    |proj g|=  6.53699D-04\n",
      "\n",
      "At iterate    3    f=  1.67717D+02    |proj g|=  2.84217D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   2.842D-06   1.677D+02\n",
      "  F =   167.71693732316814     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.73048D+02    |proj g|=  2.08347D+00\n",
      "\n",
      "At iterate    1    f=  1.73041D+02    |proj g|=  7.70967D-02\n",
      "\n",
      "At iterate    2    f=  1.73041D+02    |proj g|=  1.18803D-03\n",
      "\n",
      "At iterate    3    f=  1.73041D+02    |proj g|=  2.84217D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   2.842D-06   1.730D+02\n",
      "  F =   173.04089637326263     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.78361D+02    |proj g|=  2.06145D+00\n",
      "\n",
      "At iterate    1    f=  1.78355D+02    |proj g|=  7.26118D-02\n",
      "\n",
      "At iterate    2    f=  1.78355D+02    |proj g|=  1.07150D-03\n",
      "\n",
      "At iterate    3    f=  1.78355D+02    |proj g|=  2.84217D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   2.842D-06   1.784D+02\n",
      "  F =   178.35469620620594     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.83627D+02    |proj g|=  2.21490D+00\n",
      "\n",
      "At iterate    1    f=  1.83620D+02    |proj g|=  1.06280D-01\n",
      "\n",
      "At iterate    2    f=  1.83620D+02    |proj g|=  1.63141D-03\n",
      "\n",
      "At iterate    3    f=  1.83620D+02    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   0.000D+00   1.836D+02\n",
      "  F =   183.61973716796501     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.88884D+02    |proj g|=  2.18243D+00\n",
      "\n",
      "At iterate    1    f=  1.88877D+02    |proj g|=  9.93197D-02\n",
      "\n",
      "At iterate    2    f=  1.88877D+02    |proj g|=  1.45803D-03\n",
      "\n",
      "At iterate    3    f=  1.88877D+02    |proj g|=  5.68434D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   5.684D-06   1.889D+02\n",
      "  F =   188.87700574562899     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.94118D+02    |proj g|=  2.22377D+00\n",
      "\n",
      "At iterate    1    f=  1.94111D+02    |proj g|=  1.08659D-01\n",
      "\n",
      "At iterate    2    f=  1.94111D+02    |proj g|=  1.57172D-03\n",
      "\n",
      "At iterate    3    f=  1.94111D+02    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   0.000D+00   1.941D+02\n",
      "  F =   194.11067693467749     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.99333D+02    |proj g|=  2.24297D+00\n",
      "\n",
      "At iterate    1    f=  1.99326D+02    |proj g|=  1.13118D-01\n",
      "\n",
      "At iterate    2    f=  1.99326D+02    |proj g|=  1.60867D-03\n",
      "\n",
      "At iterate    3    f=  1.99326D+02    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   0.000D+00   1.993D+02\n",
      "  F =   199.32585324558789     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.04538D+02    |proj g|=  2.22266D+00\n",
      "\n",
      "At iterate    1    f=  2.04532D+02    |proj g|=  1.08784D-01\n",
      "\n",
      "At iterate    2    f=  2.04532D+02    |proj g|=  1.48361D-03\n",
      "\n",
      "At iterate    3    f=  2.04532D+02    |proj g|=  2.84217D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   2.842D-06   2.045D+02\n",
      "  F =   204.53164427970151     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.09730D+02    |proj g|=  2.22587D+00\n",
      "\n",
      "At iterate    1    f=  2.09723D+02    |proj g|=  1.09665D-01\n",
      "\n",
      "At iterate    2    f=  2.09723D+02    |proj g|=  1.45519D-03\n",
      "\n",
      "At iterate    3    f=  2.09723D+02    |proj g|=  5.68434D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   5.684D-06   2.097D+02\n",
      "  F =   209.72331173539047     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.14897D+02    |proj g|=  2.27932D+00\n",
      "\n",
      "At iterate    1    f=  2.14890D+02    |proj g|=  1.21702D-01\n",
      "\n",
      "At iterate    2    f=  2.14890D+02    |proj g|=  1.61435D-03\n",
      "\n",
      "At iterate    3    f=  2.14890D+02    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   0.000D+00   2.149D+02\n",
      "  F =   214.89000022778094     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.20060D+02    |proj g|=  2.23465D+00\n",
      "\n",
      "At iterate    1    f=  2.20054D+02    |proj g|=  1.11925D-01\n",
      "\n",
      "At iterate    2    f=  2.20054D+02    |proj g|=  1.42109D-03\n",
      "\n",
      "At iterate    3    f=  2.20054D+02    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   0.000D+00   2.201D+02\n",
      "  F =   220.05361302393277     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.25200D+02    |proj g|=  2.28223D+00\n",
      "\n",
      "At iterate    1    f=  2.25194D+02    |proj g|=  1.22640D-01\n",
      "\n",
      "At iterate    2    f=  2.25194D+02    |proj g|=  1.54330D-03\n",
      "\n",
      "At iterate    3    f=  2.25194D+02    |proj g|=  2.84217D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   2.842D-06   2.252D+02\n",
      "  F =   225.19419047878108     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.30346D+02    |proj g|=  2.20360D+00\n",
      "\n",
      "At iterate    1    f=  2.30340D+02    |proj g|=  1.05314D-01\n",
      "\n",
      "At iterate    2    f=  2.30340D+02    |proj g|=  1.24771D-03\n",
      "\n",
      "At iterate    3    f=  2.30340D+02    |proj g|=  5.68434D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   5.684D-06   2.303D+02\n",
      "  F =   230.33986569807584     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.35460D+02    |proj g|=  2.29390D+00\n",
      "\n",
      "At iterate    1    f=  2.35454D+02    |proj g|=  1.25499D-01\n",
      "\n",
      "At iterate    2    f=  2.35454D+02    |proj g|=  1.51772D-03\n",
      "\n",
      "At iterate    3    f=  2.35454D+02    |proj g|=  1.13687D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   1.137D-05   2.355D+02\n",
      "  F =   235.45379264695146     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.40568D+02    |proj g|=  2.26693D+00\n",
      "\n",
      "At iterate    1    f=  2.40562D+02    |proj g|=  1.19621D-01\n",
      "\n",
      "At iterate    2    f=  2.40562D+02    |proj g|=  1.39266D-03\n",
      "\n",
      "At iterate    3    f=  2.40562D+02    |proj g|=  2.84217D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   2.842D-06   2.406D+02\n",
      "  F =   240.56185729807760     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.45661D+02    |proj g|=  2.27908D+00\n",
      "\n",
      "At iterate    1    f=  2.45656D+02    |proj g|=  1.22438D-01\n",
      "\n",
      "At iterate    2    f=  2.45656D+02    |proj g|=  1.39266D-03\n",
      "\n",
      "At iterate    3    f=  2.45656D+02    |proj g|=  5.68434D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   5.684D-06   2.457D+02\n",
      "  F =   245.65577176806320     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.50744D+02    |proj g|=  2.27957D+00\n",
      "\n",
      "At iterate    1    f=  2.50738D+02    |proj g|=  1.22648D-01\n",
      "\n",
      "At iterate    2    f=  2.50738D+02    |proj g|=  1.36424D-03\n",
      "\n",
      "At iterate    3    f=  2.50738D+02    |proj g|=  1.13687D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   1.137D-05   2.507D+02\n",
      "  F =   250.73833140244602     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.55817D+02    |proj g|=  2.27387D+00\n",
      "\n",
      "At iterate    1    f=  2.55811D+02    |proj g|=  1.21483D-01\n",
      "\n",
      "At iterate    2    f=  2.55811D+02    |proj g|=  1.32729D-03\n",
      "\n",
      "At iterate    3    f=  2.55811D+02    |proj g|=  5.68434D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   5.684D-06   2.558D+02\n",
      "  F =   255.81115655931964     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.60876D+02    |proj g|=  2.28617D+00\n",
      "\n",
      "At iterate    1    f=  2.60871D+02    |proj g|=  1.24328D-01\n",
      "\n",
      "At iterate    2    f=  2.60871D+02    |proj g|=  1.33014D-03\n",
      "\n",
      "At iterate    3    f=  2.60871D+02    |proj g|=  5.68434D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   5.684D-06   2.609D+02\n",
      "  F =   260.87051440619433     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.65939D+02    |proj g|=  2.22140D+00\n",
      "\n",
      "At iterate    1    f=  2.65934D+02    |proj g|=  1.10032D-01\n",
      "\n",
      "At iterate    2    f=  2.65934D+02    |proj g|=  1.11413D-03\n",
      "\n",
      "At iterate    3    f=  2.65934D+02    |proj g|=  5.68434D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   5.684D-06   2.659D+02\n",
      "  F =   265.93366808522353     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.70977D+02    |proj g|=  2.28715D+00\n",
      "\n",
      "At iterate    1    f=  2.70972D+02    |proj g|=  1.24732D-01\n",
      "\n",
      "At iterate    2    f=  2.70972D+02    |proj g|=  1.27898D-03\n",
      "\n",
      "At iterate    3    f=  2.70972D+02    |proj g|=  5.68434D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   5.684D-06   2.710D+02\n",
      "  F =   270.97220250043563     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         2 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.76021D+02    |proj g|=  2.21622D+00\n",
      "\n",
      "At iterate    1    f=  2.76016D+02    |proj g|=  1.09060D-01\n",
      "\n",
      "At iterate    2    f=  2.76016D+02    |proj g|=  1.05729D-03\n",
      "\n",
      "At iterate    3    f=  2.76016D+02    |proj g|=  5.68434D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      7      3     0     2   5.684D-06   2.760D+02\n",
      "  F =   276.01631172584672     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "from UQpy import PythonModel \n",
    "from UQpy.surrogates import GaussianProcessRegression \n",
    "from UQpy.sampling import MonteCarloSampling, AdaptiveKriging \n",
    "from UQpy.run_model.RunModel import RunModel \n",
    "from UQpy.distributions import Uniform \n",
    "from BraninHoo import function \n",
    "from UQpy.utilities.MinimizeOptimizer import MinimizeOptimizer\n",
    "\n",
    "marginals = [Uniform(loc=-5, scale=15), Uniform(loc=0, scale=15)] \n",
    "x = MonteCarloSampling(distributions=marginals, nsamples=20)\n",
    "\n",
    "model = PythonModel(model_script='BraninHoo.py', model_object_name='function')\n",
    "rmodel = RunModel(model=model)\n",
    "\n",
    "from UQpy.surrogates.gaussian_process.regression_models import LinearRegression \n",
    "from UQpy.surrogates.gaussian_process.kernels import RBF \n",
    "\n",
    "bounds = [[10**(-3), 10**3], [10**(-3), 10**2], [10**(-3), 10**2]] \n",
    "optimizer = MinimizeOptimizer(method=\"L-BFGS-B\", bounds=bounds) \n",
    "K = GaussianProcessRegression(regression_model=LinearRegression(), kernel=RBF(),\n",
    "                              optimizer=optimizer, hyperparameters=[1, 1, 0.1],\n",
    "                              optimizations_number=10)\n",
    "\n",
    "from UQpy.sampling.adaptive_kriging_functions.ExpectedImprovement import ExpectedImprovement\n",
    "\n",
    "learning_function = ExpectedImprovement() \n",
    "a = AdaptiveKriging(runmodel_object=rmodel, samples=x.samples, surrogate=K, \n",
    "                    learning_nsamples=10 ** 3, n_add=1, learning_function=learning_function, \t\t       distributions=marginals) \n",
    "a.run(nsamples=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "rise": {
   "autolaunch": true,
   "backimage": "MseeBackground.png",
   "enable_chalkboard": true,
   "height": "90%",
   "reveal_shortcuts": {
    "chalkboard": {
     "clear": "ctrl-k"
    }
   },
   "width": "90%"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
